<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[c++ map 查找性能测试]]></title>
      <url>/2018/08/01/c-map-%E6%9F%A5%E6%89%BE%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</url>
      <content type="html"><![CDATA[<p>最近在为推荐服务作性能调优，这个服务的主要逻辑是用离线计算的模型数据给请求中的每个广告打分，再返回这些广告的排序结果，这里面打分的过程其实就用请求中的数据拼成各种key，去查一个大的 map，这种计算非常多，成为了主要的性能瓶颈，代码比较老，使用的是 boost::unordered_map，为了解决这个问题，找了一些第三方库和标准库对比了一下</p>
<p>下面是在一台 aws <code>r4.xlarge</code> 机器上的测试结果(注意编译的时候一定要加 -O2)：</p>
<pre><code>std::map&lt;int, int&gt;                                 =&gt; 51866903
std::unordered_map&lt;int, int&gt;                       =&gt; 3838175
std::unordered_map&lt;int, int, nohashint&gt;            =&gt; 3508570
std::unordered_map&lt;int, int&gt;(N)                    =&gt; 3804471
boost::unordered_map&lt;int, int&gt;                     =&gt; 3291384
boost::unordered_map&lt;int, int, nohashint&gt;          =&gt; 3293934
boost::unordered_map&lt;int, int&gt;(N)                  =&gt; 3265856
google::dense_hash_map&lt;int, int&gt;                   =&gt; 785969
google::dense_hash_map&lt;int, int, nohashint&gt;        =&gt; 784455
google::dense_hash_map&lt;int, int&gt;(N)                =&gt; 899262
tsl::hopscotch_map&lt;int, int&gt;                       =&gt; 654668
tsl::hopscotch_map&lt;int, int, nohashint&gt;            =&gt; 680964
tsl::hopscotch_map&lt;int, int&gt;(N)                    =&gt; 663607
tsl::robin_map&lt;int, int&gt;                           =&gt; 406176
tsl::robin_map&lt;int, int, nohashint&gt;                =&gt; 411358
tsl::robin_map&lt;int, int&gt;(N)                        =&gt; 409993
</code></pre><p>可以看到 tsl::robin_map 的性能基本上能达到 std::unordered_map 的 10 倍，这个性能和操作系统以及库版本也有一定关系，实际生产环境中建议把<a href="https://github.com/hatlonely/hellocpp/blob/master/src/unordered_map/test_unordered_map.cpp" target="_blank" rel="noopener">代码</a>拉下来在自己的环境下测试一下</p>
<p>我们线上用 tsl::robin_map 替换了原来的 boost::unordered_map，整体性能提升了 5 倍，这里面当然也还包含了一些其他的优化，这个优化算是比较大的优化点了</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>Benchmark of major hash maps implementations:<br><a href="https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html" target="_blank" rel="noopener">https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html</a></li>
<li>测试代码: <a href="https://github.com/hatlonely/hellocpp/blob/master/src/unordered_map/test_unordered_map.cpp" target="_blank" rel="noopener">https://github.com/hatlonely/hellocpp/blob/master/src/unordered_map/test_unordered_map.cpp</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> c++ </tag>
            
            <tag> map </tag>
            
            <tag> 性能 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang grpc 负载均衡]]></title>
      <url>/2018/06/23/golang-grpc-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
      <content type="html"><![CDATA[<p>微服务架构里面，每个服务都会有很多节点，如果流量分配不均匀，会造成资源的浪费，甚至将一些机器压垮，这个时候就需要负载均衡，最简单的一种策略就是轮询，顺序依次选择不同的节点访问</p>
<p>grpc 在客户端提供了负载均衡的实现，并提供了服务地址解析和更新的接口(默认提供了 DNS 域名解析的支持)，方便不同服务的集成</p>
<h3 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h3><pre><code class="go">conn, err := grpc.Dial(
    &quot;&quot;,
    grpc.WithInsecure(),
    // 负载均衡，使用 consul 作服务发现
    grpc.WithBalancer(grpc.RoundRobin(grpclb.NewConsulResolver(
        &quot;127.0.0.1:8500&quot;, &quot;grpc.health.v1.add&quot;,
    ))),
)
</code></pre>
<p>创建连接的时候可以使用 <code>WithBalancer</code> 选项来指定负载均衡策略，这里使用 RoundRobin 算法，其实就是轮询策略</p>
<h3 id="与-consul-的集成"><a href="#与-consul-的集成" class="headerlink" title="与 consul 的集成"></a>与 consul 的集成</h3><p>有了负载均衡策略，还需要一个地址解析和更新策略，可以使用 DNS 服务来实现，但如果我们使用 consul 来做服务的注册和发现，可以通过实现 <code>naming.Resolver</code> 和 <code>naming.Watcher</code> 接口来支持</p>
<ul>
<li><code>naming.Resolver</code>: 实现地址解析</li>
<li><code>naming.Watcher</code>: 实现节点的变更，添加或者删除</li>
</ul>
<pre><code class="go">func NewConsulResolver(address string, service string) naming.Resolver {
    return &amp;consulResolver{
        address: address,
        service: service,
    }
}

type consulResolver struct {
    address string
    service string
}

func (r *consulResolver) Resolve(target string) (naming.Watcher, error) {
    config := api.DefaultConfig()
    config.Address = r.address
    client, err := api.NewClient(config)
    if err != nil {
        return nil, err
    }

    return &amp;consulWatcher{
        client:  client,
        service: r.service,
        addrs:   map[string]struct{}{},
    }, nil
}

type consulWatcher struct {
    client    *api.Client
    service   string
    addrs     map[string]struct{}
    lastIndex uint64
}

func (w *consulWatcher) Next() ([]*naming.Update, error) {
    for {
        services, metainfo, err := w.client.Health().Service(w.service, &quot;&quot;, true, &amp;api.QueryOptions{
            WaitIndex: w.lastIndex, // 同步点，这个调用将一直阻塞，直到有新的更新
        })
        if err != nil {
            logrus.Warn(&quot;error retrieving instances from Consul: %v&quot;, err)
        }
        w.lastIndex = metainfo.LastIndex

        addrs := map[string]struct{}{}
        for _, service := range services {
            addrs[net.JoinHostPort(service.Service.Address, strconv.Itoa(service.Service.Port))] = struct{}{}
        }

        var updates []*naming.Update
        for addr := range w.addrs {
            if _, ok := addrs[addr]; !ok {
                updates = append(updates, &amp;naming.Update{Op: naming.Delete, Addr: addr})
            }
        }

        for addr := range addrs {
            if _, ok := w.addrs[addr]; !ok {
                updates = append(updates, &amp;naming.Update{Op: naming.Add, Addr: addr})
            }
        }

        if len(updates) != 0 {
            w.addrs = addrs
            return updates, nil
        }
    }
}

func (w *consulWatcher) Close() {
    // nothing to do
}
</code></pre>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>gRPC Name Resolution: <a href="https://github.com/grpc/grpc/blob/master/doc/naming.md" target="_blank" rel="noopener">https://github.com/grpc/grpc/blob/master/doc/naming.md</a></li>
<li>Load Balancing in gRPC: <a href="https://github.com/grpc/grpc/blob/master/doc/load-balancing.md" target="_blank" rel="noopener">https://github.com/grpc/grpc/blob/master/doc/load-balancing.md</a></li>
<li>dns_resolver: <a href="https://github.com/grpc/grpc-go/blob/30fb59a4304034ce78ff68e21bd25776b1d79488/naming/dns_resolver.go" target="_blank" rel="noopener">https://github.com/grpc/grpc-go/blob/30fb59a4304034ce78ff68e21bd25776b1d79488/naming/dns_resolver.go</a></li>
<li>代码地址: <a href="https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/cmd/client/main.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/cmd/client/main.go</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> grpc </tag>
            
            <tag> 负载均衡 </tag>
            
            <tag> load balancer </tag>
            
            <tag> consul </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang consul-grpc 服务注册与发现]]></title>
      <url>/2018/06/23/golang-consul-grpc-%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%8E%E5%8F%91%E7%8E%B0/</url>
      <content type="html"><![CDATA[<p>在微服务架构里面，每个小服务都是由很多节点组成，节点的添加删除故障希望能对下游透明，因此有必要引入一种服务的自动注册和发现机制，而 consul 提供了完整的解决方案，并且内置了对 GRPC 以及 HTTP 服务的支持</p>
<h3 id="总体架构"><a href="#总体架构" class="headerlink" title="总体架构"></a>总体架构</h3><p><img src="/img/architecture/service_register_and_find.png" alt="服务注册与发现"></p>
<ul>
<li>服务调用: client 直连 server 调用服务</li>
<li>服务注册: 服务端将服务的信息注册到 consul 里</li>
<li>服务发现: 客户端从 consul 里发现服务信息，主要是服务的地址</li>
<li>健康检查: consul 检查服务器的健康状态</li>
</ul>
<h3 id="服务注册"><a href="#服务注册" class="headerlink" title="服务注册"></a>服务注册</h3><p>服务端将服务信息注册到 consul 里，这个注册可以在服务启动可以提供服务的时候完成</p>
<p>完整代码参考: <a href="https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/internal/grpcsr/consul_register.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/internal/grpcsr/consul_register.go</a></p>
<pre><code class="go">config := api.DefaultConfig()
config.Address = r.Address
client, err := api.NewClient(config)
if err != nil {
    panic(err)
}
agent := client.Agent()

IP := localIP()
reg := &amp;api.AgentServiceRegistration{
        ID:      fmt.Sprintf(&quot;%v-%v-%v&quot;, r.Service, IP, r.Port), // 服务节点的名称
        Name:    fmt.Sprintf(&quot;grpc.health.v1.%v&quot;, r.Service),    // 服务名称
        Tags:    r.Tag,                                          // tag，可以为空
        Port:    r.Port,                                         // 服务端口
        Address: IP,                                             // 服务 IP
        Check: &amp;api.AgentServiceCheck{     // 健康检查
            Interval: r.Interval.String(), // 健康检查间隔
            // grpc 支持，执行健康检查的地址，service 会传到 Health.Check 函数中
            GRPC:     fmt.Sprintf(&quot;%v:%v/%v&quot;, IP, r.Port, r.Service), 
            DeregisterCriticalServiceAfter: r.DeregisterCriticalServiceAfter.String(), // 注销时间，相当于过期时间
        },
    }

if err := agent.ServiceRegister(reg); err != nil {
    panic(err)
}
</code></pre>
<h3 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h3><p>客户端从 consul 里发现服务信息，主要是服务的地址</p>
<p>完整代码参考: <a href="https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/internal/grpclb/consul_resolver.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/internal/grpclb/consul_resolver.go</a></p>
<pre><code class="go">services, metainfo, err := w.client.Health().Service(w.service, &quot;&quot;, true, &amp;api.QueryOptions{
    WaitIndex: w.lastIndex, // 同步点，这个调用将一直阻塞，直到有新的更新
})
if err != nil {
    logrus.Warn(&quot;error retrieving instances from Consul: %v&quot;, err)
}
w.lastIndex = metainfo.LastIndex

addrs := map[string]struct{}{}
for _, service := range services {
    addrs[net.JoinHostPort(service.Service.Address, strconv.Itoa(service.Service.Port))] = struct{}{}
}
</code></pre>
<h3 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h3><p>consul 检查服务器的健康状态，consul 用 <code>google.golang.org/grpc/health/grpc_health_v1.HealthServer</code> 接口，实现了对 grpc健康检查的支持，所以我们只需要实现先这个接口，consul 就能利用这个接口作健康检查了</p>
<p>完整代码参考: <a href="https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/cmd/server/main.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/cmd/server/main.go</a></p>
<pre><code class="go">// HealthImpl 健康检查实现
type HealthImpl struct{}

// Check 实现健康检查接口，这里直接返回健康状态，这里也可以有更复杂的健康检查策略，比如根据服务器负载来返回
func (h *HealthImpl) Check(ctx context.Context, req *grpc_health_v1.HealthCheckRequest) (*grpc_health_v1.HealthCheckResponse, error) {
    return &amp;grpc_health_v1.HealthCheckResponse{
        Status: grpc_health_v1.HealthCheckResponse_SERVING,
    }, nil
}

grpc_health_v1.RegisterHealthServer(server, &amp;HealthImpl{})
</code></pre>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>完整工程代码: <a href="https://github.com/hatlonely/hellogolang/tree/master/sample/addservice" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/tree/master/sample/addservice</a></li>
<li>consul 健康检查 api: <a href="https://www.consul.io/api/agent/check.html" target="_blank" rel="noopener">https://www.consul.io/api/agent/check.html</a></li>
<li>consul 服务注册 api: <a href="https://www.consul.io/api/agent/service.html" target="_blank" rel="noopener">https://www.consul.io/api/agent/service.html</a></li>
<li>grpc 健康检查: <a href="https://github.com/grpc/grpc/blob/master/doc/health-checking.md" target="_blank" rel="noopener">https://github.com/grpc/grpc/blob/master/doc/health-checking.md</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> grpc </tag>
            
            <tag> consul </tag>
            
            <tag> 服务注册与发现 </tag>
            
            <tag> 健康检查 </tag>
            
            <tag> 微服务 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[微服务组件之限流器与熔断器]]></title>
      <url>/2018/06/21/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BB%84%E4%BB%B6%E4%B9%8B%E9%99%90%E6%B5%81%E5%99%A8%E4%B8%8E%E7%86%94%E6%96%AD%E5%99%A8/</url>
      <content type="html"><![CDATA[<p>在微服务架构里面一个很常见的问题就是服务之间的延迟和通信失败问题，极端的情况下，甚至会因为某个服务的性能下降或者故障宕机，导致访问超时，层层传递，引发雪崩，最终导致整个系统崩溃，而限流器和熔断器(这两个组件都是客户端的)能很好的解决这个问题，提高系统的可靠性和稳定性</p>
<h3 id="限流器"><a href="#限流器" class="headerlink" title="限流器"></a>限流器</h3><p>限流器，从字面上理解就是用来限制流量，有时候流量突增(可预期的比如“双11”，不可预期的微博的热门话题等)，会将后端服务压垮，甚至直接宕机，使用限流器能限制访问后端的流量，起到一个保护作用，被限制的流量，可以根据具体的业务逻辑去处理，直接返回错误或者返回默认值等等</p>
<p>golang 提供了拓展库(<code>golang.org/x/time/rate</code>)提供了限流器组件，用法上也很简单直观，通过下面这段代码就可以创建一个限流器</p>
<pre><code class="go">// 每 800ms 产生 1 个 token，最多缓存 1 个 token，如果缓存满了，新的 token 会被丢弃
limiter := rate.NewLimiter(rate.Every(time.Duration(800)*time.Millisecond), 1)
</code></pre>
<p>限流器提供三种使用方式，<code>Allow</code>, <code>Wait</code>, <code>Reserve</code></p>
<p><code>Allow</code>: 返回是否有 token，没有 token 返回 false，或者消耗 1 个 token 返回 true<br><code>Wait</code>: 阻塞等待，知道取到 1 个 token<br><code>Reserve</code>: 返回 token 信息，<code>Allow</code> 其实相当于 <code>Reserve().OK</code>，此外还会返回需要等待多久才有新的 token</p>
<p>一般使用 Wait 的场景会比较多一些</p>
<pre><code class="go">if err := limiter.Wait(context.Background()); err != nil {
    panic(err)
}

// do you business logic
</code></pre>
<h3 id="熔断器"><a href="#熔断器" class="headerlink" title="熔断器"></a>熔断器</h3><p>和限流器对依赖服务的保护机制不一样，熔断器是当依赖的服务已经出现故障时，为了保证自身服务的正常运行不再访问依赖的服务，防止雪崩效应</p>
<p>熔断器有三种状态：</p>
<ul>
<li><code>关闭</code>状态：服务正常，并维护一个失败率统计，当失败率达到阀值时，转到<code>开启</code>状态</li>
<li><code>开启</code>状态：服务异常，调用 fallback 函数，一段时间之后，进入<code>半开启</code>状态</li>
<li><code>半开启</code>装态：尝试恢复服务，失败率高于阀值，进入<code>开启</code>状态，低于阀值，进入<code>关闭</code>状态</li>
</ul>
<p><code>github.com/afex/hystrix-go</code>，提供了 go 熔断器实现，使用上面也很方便，首先创建一个熔断器</p>
<pre><code class="go">hystrix.ConfigureCommand(
    &quot;addservice&quot;, // 熔断器名字，可以用服务名称命名，一个名字对应一个熔断器，对应一份熔断策略
    hystrix.CommandConfig{
        Timeout:                100,  // 超时时间 100ms
        MaxConcurrentRequests:  2,    // 最大并发数，超过并发返回错误
        RequestVolumeThreshold: 4,    // 请求数量的阀值，用这些数量的请求来计算阀值
        ErrorPercentThreshold:  25,   // 错误率阀值，达到阀值，启动熔断，25%
        SleepWindow:            1000, // 熔断尝试恢复时间，1000ms
    },
)
</code></pre>
<p>提供了阻塞和非阻塞两种使用方式，完整代码可以参考如下链接: <a href="https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/cmd/client/main.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/cmd/client/main.go</a></p>
<p>阻塞使用 <code>Do</code> 方法，返回一个 err</p>
<pre><code class="go">err := hystrix.Do(&quot;addservice&quot;, func() error {
    // 正常业务逻辑，一般是访问其他资源
    var err error
    // 设置总体超时时间 10 ms 超时
    ctx, cancel := context.WithTimeout(context.Background(), time.Duration(50*time.Millisecond))
    defer cancel()
    res, err = client.Add(
        ctx, req,
        // 这里可以再次设置重试次数，重试时间，重试返回码
        grpc_retry.WithMax(3),
        grpc_retry.WithPerRetryTimeout(time.Duration(5)*time.Millisecond),
        grpc_retry.WithCodes(codes.DeadlineExceeded),
    )
    return err
}, func(err error) error {
    // 失败处理逻辑，访问其他资源失败时，或者处于熔断开启状态时，会调用这段逻辑
    // 可以简单构造一个response返回，也可以有一定的策略，比如访问备份资源
    // 也可以直接返回 err，这样不用和远端失败的资源通信，防止雪崩
    // 这里因为我们的场景太简单，所以我们可以在本地在作一个加法就可以了
    fmt.Println(err)
    res = &amp;addservice.AddResponse{V: req.A + req.B}
    return nil
})
</code></pre>
<p>非阻塞方法使用 <code>Go</code> 方法，返回一个 error 的 channel，建议在有多个资源需要并发访问的场景下是使用</p>
<pre><code class="go">errc1 := hystrix.Go(&quot;addservice&quot;, func() error {
    var err error
    ctx, cancel := context.WithTimeout(context.Background(), time.Duration(50*time.Millisecond))
    defer cancel()
    res1, err = client.Add(ctx, req)
    if err == nil {
        success &lt;- struct{}{}
    }
    return err
}, nil)

// 有 fallback 处理
errc2 := hystrix.Go(&quot;addservice&quot;, func() error {
    var err error
    ctx, cancel := context.WithTimeout(context.Background(), time.Duration(50*time.Millisecond))
    defer cancel()
    res2, err = client.Add(ctx, req)
    if err == nil {
        success &lt;- struct{}{}
    }
    return err
}, func(err error) error {
    fmt.Println(err)
    res2 = &amp;addservice.AddResponse{V: req.A + req.B}
    success &lt;- struct{}{}
    return nil
})

for i := 0; i &lt; 2; i++ {
    select {
    case &lt;-success:
        fmt.Println(&quot;success&quot;, i)
    case err := &lt;-errc1:
        fmt.Println(&quot;err1:&quot;, err)
    case err := &lt;-errc2:
        // 这个分支永远不会走到，因为熔断机制里面永远不会返回错误
        fmt.Println(&quot;err2:&quot;, err)
    }
}
</code></pre>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>测试代码: <a href="https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/cmd/client/main.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/sample/addservice/cmd/client/main.go</a></li>
<li>Circuit Breaker Pattern: <a href="https://docs.microsoft.com/en-us/previous-versions/msp-n-p/dn589784(v%3dpandp.10)" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/previous-versions/msp-n-p/dn589784(v%3dpandp.10)</a></li>
<li>hystrix-go: <a href="https://github.com/afex/hystrix-go/" target="_blank" rel="noopener">https://github.com/afex/hystrix-go/</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 微服务 </tag>
            
            <tag> 限流器 </tag>
            
            <tag> 熔断器 </tag>
            
            <tag> ratelimiter </tag>
            
            <tag> circuitbreaker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 面向对象特性]]></title>
      <url>/2018/06/19/golang-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%89%B9%E6%80%A7/</url>
      <content type="html"><![CDATA[<p>和其他高级语言一样，golang 也支持面向对象编程，支持得比较简单，有些特性并不支持，但是够用了</p>
<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>接口使用 interface 关键字声明，任何实现接口定义方法的类都可以实例化该接口，接口和实现类之间没有任何依赖，你可以实现一个新的类当做 Sayer 来使用，而不需要依赖 Sayer 接口，也可以为已有的类创建一个新的接口，而不需要修改任何已有的代码，和其他静态语言相比，这可以算是 golang 的特色了吧</p>
<pre><code class="go">type Sayer interface {
    Say(message string)
    SayHi()
}
</code></pre>
<h3 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h3><p>继承使用组合的方式实现</p>
<pre><code class="go">type Animal struct {
    Name string
}

func (a *Animal) Say(message string) {
    fmt.Printf(&quot;Animal[%v] say: %v\n&quot;, a.Name, message)
}

type Dog struct {
    Animal
}
</code></pre>
<p>Dog 将继承 Animal 的 Say 方法，以及其成员 Name</p>
<h3 id="覆盖"><a href="#覆盖" class="headerlink" title="覆盖"></a>覆盖</h3><p>子类可以重新实现父类的方法</p>
<pre><code class="go">// override Animal.Say
func (d *Dog) Say(message string) {
    fmt.Printf(&quot;Dog[%v] say: %v\n&quot;, d.Name, message)
}
</code></pre>
<p>Dog.Say 将覆盖 Animal.Say</p>
<h3 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h3><p>接口可以用任何实现该接口的指针来实例化</p>
<pre><code class="go">var sayer Sayer

sayer = &amp;Dog{Animal{Name: &quot;Yoda&quot;}}
sayer.Say(&quot;hello world&quot;)
</code></pre>
<p>但是不支持父类指针指向子类，下面这种写法是不允许的</p>
<pre><code class="go">var animal *Animal
animal = &amp;Dog{Animal{Name: &quot;Yoda&quot;}}
</code></pre>
<p>同样子类继承的父类的方法引用的父类的其他方法也没有多态特性</p>
<pre><code class="go">func (a *Animal) Say(message string) {
    fmt.Printf(&quot;Animal[%v] say: %v\n&quot;, a.Name, message)
}

func (a *Animal) SayHi() {
    a.Say(&quot;Hi&quot;)
}

func (d *Dog) Say(message string) {
    fmt.Printf(&quot;Dog[%v] say: %v\n&quot;, d.Name, message)
}

func main() {
    var sayer Sayer

    sayer = &amp;Dog{Animal{Name: &quot;Yoda&quot;}}
    sayer.Say(&quot;hello world&quot;)  // Dog[Yoda] say: hello world
    sayer.SayHi()             // Animal[Yoda] say: Hi
}
</code></pre>
<p>上面这段代码中，子类 Dog 没有实现 SayHi 方法，调用的是从父类 Animal.SayHi，而 Animal.SayHi 调用的是 Animal.Say 而不是Dog.Say，这一点和其他面向对象语言有所区别，需要特别注意，但是可以用下面的方式来实现类似的功能，以提高代码的复用性</p>
<pre><code class="go">func SayHi(s Sayer) {
    s.Say(&quot;Hi&quot;)
}

type Cat struct {
    Animal
}

func (c *Cat) Say(message string) {
    fmt.Printf(&quot;Cat[%v] say: %v\n&quot;, c.Name, message)
}

func (c *Cat) SayHi() {
    SayHi(c)
}

func main() {
    var sayer Sayer

    sayer = &amp;Cat{Animal{Name: &quot;Jerry&quot;}}
    sayer.Say(&quot;hello world&quot;) // Cat[Jerry] say: hello world
    sayer.SayHi()            // Cat[Jerry] say: Hi
}
</code></pre>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>完整代码参考: <a href="https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/object_oriented_test.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/object_oriented_test.go</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 面向对象 </tag>
            
            <tag> 接口 </tag>
            
            <tag> 继承 </tag>
            
            <tag> 多态 </tag>
            
            <tag> 组合 </tag>
            
            <tag> 覆盖 </tag>
            
            <tag> interface </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[aerospike 集群搭建]]></title>
      <url>/2018/06/02/aerospike-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>aerospike 是一个分布式的 kv 存储服务，与 redis，memcached 等相比，最大的特点是支持内存和磁盘的混合存储，并且对 ssd 的支<br>持非常好，将索引存在内存中，数据存在 ssd 中，保持极高性能的同时，能有效的节约成本</p>
<h3 id="单机安装"><a href="#单机安装" class="headerlink" title="单机安装"></a>单机安装</h3><p>安装</p>
<pre><code>wget -O aerospike.tgz &#39;https://www.aerospike.com/download/server/latest/artifact/el6&#39;
tar -xvf aerospike.tgz
cd aerospike-server-community-*-el6
sudo ./asinstall
</code></pre><p>启动</p>
<pre><code>sudo service aerospike start
</code></pre><p>查看日志</p>
<pre><code>tail -f /var/log/aerospike/aerospike.log
</code></pre><h3 id="集群安装"><a href="#集群安装" class="headerlink" title="集群安装"></a>集群安装</h3><p>首先用上面的步骤在每个节点安装 aerospike，再修改配置文件 <code>/etc/aerospike/aerospike.conf</code>，添加集群的地址列表，启动服务即可</p>
<p>下面是一个配置文件样例</p>
<pre><code>service {
    user root
    group root
    paxos-single-replica-limit 1
    pidfile /var/run/aerospike/asd.pid
    proto-fd-max 15000
}

logging {
    file /var/log/aerospike/aerospike.log {
        context any info
    }
}

network {
    service {
        address 0.0.0.0
        port 3000
        # add current node address here
        access-address 172.31.25.40 3002
    }

    heartbeat {
        mode mesh
        # add current node address here        
        address 172.31.25.40
        port 3002
        # add all cluster node address here
        mesh-seed-address-port 172.31.25.40 3002
        mesh-seed-address-port 172.31.23.48 3002
        mesh-seed-address-port 172.31.19.27 3002
        interval 150
        timeout 10
    }

    fabric {
        address any
        port 3001
    }

    info {
        address any
        port 3003
    }
}

namespace test {
    memory-size 8G
    storage-engine memory
}
</code></pre><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>Install on Red Hat: <a href="https://www.aerospike.com/docs/operations/install/linux/el6" target="_blank" rel="noopener">https://www.aerospike.com/docs/operations/install/linux/el6</a></li>
<li>Network Heartbeat: <a href="https://www.aerospike.com/docs/operations/configure/network/heartbeat/index.html" target="_blank" rel="noopener">https://www.aerospike.com/docs/operations/configure/network/heartbeat/index.html</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> aerospike </tag>
            
            <tag> kv存储 </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[cmake 的正确打开方式]]></title>
      <url>/2018/05/30/cmake-%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%89%93%E5%BC%80%E6%96%B9%E5%BC%8F/</url>
      <content type="html"><![CDATA[<p>用了那么多年 c++，今天才搞明白 cmake 该怎么用……</p>
<p>cmake 是一个跨平台的 c++ 构建工具，与 makefile 类似，但是 makefile 更关注依赖，cmake 更关注构建本身，所以语法上要比makefile 要简洁清晰一些，而最近发现 cmake 原来还自带了依赖管理的功能，瞬间觉得之前的用法都太低级了……</p>
<h3 id="依赖管理"><a href="#依赖管理" class="headerlink" title="依赖管理"></a>依赖管理</h3><pre><code>include(ExternalProject)

add_custom_target(third)

ExternalProject_Add(
    google_gtest
    URL https://github.com/google/googletest/archive/release-1.8.0.zip
    PREFIX ${DMP_CLIENT_SOURCE_DIR}/third/gtest
    CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=${DMP_CLIENT_SOURCE_DIR}/third/gtest/build -DBUILD_SHARED_LIBS=OFF
)
add_dependencies(third google_gtest)
</code></pre><p>上面这段代码就可以自动下载 <code>gtest</code> 依赖到本地的 <code>third/gtest/</code> 目录，并安装在 <code>third/gtest/build</code> 下，这个目录下面将有两个目录， <code>include</code> 头文件以及 <code>lib</code> 库文件</p>
<p>这里核心的命令是 ExternalProject_Add，功能很强大，支持不同的地址去获取依赖，可以是打包文件的 <code>URL</code>，比如 github 上的某个项目的 tag，或者像 boost 这种，在官网提供的下载链接，也可以直接是 <code>GIT_REPOSITORY</code>，一般建议直接使用打包的 tag，因为比较快，而且有固定的 tag，比较好做版本管理，但是有些项目引用了外部项目需要执行 <code>git submodule update --init</code>，这种就比较适合用 git 地址，会自动下载依赖模块</p>
<p>另外就是编译这个过程，如果是标准的使用 cmake 构建的项目，基本不需要额外的配置，会自动编译，我一般习惯设置一个编译后的 install 目录，可以通过 <code>CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=${DMP_CLIENT_SOURCE_DIR}/third/gtest/build</code> 设置 cmake 的参数来实现，还有一些直接使用 makefile 构建的项目，需要自己去配置这个构建的过程，还有就是像 boost 这种，自己搞了工具，反正基本上每个库都会有些不一样，都会有些小问题需要解决，还是挺麻烦的，但是多了之后也都是一样的套路</p>
<p>总结一下就是这个功能有，但是使用起来还是挺麻烦的，也有人为了简化这种配置，基于这个功能整了一个 cpm，可惜现在已经不再维护了，而且里面很多库也都找不到</p>
<p>在发现这个依赖管理之前，我们是通过 shell 脚本来下载依赖的，虽然丑陋一点，但也基本能解决依赖的问题，相比之下，这种方式统一在了 <code>CMakeLists.txt</code> 里面，可读性上会更好一些，使用上面编译安装的命令都统一了，不需要执行额外的脚本，也会更方便一些</p>
<p>但是依旧很丑陋……可能历史的包袱太重吧，各种各样的库，五花八门的构建方式，cmake 能做到这样已经很不错了</p>
<h3 id="添加头文件目录和库搜索目录"><a href="#添加头文件目录和库搜索目录" class="headerlink" title="添加头文件目录和库搜索目录"></a>添加头文件目录和库搜索目录</h3><pre><code>include_directories(
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/gtest/build/include&quot;    
)

link_directories(
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/gtest/build/lib&quot;
)
</code></pre><p>这样我们就能使用刚刚下载的 gtest 依赖了</p>
<h3 id="生成-proto-代码"><a href="#生成-proto-代码" class="headerlink" title="生成 proto 代码"></a>生成 proto 代码</h3><pre><code>add_custom_command(
    OUTPUT ${DMP_CLIENT_SOURCE_DIR}/proto/dmpval_pb_message.pb.cc ${DMP_CLIENT_SOURCE_DIR}/proto/dmpval_pb_message.pb.h
    DEPENDS ${DMP_CLIENT_SOURCE_DIR}/proto/dmpval_pb_message.proto
    COMMAND ${DMP_CLIENT_SOURCE_DIR}/third/protobuf/build/bin/protoc -I. --cpp_out=. dmpval_pb_message.proto
    WORKING_DIRECTORY ${DMP_CLIENT_SOURCE_DIR}/proto
)
add_custom_target(
    pbout
    DEPENDS ${DMP_CLIENT_SOURCE_DIR}/proto/dmpval_pb_message.pb.cc
)
add_dependencies(pbout third)
</code></pre><p>add_custom_command 可以执行自定义的命令，然后再使用 add_custom_target 生成一个 pbout 的目标供下面的可执行程序依赖</p>
<h3 id="添加可执行文件"><a href="#添加可执行文件" class="headerlink" title="添加可执行文件"></a>添加可执行文件</h3><pre><code>add_executable(test_dmpkey test/dmpkey_test.cpp ${dmpkey_source})
add_dependencies(test_dmpkey third pbout)
target_link_libraries(
    test_dmpkey
    gtest
    murmur3
    pthread
)
</code></pre><p>使用代码文件生成一个测试的可执行程序 <code>test_dmpkey</code>，并让这个可执行程序依赖第三方依赖 <code>third</code> 和我们的 proto 编译结果 <code>pbout</code></p>
<h3 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h3><pre><code>enable_testing()
add_test(NAME dmpkey_test COMMAND test_dmpkey)
add_test(NAME dmpval_test COMMAND test_dmpval)
</code></pre><p>增加单元测试比较容易，使用 add_test 命令，在 COMMAND 后面添加需要执行的测试命令即可，添加后就可以使用 <code>make test</code> 执行单测了</p>
<h3 id="make-install"><a href="#make-install" class="headerlink" title="make install"></a>make install</h3><pre><code>install(TARGETS dmpclient DESTINATION lib)
install(DIRECTORY ${DMP_CLIENT_SOURCE_DIR}/include/datasource DESTINATION include/dmpclient)
</code></pre><p>install 更简单，指定源和目标即可</p>
<h3 id="CMakeLists-txt-参考代码"><a href="#CMakeLists-txt-参考代码" class="headerlink" title="CMakeLists.txt 参考代码"></a>CMakeLists.txt 参考代码</h3><pre><code>cmake_minimum_required(VERSION 2.8.7 FATAL_ERROR)
project(DMP_CLIENT)

find_package(Threads REQUIRED)
include(ExternalProject)

add_custom_target(third)

ExternalProject_Add(
    google_gtest
    URL https://github.com/google/googletest/archive/release-1.8.0.zip
    PREFIX ${DMP_CLIENT_SOURCE_DIR}/third/gtest
    CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=${DMP_CLIENT_SOURCE_DIR}/third/gtest/build -DBUILD_SHARED_LIBS=OFF
)
add_dependencies(third google_gtest)

ExternalProject_Add(
    google_protobuf
    URL https://github.com/google/protobuf/archive/v3.5.2.zip
    PREFIX ${DMP_CLIENT_SOURCE_DIR}/third/protobuf
    BUILD_IN_SOURCE true
    CONFIGURE_COMMAND &quot;&quot;
    BUILD_COMMAND sh autogen.sh &amp;&amp; ./configure --prefix=${DMP_CLIENT_SOURCE_DIR}/third/protobuf/build --disable-shared &amp;&amp; make -j8
    INSTALL_COMMAND make install
)
add_dependencies(third google_protobuf)

ExternalProject_Add(
    boostorg_boost
    URL https://dl.bintray.com/boostorg/release/1.67.0/source/boost_1_67_0.tar.gz
    PREFIX ${DMP_CLIENT_SOURCE_DIR}/third/boost
    BUILD_IN_SOURCE true
    CONFIGURE_COMMAND &quot;&quot;
    BUILD_COMMAND sh bootstrap.sh &amp;&amp; ./b2 link=static -j8
    INSTALL_COMMAND ./b2 install --prefix=${DMP_CLIENT_SOURCE_DIR}/third/boost/build
)
add_dependencies(third boostorg_boost)

ExternalProject_Add(
    peterscott_murmur3
    URL https://github.com/PeterScott/murmur3/archive/master.zip
    PREFIX ${DMP_CLIENT_SOURCE_DIR}/third/murmur3
    BUILD_IN_SOURCE true
    CONFIGURE_COMMAND &quot;&quot;
    BUILD_COMMAND gcc -c murmur3.c &amp;&amp; ar rcs libmurmur3.a murmur3.o
    INSTALL_COMMAND mkdir -p ../../build/{include,lib} &amp;&amp; cp murmur3.h ../../build/include &amp;&amp; cp libmurmur3.a ../../build/lib
)
add_dependencies(third peterscott_murmur3)

ExternalProject_Add(
    vipshop_hiredis_vip
    URL https://github.com/vipshop/hiredis-vip/archive/0.3.0.zip
    PREFIX ${DMP_CLIENT_SOURCE_DIR}/third/hiredis-vip
    BUILD_IN_SOURCE true
    CONFIGURE_COMMAND &quot;&quot;
    BUILD_COMMAND make
    INSTALL_COMMAND PREFIX=${DMP_CLIENT_SOURCE_DIR}/third/hiredis-vip/build make install
    COMMAND rm -rf ${DMP_CLIENT_SOURCE_DIR}/third/hiredis-vip/build/lib/*.dylib
)
add_dependencies(third vipshop_hiredis_vip)

ExternalProject_Add(
    aerospike_aerospike_client_c
    GIT_REPOSITORY git@github.com:aerospike/aerospike-client-c.git
    PREFIX ${DMP_CLIENT_SOURCE_DIR}/third/aerospike-client-c
    BUILD_IN_SOURCE true
    CONFIGURE_COMMAND &quot;&quot;
    BUILD_COMMAND make
    INSTALL_COMMAND ls target | xargs -I {} cp -r target/{}/ ${DMP_CLIENT_SOURCE_DIR}/third/aerospike-client-c/build
    COMMAND rm -rf ${DMP_CLIENT_SOURCE_DIR}/third/aerospike-client-c/build/lib/libaerospike.dylib
)
add_dependencies(third aerospike_aerospike_client_c)

ExternalProject_Add(
    nlohmann_json
    URL https://github.com/nlohmann/json/archive/v3.1.2.zip
    PREFIX ${DMP_CLIENT_SOURCE_DIR}/third/json
    CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=${DMP_CLIENT_SOURCE_DIR}/third/json/build -DBUILD_SHARED_LIBS=OFF
)
add_dependencies(third nlohmann_json)

set(CMAKE_CXX_FLAGS &quot;-std=c++11 -O2 -g&quot;)

# generate proto struct
add_custom_command(
    OUTPUT ${DMP_CLIENT_SOURCE_DIR}/proto/dmpval_pb_message.pb.cc ${DMP_CLIENT_SOURCE_DIR}/proto/dmpval_pb_message.pb.h
    DEPENDS ${DMP_CLIENT_SOURCE_DIR}/proto/dmpval_pb_message.proto
    COMMAND ${DMP_CLIENT_SOURCE_DIR}/third/protobuf/build/bin/protoc -I. --cpp_out=. dmpval_pb_message.proto
    WORKING_DIRECTORY ${DMP_CLIENT_SOURCE_DIR}/proto
)
add_custom_target(
    pbout
    DEPENDS ${DMP_CLIENT_SOURCE_DIR}/proto/dmpval_pb_message.pb.cc
)
add_dependencies(pbout third)

include_directories(
    &quot;${DMP_CLIENT_SOURCE_DIR}/include&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/proto&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/boost/build/include&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/murmur3/build/include&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/gtest/build/include&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/protobuf/build/include&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/hiredis-vip/build/include&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/aerospike-client-c/build/include&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/json/build/include&quot;
)

link_directories(
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/gtest/build/lib&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/protobuf/build/lib&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/murmur3/build/lib&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/hiredis-vip/build/lib&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/aerospike-client-c/build/lib&quot;
    &quot;${DMP_CLIENT_SOURCE_DIR}/third/json/build/lib&quot;
)

aux_source_directory(src/dmpkey dmpkey_source)
aux_source_directory(src/dmpval dmpval_source)
aux_source_directory(src/datasource datasource_source)
aux_source_directory(src/dmpclient dmpclient_source)
set(proto_source proto/dmpval_pb_message.pb.cc)
set(all_source ${dmpkey_source} ${dmpval_source} ${datasource_source} ${dmpclient_source} ${proto_source})

add_executable(test_dmpkey test/dmpkey_test.cpp ${dmpkey_source})
add_dependencies(test_dmpkey third pbout)
target_link_libraries(
    test_dmpkey
    gtest
    murmur3
    pthread
)

add_executable(test_dmpval test/dmpval_test.cpp ${dmpval_source} ${proto_source})
add_dependencies(test_dmpval third pbout)
target_link_libraries(
    test_dmpval
    gtest
    protobuf
    pthread
)

add_executable(test_redis_string test/redis_string_test.cpp src/datasource/redis_string.cpp)
add_dependencies(test_redis_string third pbout)
target_link_libraries(
    test_redis_string
    gtest
    hiredis_vip
    pthread
)

add_executable(test_aerospike test/aerospike_test.cpp src/datasource/aerospike.cpp)
add_dependencies(test_aerospike third pbout)
target_link_libraries(
    test_aerospike
    gtest
    pthread
    aerospike
    ssl
    crypto
    z
)

add_executable(test_dmpclient test/dmpclient_test.cpp ${all_source})
add_dependencies(test_dmpclient third pbout)
target_link_libraries(
    test_dmpclient
    gtest
    hiredis_vip
    aerospike
    ssl
    crypto
    z
    protobuf
    murmur3
    pthread
)

enable_testing()
add_test(NAME dmpkey_test COMMAND test_dmpkey)
add_test(NAME dmpval_test COMMAND test_dmpval)
add_test(NAME redis_string_test COMMAND test_redis_string)
add_test(NAME aerospike_test COMMAND test_aerospike)
add_test(NAME dmpclient_test COMMAND test_dmpclient)

add_library(dmpclient STATIC ${all_source})
add_dependencies(dmpclient third pbout)

install(TARGETS dmpclient DESTINATION lib)
install(DIRECTORY ${DMP_CLIENT_SOURCE_DIR}/include/datasource DESTINATION include/dmpclient)
install(DIRECTORY ${DMP_CLIENT_SOURCE_DIR}/include/localcache DESTINATION include/dmpclient)
install(DIRECTORY ${DMP_CLIENT_SOURCE_DIR}/include/dmpclient DESTINATION include/dmpclient)
install(DIRECTORY ${DMP_CLIENT_SOURCE_DIR}/include/dmpkey DESTINATION include/dmpclient)
install(DIRECTORY ${DMP_CLIENT_SOURCE_DIR}/include/dmpval DESTINATION include/dmpclient)
</code></pre><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>cmake 官方文档：<a href="https://cmake.org/cmake/help/v3.11/manual/cmake-commands.7.html" target="_blank" rel="noopener">https://cmake.org/cmake/help/v3.11/manual/cmake-commands.7.html</a></li>
<li>ExternalProject：<a href="https://cmake.org/cmake/help/v3.11/module/ExternalProject.html" target="_blank" rel="noopener">https://cmake.org/cmake/help/v3.11/module/ExternalProject.html</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> c++ </tag>
            
            <tag> cmake </tag>
            
            <tag> cmakelists.txt </tag>
            
            <tag> 构建工具 </tag>
            
            <tag> 单元测试 </tag>
            
            <tag> 依赖管理 </tag>
            
            <tag> makefile </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux 日志管理服务 logrotate]]></title>
      <url>/2018/04/16/linux-%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1-logrotate/</url>
      <content type="html"><![CDATA[<p>logrotate 是操作系统用来管理日志的工具，支持日志的切割、压缩、清理以及邮件报警等，通过 crontab 服务定时运行，也可以用这个工具来管理我们自己的服务日志，只需要简单配置下配置文件即可</p>
<h3 id="logrotate-配置"><a href="#logrotate-配置" class="headerlink" title="logrotate 配置"></a>logrotate 配置</h3><p><code>helloworld.conf</code>，多份日志可以直接写在一个配置文件里面，也可以分成多个文件 <code>include</code> 进来</p>
<pre><code>/path/to/log/hello.log
/path/to/log/world.err
{
    hourly
    rotate 24
    notifempty
    nocompress
    missingok
    copytruncate
    dateext
    dateformat .%Y%m%d%H
    olddir /path/to/log/bk/
    postrotate
        echo &quot;update to aws s3&quot;
    endscript
}
</code></pre><ul>
<li><code>hourly</code>: 日志切割按照小时来切割，logrotate 3.9.0 以后版本才支持，但是其实真正的调度是在 crontab 里面配置的</li>
<li><code>rotate</code>: 保留多少个历史文件</li>
<li><code>notifempty</code>: 如果文件为空，则不切分文件，默认是 <code>ifempty</code></li>
<li><code>nocompress</code>: 不压缩文件</li>
<li><code>missingok</code>: 忽略文件缺失信息</li>
<li><code>copytruncate</code>: 创建一个日志的拷贝，并且截断老的日志，适合那种一直写一个文件，也不关闭的服务。由于这个阶段的过程会有一小段时间，可能会有数据丢失</li>
<li><code>dateext</code>: 使用日期后缀</li>
<li><code>dateformat</code>: 日期后缀的格式</li>
<li><code>olddir</code>: 备份目录</li>
<li><code>postrotate/endscript</code>: 切割后执行的命令，这个选项非常灵活，可以实现一些强大的功能，比如日志上传，日志分析等等</li>
</ul>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>直接执行 <code>logrotate -f helloworld.conf</code> 可以强制执行切割，测试是否生效</p>
<h3 id="加入到-crontab"><a href="#加入到-crontab" class="headerlink" title="加入到 crontab"></a>加入到 crontab</h3><p>上面测试没有问题之后，<code>crontab -e</code> 加入到 crontab 里面即可</p>
<pre><code>59 * * * * /path/to/logrotate /path/to/helloworld.conf &gt;/dev/null 2&gt;&amp;1
</code></pre><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>logrotate man: <a href="https://linux.die.net/man/8/logrotate" target="_blank" rel="noopener">https://linux.die.net/man/8/logrotate</a></li>
<li>logrotate 日期后缀支持小时: <a href="https://stackoverflow.com/questions/31132995/logrotate-dateformat-seems-not-supporting-hms" target="_blank" rel="noopener">https://stackoverflow.com/questions/31132995/logrotate-dateformat-seems-not-supporting-hms</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> linux </tag>
            
            <tag> logrotate </tag>
            
            <tag> 日志 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[logstash mysql 准实时同步到 elasticsearch]]></title>
      <url>/2018/04/14/logstash-mysql-%E5%87%86%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E5%88%B0-elasticsearch/</url>
      <content type="html"><![CDATA[<p>mysql 作为成熟稳定的数据持久化解决方案，广泛地应用在各种领域，但是在数据分析方面稍有不足，而 elasticsearch 作为数据分析领域的佼佼者，刚好可以弥补这项不足，而我们要做的只需要将 mysql 中的数据同步到 elasticsearch 中即可，而 logstash 刚好就可以支持，所有你需要做的只是写一个配置文件而已</p>
<h3 id="logstash-获取"><a href="#logstash-获取" class="headerlink" title="logstash 获取"></a>logstash 获取</h3><p>获取 logstash</p>
<pre><code>wget https://artifacts.elastic.co/downloads/logstash/logstash-6.2.3.zip
unzip logstash-6.2.3.zip &amp;&amp; cd logstash-6.2.3
</code></pre><p>安装 jdbc 和 elasticsearch 插件</p>
<pre><code>bin/logstash-plugin install logstash-input-jdbc
bin/logstash-plugin install logstash-output-elasticsearch
</code></pre><p>获取 jdbc mysql 驱动</p>
<pre><code>wget https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.46.zip
unzip mysql-connector-java-5.1.46.zip
</code></pre><h3 id="编写配置文件"><a href="#编写配置文件" class="headerlink" title="编写配置文件"></a>编写配置文件</h3><h4 id="logstash-input-jdbc"><a href="#logstash-input-jdbc" class="headerlink" title="logstash-input-jdbc"></a>logstash-input-jdbc</h4><p>使用 logstash-input-jdbc 插件读取 mysql 的数据，这个插件的工作原理比较简单，就是定时执行一个 sql，然后将 sql 执行的结果写入到流中，增量获取的方式没有通过 binlog 方式同步，而是用一个递增字段作为条件去查询，每次都记录当前查询的位置，由于递增的特性，只需要查询比当前大的记录即可获取这段时间内的全部增量，一般的递增字段有两种，<code>AUTO_INCREMENT</code> 的主键 <code>id</code> 和 <code>ON UPDATE CURRENT_TIMESTAMP</code> 的 <code>update_time</code> 字段，<code>id</code> 字段只适用于那种只有插入没有更新的表，<code>update_time</code> 更加通用一些，建议在 mysql 表设计的时候都增加一个 <code>update_time</code> 字段</p>
<pre><code class="ruby">input {
  jdbc {
    jdbc_driver_library =&gt; &quot;../mysql-connector-java-5.1.46/mysql-connector-java-5.1.46-bin.jar&quot;
    jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;
    jdbc_connection_string =&gt; &quot;jdbc:mysql://&lt;mysql_host&gt;:3306/rta&quot;
    jdbc_user =&gt; &quot;&lt;username&gt;&quot;
    jdbc_password =&gt; &quot;&lt;password&gt;&quot;
    schedule =&gt; &quot;* * * * *&quot;
    statement =&gt; &quot;SELECT * FROM table WHERE update_time &gt;= :sql_last_value&quot;
    use_column_value =&gt; true
    tracking_column_type =&gt; &quot;timestamp&quot;
    tracking_column =&gt; &quot;update_time&quot;
    last_run_metadata_path =&gt; &quot;syncpoint_table&quot;
  }
}
</code></pre>
<ul>
<li><code>jdbc_driver_library</code>: jdbc mysql 驱动的路径，在上一步中已经下载</li>
<li><code>jdbc_driver_class</code>: 驱动类的名字，mysql 填 <code>com.mysql.jdbc.Driver</code> 就好了</li>
<li><code>jdbc_connection_string</code>: mysql 地址</li>
<li><code>jdbc_user</code>: mysql 用户</li>
<li><code>jdbc_password</code>: mysql 密码</li>
<li><code>schedule</code>: 执行 sql 时机，类似 crontab 的调度</li>
<li><code>statement</code>: 要执行的 sql，以 “:” 开头是定义的变量，可以通过 parameters 来设置变量，这里的 <code>sql_last_value</code> 是内置的变量，表示上一次 sql 执行中 update_time 的值，这里 <code>update_time</code> 条件是 <code>&gt;=</code> 因为时间有可能相等，没有等号可能会漏掉一些增量</li>
<li><code>use_column_value</code>: 使用递增列的值</li>
<li><code>tracking_column_type</code>: 递增字段的类型，<code>numeric</code> 表示数值类型, <code>timestamp</code> 表示时间戳类型</li>
<li><code>tracking_column</code>: 递增字段的名称，这里使用 update_time 这一列，这列的类型是 <code>timestamp</code></li>
<li><code>last_run_metadata_path</code>: 同步点文件，这个文件记录了上次的同步点，重启时会读取这个文件，这个文件可以手动修改</li>
</ul>
<h4 id="logstash-output-elasticsearch"><a href="#logstash-output-elasticsearch" class="headerlink" title="logstash-output-elasticsearch"></a>logstash-output-elasticsearch</h4><pre><code class="ruby">output {
  elasticsearch {
    hosts =&gt; [&quot;172.31.22.165&quot;, &quot;172.31.17.241&quot;, &quot;172.31.30.84&quot;, &quot;172.31.18.178&quot;]
    user =&gt; &quot;&lt;user&gt;&quot;
    password =&gt; &quot;&lt;password&gt;&quot;
    index =&gt; &quot;table&quot;
    document_id =&gt; &quot;%{id}&quot;
  }
}
</code></pre>
<ul>
<li><code>hosts</code>: es 集群地址</li>
<li><code>user</code>: es 用户名</li>
<li><code>password</code>: es 密码</li>
<li><code>index</code>: 导入到 es 中的 index 名，这里我直接设置成了 mysql 表的名字</li>
<li><code>document_id</code>: 导入到 es 中的文档 id，这个需要设置成主键，否则同一条记录更新后在 es 中会出现两条记录，<code>%{id}</code> 表示引用 mysql 表中 <code>id</code> 字段的值</li>
</ul>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>把上面的代码保存到一个配置文件里面 <code>sync_table.cfg</code>，执行下面命令即可</p>
<pre><code>cd logstash-6.2.3 &amp;&amp; bin/logstash -f config/sync_table.cfg
</code></pre><p>如果成功了会在标准输出输出执行的 sql 语句</p>
<pre><code>[2018-04-14T18:12:00,278][INFO ][logstash.inputs.jdbc     ] (0.001011s) SELECT version()
[2018-04-14T18:12:00,284][INFO ][logstash.inputs.jdbc     ] (0.000723s) SELECT * FROM table WHERE update_time &gt; &#39;2018-04-14 17:55:00&#39;
</code></pre><h3 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h3><h4 id="多表同步"><a href="#多表同步" class="headerlink" title="多表同步"></a>多表同步</h4><p>一个 logstash 实例可以借助 pipelines 机制同步多个表，只需要写多个配置文件就可以了，假设我们有两个表 table1 和 table2，对应两个配置文件 <code>sync_table1.cfg</code> 和 <code>sync_table2.cfg</code></p>
<p>在 <code>config/pipelines.yml</code> 中配置</p>
<pre><code>- pipeline.id: table1
  path.config: &quot;config/sync_table1.cfg&quot;
- pipeline.id: table2
  path.config: &quot;config/sync_table2.cfg&quot;
</code></pre><p>直接 <code>bin/logstash</code> 启动即可</p>
<h4 id="timestamp-字段"><a href="#timestamp-字段" class="headerlink" title="@timestamp 字段"></a><code>@timestamp</code> 字段</h4><p>默认情况下 <code>@timestamp</code> 字段是 logstash-input-jdbc 添加的字段，默认是当前时间，这个字段在数据分析的时候非常有用，但是有时候我们希望使用数据中的某些字段来指定这个字段，这个时候可以使用 filter.date, 这个插件是专门用来设置 <code>@timestamp</code> 这个字段的</p>
<p>比如我有我希望用字段 <code>timeslice</code> 来表示 <code>@timestamp</code>，<code>timeslice</code> 是一个字符串，格式为 <code>%Y%m%d%H%M</code></p>
<pre><code class="ruby">filter {
  date {
    match =&gt; [ &quot;timeslice&quot;, &quot;yyyyMMddHHmm&quot; ]
    timezone =&gt; &quot;Asia/Shanghai&quot;
  }
}
</code></pre>
<p>把这一段配置加到 <code>sync_table.cfg</code> 中，现在 <code>@timestamp</code> 和 <code>timeslice</code> 一致了</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>logstash-input-jdbc 插件: <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html</a></li>
<li>logstash-output-elasticsearch 插件: <a href="https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html</a></li>
<li>logstash-multiple-piplines: <a href="https://www.elastic.co/blog/logstash-multiple-pipelines" target="_blank" rel="noopener">https://www.elastic.co/blog/logstash-multiple-pipelines</a></li>
<li>logstash-filter-date 插件: <a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-date.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/plugins-filters-date.html</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> elasticsearch </tag>
            
            <tag> mysql </tag>
            
            <tag> logstash </tag>
            
            <tag> 数据同步 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[elasticsearch + kibana 集群环境搭建]]></title>
      <url>/2018/04/12/elasticsearch-kibana-%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>elk 提供了完备且成熟的日志存储和分析的解决方案，免费开源，本文主要介绍 elasticsearch 集群以及 kibana 的环境搭建</p>
<h3 id="elasticsearch"><a href="#elasticsearch" class="headerlink" title="elasticsearch"></a>elasticsearch</h3><p>elasticsearch 可以理解为一个支持模糊查询的数据库，用来存储日志</p>
<h4 id="下载-elasticsearch"><a href="#下载-elasticsearch" class="headerlink" title="下载 elasticsearch"></a>下载 elasticsearch</h4><pre><code>wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.2.3.tar.gz
tar -xzvf elasticsearch-6.2.3.tar.gz
</code></pre><h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>修改 <code>config/elasticsearch.yml</code></p>
<pre><code>cluster.name: rlogger       # 集群名称，所有节点统一一个
node.name: node-2           # 节点名称，每个节点一个即可
network.host: 0.0.0.0       # 绑定的地址，设置成 0.0.0.0 表示接受来自任何地址的请求
http.port: 9200
discovery.zen.ping.unicast.hosts: [&quot;172.31.22.165&quot;, &quot;172.31.17.241&quot;, &quot;172.31.30.84&quot;, &quot;172.31.18.178&quot;]
discovery.zen.minimum_master_nodes: 3
</code></pre><p>如果需要修改 java 堆栈区大小，可以修改 <code>config/jvm.options</code></p>
<pre><code>-Xms8g
-Xmx8g
</code></pre><h4 id="启动-elasticsearch"><a href="#启动-elasticsearch" class="headerlink" title="启动 elasticsearch"></a>启动 elasticsearch</h4><pre><code>nohup bin/elasticsearch &amp;
</code></pre><p>节点之间的 9200 端口需要互通</p>
<h4 id="检查是否生效"><a href="#检查是否生效" class="headerlink" title="检查是否生效"></a>检查是否生效</h4><pre><code>curl -XGET &#39;http://172.31.17.241:9200/_cat/nodes?pretty&#39;
</code></pre><p>会有如下输出</p>
<pre><code>172.31.18.178 61 99 0 0.01 0.04 0.09 mdi - node-4
172.31.17.241 27 99 0 0.06 0.04 0.05 mdi - node-1
172.31.30.84  27 99 0 0.06 0.07 0.06 mdi - node-2
172.31.22.165 68 99 0 0.00 0.01 0.05 mdi * node-3
</code></pre><h3 id="kibana"><a href="#kibana" class="headerlink" title="kibana"></a>kibana</h3><p>kibana 通过一个 web 界面提供日志的检索分析功能，还可以绘制各种图表，非常方便</p>
<h4 id="下载-kibana"><a href="#下载-kibana" class="headerlink" title="下载 kibana"></a>下载 kibana</h4><pre><code>wget https://artifacts.elastic.co/downloads/kibana/kibana-6.2.3-linux-x86_64.tar.gz
tar -xzvf kibana-6.2.3-linux-x86_64.tar.gz
</code></pre><h4 id="修改配置文件-1"><a href="#修改配置文件-1" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>修改 <code>config/kibana.yml</code></p>
<pre><code>server.host: &quot;0.0.0.0&quot;      # 绑定的地址，设置成 0.0.0.0 表示接受来自任何地址的请求
elasticsearch.url: &quot;http://localhost:9200&quot;
</code></pre><p>由于我的 kibana 直接部署在 elasticsearch 节点机器上，所以这里 <code>elasticsearch.url</code> 配成默认的就行</p>
<h4 id="启动-kibana"><a href="#启动-kibana" class="headerlink" title="启动 kibana"></a>启动 kibana</h4><pre><code>nohup bin/kibana &amp;
</code></pre><p>注意开放 5601 端口</p>
<h4 id="检查是否生效-1"><a href="#检查是否生效-1" class="headerlink" title="检查是否生效"></a>检查是否生效</h4><p>在浏览器里面访问 <code>http://&lt;kibana ip&gt;:5601</code>，即可</p>
<p>到这里 elasticsearch + kibana 集群环境已经搭建完成了，下面这个 metricbeat 是机器基本指标的一些监控，在上面 kibana 地址的首页就有引导</p>
<h3 id="metricbeat"><a href="#metricbeat" class="headerlink" title="metricbeat"></a>metricbeat</h3><p>metricbeat 会自动收集一些机器指标发到 elasticsearch，并在 kibana 有可视化的图表展示</p>
<h4 id="下载-metricbeat"><a href="#下载-metricbeat" class="headerlink" title="下载 metricbeat"></a>下载 metricbeat</h4><pre><code>curl -L -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-6.2.3-x86_64.rpm
sudo rpm -vi metricbeat-6.2.3-x86_64.rpm
</code></pre><h4 id="修改配置文件-2"><a href="#修改配置文件-2" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>修改 <code>/etc/metricbeat/metricbeat.yml</code></p>
<pre><code>output.elasticsearch:
  hosts: [&quot;172.31.17.241:9200&quot;, &quot;172.31.30.84:9200&quot;, &quot;172.31.22.165:9200&quot;, &quot;172.31.18.178:9200&quot;]
setup.kibana:
  host: &quot;172.31.17.241:5601&quot;
</code></pre><h4 id="启动-metricbeat"><a href="#启动-metricbeat" class="headerlink" title="启动 metricbeat"></a>启动 metricbeat</h4><pre><code>sudo metricbeat modules enable system
sudo metricbeat setup
sudo service metricbeat start
</code></pre><h4 id="查看机器状态"><a href="#查看机器状态" class="headerlink" title="查看机器状态"></a>查看机器状态</h4><p>现在可以在 kibana 的 <code>Dashboard</code> 里面看到 <code>[Metricbeat System] Host overview</code>，点进去就可以看到 cpu 内存情况了</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>elasticsearch 下载: <a href="https://www.elastic.co/cn/downloads/elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/cn/downloads/elasticsearch</a></li>
<li>kibana 下载: <a href="https://www.elastic.co/cn/downloads/kibana" target="_blank" rel="noopener">https://www.elastic.co/cn/downloads/kibana</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> elasticsearch </tag>
            
            <tag> kibana </tag>
            
            <tag> 日志收集 </tag>
            
            <tag> 日志分析 </tag>
            
            <tag> 环境搭建 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 性能优化之累加哈希]]></title>
      <url>/2018/04/12/golang-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E7%B4%AF%E5%8A%A0%E5%93%88%E5%B8%8C/</url>
      <content type="html"><![CDATA[<p>很多时候性能问题总是发生在一些不起眼的地方。最近做一个性能问题分析的时候发现，一个函数里面使用由于字符串拼接产生的临时字符串导致内存上涨了40%（120G 内存的机器），而这些临时字符串给 GC 也带来了非常大的负担，成为主要的性能瓶颈，而这些字符串作为 map 的 key，又必须要拼接，所以想到了直接使用 hash 后的值作为 map 的 key，而这个 hash 值使用累加 hash 计算得出。</p>
<p>所谓累加 hash，就是对字符串的 hash 可以分为任意多段，对每一段连续 hash，结果累加，对于任意一种分段方式，最后能得到一致的 hash 结果，比如：<code>H.hash(&quot;hello world&quot;)</code>, <code>H.hash(&quot;hello&quot;).hash(&quot; &quot;).hash(&quot;world&quot;)</code>, <code>H.hash(&quot;hello wo&quot;).hash(&quot;rld)&quot;</code> 这些结果最后都应该是一致的，利用这个特性，就能做到对多个字符串哈希而不用拼接</p>
<h3 id="BKDR-hash-实现"><a href="#BKDR-hash-实现" class="headerlink" title="BKDR hash 实现"></a>BKDR hash 实现</h3><pre><code class="golang">type StringHasherBKDR uint64

// NewStringHasherBKDR 创建一个新的 Hasher
func NewStringHasherBKDR() StringHasherBKDR {
    return StringHasherBKDR(0)
}

// AddStr 增加一个字符串
func (bkdr StringHasherBKDR) AddStr(str string) StringHasherBKDR {
    val := uint64(bkdr)
    for i := 0; i &lt; len(str); i++ {
        val = val*131 + uint64(str[i])
    }
    return StringHasherBKDR(val)
}

// AddInt 添加一个 int 值
func (bkdr StringHasherBKDR) AddInt(i uint64) StringHasherBKDR {
    val := uint64(bkdr)
    val = val*131 + i
    return StringHasherBKDR(val)
}

// Val 转成 uint64 的值
func (bkdr StringHasherBKDR) Val() uint64 {
    return uint64(bkdr)
}
</code></pre>
<p>使用上也很简单</p>
<pre><code>hasher := NewStringHasherBKDR()
So(hasher.AddStr(&quot;hello world&quot;).Val(), ShouldEqual, hasher.AddStr(&quot;hello&quot;).AddStr(&quot; &quot;).AddStr(&quot;world&quot;).Val())
</code></pre><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>代码地址: <a href="https://github.com/hatlonely/easygolang/blob/master/hashopt/" target="_blank" rel="noopener">https://github.com/hatlonely/easygolang/blob/master/hashopt/</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 性能优化 </tag>
            
            <tag> hash </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 性能优化之 bitset 代替 hashset]]></title>
      <url>/2018/04/12/golang-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B-bitset-%E4%BB%A3%E6%9B%BF-hashset/</url>
      <content type="html"><![CDATA[<p>hashset 是一种非常高效的数据结构，插入和查询的复杂度都是 O(1)，基本上能满足大部分场景的性能需求，但在一些特殊的场景下，频次非常高的调用依然会成为性能瓶颈（用 pprof 分析），比如广告里面的定向逻辑，在一次请求中过滤逻辑可能会执行上千次，而其中有些过滤刚好都是一些枚举值，比如性别定向，年龄定向等等，对于这种可以用枚举表示的值可以用 bitset 优化，能有20多倍的性能提升</p>
<p>bitset 的本质也是一种 hashset，只不过哈希桶用一个 uint64 来表示了，uint64 中的每一位用来代表一个元素是否存在，如果为1表示存在，为0表示不存在，而插入和查询操作就变成了位运算</p>
<h3 id="bitset-实现"><a href="#bitset-实现" class="headerlink" title="bitset 实现"></a>bitset 实现</h3><p>bitset 的实现比较容易，下面这个是一个只支持枚举值不超过64的版本，当然也可以拓展到任意长度，使用一个 uint64 数组作为 hash 桶即可</p>
<pre><code class="golang">type BitSet struct {
    bit uint64
}

func (bs *BitSet) Add(i uint64) {
    bs.bit |= 1 &lt;&lt; i
}

func (bs *BitSet) Del(i uint64) {
    bs.bit &amp;= ^(1 &lt;&lt; i)
}

func (bs BitSet) Has(i uint64) bool {
    return bs.bit&amp;(1&lt;&lt;i) != 0
}
</code></pre>
<h3 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h3><pre><code class="golang">func BenchmarkSetContains(b *testing.B) {
    bitset := NewBitSet()
    hashset := map[uint64]struct{}{}
    for _, i := range []uint64{1, 2, 4, 10} {
        bitset.Add(i)
        hashset[i] = struct{}{}
    }

    b.Run(&quot;bitset&quot;, func(b *testing.B) {
        for i := 0; i &lt; b.N; i++ {
            for i := uint64(0); i &lt; uint64(10); i++ {
                _ = bitset.Has(i)
            }
        }
    })

    b.Run(&quot;hashset&quot;, func(b *testing.B) {
        for i := 0; i &lt; b.N; i++ {
            for i := uint64(0); i &lt; uint64(10); i++ {
                _, _ = hashset[i]
            }
        }
    })
}
</code></pre>
<pre><code>BenchmarkSetContains/bitset-8             500000000             3.81 ns/op           0 B/op           0 allocs/op
BenchmarkSetContains/hashset-8            20000000            89.4 ns/op           0 B/op           0 allocs/op
</code></pre><p>可以看到 bitset 相比 hashset 有20多倍的性能提升</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>代码地址：<a href="https://github.com/hatlonely/easygolang/blob/master/datastruct/bitset.go" target="_blank" rel="noopener">https://github.com/hatlonely/easygolang/blob/master/datastruct/bitset.go</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 性能优化 </tag>
            
            <tag> 数据结构 </tag>
            
            <tag> bitset </tag>
            
            <tag> hashset </tag>
            
            <tag> set </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 构建工具之 Makefile]]></title>
      <url>/2018/04/11/golang-%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7%E4%B9%8B-Makefile/</url>
      <content type="html"><![CDATA[<p>可能是因为编译太简单了，golang 并没有一个官方的构建工具（类似于 java 的 maven 和 gradle之类的），但是除了编译，我们可能还需要下载依赖，运行测试，甚至像 easyjson，protobuf，thrift 这样的工具下载和代码生成，如果没有构建工具，这些工作就会非常麻烦</p>
<p>为了解决这个问题，之前写过一个 <code>everything.sh</code> 的脚本，把所有的操作都封装在这个脚本里面，只需要执行类似于 <code>sh everything.sh dependency</code> 的命令就可以完成对应的工作，大大简化了构建过程，但是也有一个问题，shell 脚本本身的可读性并不是很好，而且对于各个操作之间的依赖不好描述</p>
<p>一次偶然的机会，在 github 上看到有人用 Makefile，就尝试了一下，发现真的非常合适，Makefile 本身就是用来描述依赖的，可读性非常好，而且与强大的 shell 结合在一起，基本可以实现任何想要的功能</p>
<p>下面是我在实际项目中使用的一个 Makefile，支持的功能包括</p>
<ul>
<li><code>make build</code>: 编译</li>
<li><code>make vendor</code>: 下载依赖</li>
<li><code>make api</code>: 生成协议代码</li>
<li><code>make json</code>: easyjson 代码生成</li>
<li><code>make test</code>: 运行单元测试</li>
<li><code>make benchmark</code>: 运行性能测试</li>
<li><code>make stat</code>: 代码复杂度统计，代码行数统计</li>
<li><code>make clean</code>: 清理 build 目录</li>
<li><code>make deep_clean</code>: 清理所有代码以外的其他文件</li>
<li><code>make third</code>: 下载所有依赖的第三方工具</li>
<li><code>make protoc</code>: 下载 protobuf 工具</li>
<li><code>make glide</code>: 下载 glide 依赖管理工具</li>
<li><code>make golang</code>: 下载 golang 环境</li>
<li><code>make cloc</code>: 下载 cloc 统计工具</li>
<li><code>make gocyclo</code>: 下载 gocyclo 圈复杂度计算工具</li>
<li><code>make easyjson</code>: 下载 easyjson 工具</li>
</ul>
<pre><code class="Makefile">export PATH:=${PATH}:${GOPATH}/bin:$(shell pwd)/third/go/bin:$(shell pwd)/third/protobuf/bin:$(shell pwd)/third/cloc-1.76

.PHONY: all
all: third vendor api json build test stat

build: cmd/rta_server/*.go internal/*/*.go scripts/version.sh Makefile vendor api json
    @echo &quot;编译&quot;
    @rm -rf build/ &amp;&amp; mkdir -p build/bin/ &amp;&amp; \
    go build -ldflags &quot;-X &#39;main.AppVersion=`sh scripts/version.sh`&#39;&quot; cmd/rta_server/main.go &amp;&amp; \
    mv main build/bin/rta_server &amp;&amp; \
    cp -r configs build/configs/

vendor: glide.lock glide.yaml
    @echo &quot;下载 golang 依赖&quot;
    glide install

api: vendor
    @echo &quot;生成协议文件&quot;
    @rm -rf api &amp;&amp; mkdir api &amp;&amp; \
    cd vendor/gitlab.mobvista.com/vta/rta_proto.git/ &amp;&amp; \
    protoc --go_out=plugins=grpc:. *.proto &amp;&amp; \
    cd - &amp;&amp; \
    cp vendor/gitlab.mobvista.com/vta/rta_proto.git/* api/

json: internal/rcommon/rta_common_easyjson.go

internal/rcommon/rta_common_easyjson.go: internal/rcommon/rta_common.go Makefile
    easyjson internal/rcommon/rta_common.go

.PHONY: test
test: vendor api json
    @echo &quot;运行单元测试&quot;
    go test -cover internal/rranker/*.go
    go test -cover internal/rserver/*.go
    go test -cover internal/rworker/*.go
    go test -cover internal/rloader/*.go
    go test -cover internal/rrecall/*.go
    go test -cover internal/rmaster/*.go
    go test -cover internal/rsender/*.go

benchmark: benchmarkloader benchmarkall

.PHONY: benchmarkloader
benchmarkloader: vendor api json
    @echo &quot;运行 loader 性能测试&quot;
    go test -timeout 2h -bench BenchmarkS3Loader_Load -benchmem -cpuprofile cpu.out -memprofile mem.out -run=^$$ internal/rloader/*
    go tool pprof -svg ./rloader.test cpu.out &gt; cpu.benchmarkloader.svg
    go tool pprof -svg ./rloader.test mem.out &gt; mem.benchmarkloader.svg

.PHONY: benchmarkserver
benchmarkserver: vendor api json
    @echo &quot;运行 server 性能测试&quot;
    go test -timeout 2h -bench BenchmarkServer -benchmem -cpuprofile cpu.out -memprofile mem.out -run=^$$ internal/rserver/*
    go tool pprof -svg ./rserver.test cpu.out &gt; cpu.benchmarkserver.svg
    go tool pprof -svg ./rserver.test mem.out &gt; mem.benchmarkserver.svg

.PHONY: benchmarkall
benchmarkall: vendor api json
    @echo &quot;运行 server 性能测试&quot;
    go test -timeout 2h -bench BenchmarkAll -benchmem -cpuprofile cpu.out -memprofile mem.out -run=^$$ internal/rserver/*
    go tool pprof -svg ./rserver.test cpu.out &gt; cpu.benchmarkall.svg    
    go tool pprof -svg ./rserver.test mem.out &gt; mem.benchmarkall.svg

.PHONY: benchmarkcache
benchmarkcache: vendor api json
    @echo &quot;测试 redis 集群性能&quot;
    go test -timeout 5m -bench BenchmarkRtaCacheBatch -benchmem -cpuprofile cpu.out -memprofile mem.out -run=^$$ internal/rserver/*

.PHONY: stat
stat: cloc gocyclo
    @echo &quot;代码行数统计&quot;
    @ls internal/*/* scripts/* configs/* Makefile | xargs cloc --by-file
    @echo &quot;圈复杂度统计&quot;
    @ls internal/*/* | grep -v _test | xargs gocyclo
    @ls internal/*/* | grep -v _test | xargs gocyclo | awk &#39;{sum+=$$1}END{printf(&quot;总圈复杂度: %s&quot;, sum)}&#39;

.PHONY: clean
clean:
    rm -rf build

.PHONY: deep_clean
deep_clean:
    rm -rf vendor api build third

third: protoc glide golang cloc gocyclo easyjson

.PHONY: protoc
protoc: golang
    @hash protoc 2&gt;/dev/null || { \
        echo &quot;安装 protobuf 代码生成工具 protoc&quot; &amp;&amp; \
        mkdir -p third &amp;&amp; cd third &amp;&amp; \
        wget https://github.com/google/protobuf/releases/download/v3.2.0/protobuf-cpp-3.2.0.tar.gz &amp;&amp; \
        tar -xzvf protobuf-cpp-3.2.0.tar.gz &amp;&amp; \
        cd protobuf-3.2.0 &amp;&amp; \
        ./configure --prefix=`pwd`/../protobuf &amp;&amp; \
        make -j8 &amp;&amp; \
        make install &amp;&amp; \
        cd ../.. &amp;&amp; \
        protoc --version; \
    }
    @hash protoc-gen-go 2&gt;/dev/null || { \
        echo &quot;安装 protobuf golang 插件 protoc-gen-go&quot; &amp;&amp; \
        go get -u github.com/golang/protobuf/{proto,protoc-gen-go}; \
    }

.PHONY: glide
glide: golang
    @mkdir -p $$GOPATH/bin
    @hash glide 2&gt;/dev/null || { \
        echo &quot;安装依赖管理工具 glide&quot; &amp;&amp; \
        curl https://glide.sh/get | sh; \
    }

.PHONY: golang
golang:
    @hash go 2&gt;/dev/null || { \
        echo &quot;安装 golang 环境 go1.10&quot; &amp;&amp; \
        mkdir -p third &amp;&amp; cd third &amp;&amp; \
        wget https://dl.google.com/go/go1.10.linux-amd64.tar.gz &amp;&amp; \
        tar -xzvf go1.10.linux-amd64.tar.gz &amp;&amp; \
        cd .. &amp;&amp; \
        go version; \
    }

.PHONY: cloc
cloc:
    @hash cloc 2&gt;/dev/null || { \
        echo &quot;安装代码统计工具 cloc&quot; &amp;&amp; \
        mkdir -p third &amp;&amp; cd third &amp;&amp; \
        wget https://github.com/AlDanial/cloc/archive/v1.76.zip &amp;&amp; \
        unzip v1.76.zip; \
    }

.PHONY: gocyclo
gocyclo: golang
    @hash gocyclo 2&gt;/dev/null || { \
        echo &quot;安装代码圈复杂度统计工具 gocyclo&quot; &amp;&amp; \
        go get -u github.com/fzipp/gocyclo; \
    }

.PHONY: easyjson
easyjson: golang
    @hash easyjson 2&gt;/dev/null || { \
        echo &quot;安装 json 编译工具 easyjson&quot; &amp;&amp; \
        go get -u github.com/mailru/easyjson/...; \
    }
</code></pre>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 构建工具 </tag>
            
            <tag> Makefile </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[gradle 开发语言 groovy 入门]]></title>
      <url>/2018/03/21/gradle-%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80-groovy-%E5%85%A5%E9%97%A8/</url>
      <content type="html"><![CDATA[<p>gradle 是 java 的构建工具的一种，同类的工具还有 maven，ant。我比较喜欢 gradle 主要是其语法简洁，而且功能强大。除此之外，还支持很多其他语言的构建</p>
<p>gradle 使用的是 groovy 开发，以前没有接触过这个语言，以后可能也不太会用，了解这个语言只是想看懂 <code>build.gradle</code> 这个脚本，以及后续能在此基础上作简单的拓展开发</p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>groovy 是基于 jvm 的语言，支持很多动态和静态两种模式，既可以用作脚本开发，也可以用来构建大型的服务，建立在强大的 java 生态之上，同时支持很多现代的语法特性，可以说是非常强大，使用上面也非常方便</p>
<h3 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h3><h4 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h4><pre><code class="groovy">assert &quot;hello world&quot;.contains(&quot;hello&quot;)
assert &quot;hello world&quot;.startsWith(&quot;hello&quot;)
assert &quot;hello world&quot;.endsWith(&quot;world&quot;)
assert &quot;0123456789&quot;.indexOf(&quot;678&quot;) == 6
assert &quot;0123456789&quot;.charAt(6) == &quot;6&quot;
assert &quot;0123456789&quot;.length() == 10
assert &quot;0123456789&quot;.substring(5) == &quot;56789&quot;
assert &quot;0123456789&quot;.substring(5, 8) == &quot;567&quot;

assert &quot;0123456789&quot;[6] == &quot;6&quot;
assert &quot;0123456789&quot;[6..8] == &quot;678&quot;
assert &quot;0123456789&quot;[2, 3, 7] == &quot;237&quot;
assert &quot;0123456789&quot;[1, 3..&lt;6, 8] == &quot;13458&quot;
assert &quot;0123456789&quot; == &quot;0123456789&quot;
assert &quot;0123456789&quot;.is(&quot;0123456789&quot;)
assert !&quot;&quot;
</code></pre>
<ul>
<li>字符串可以用双引号也可以用单引号，</li>
<li>可以直接调用 java 中的字符串方法</li>
<li>的函数调用的括号可以省略，如上面的 <code>assert</code> 函数</li>
<li>相比较 java，groovy 增加了很多运算符，如上面用到的 <code>==</code>, <code>[]</code>, <code>..</code>, <code>is</code> 等等</li>
<li>空字符串会被当做 false 处理，类似的，<code>0</code>，<code>null</code>，<code>[]</code> 也会被当做 false 处理</li>
</ul>
<h4 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h4><pre><code class="groovy">assert [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].contains(3)
assert 3 in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
assert [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].indexOf(6) == 6
assert [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].get(6) == 6
assert [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][6] == 6
assert [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][6, 8] == [6, 8]
assert [0, 1, 2, 3, 4, 5, 6, 7, 8, 9][6..8] == [6, 7, 8]
assert [[2, 3],[4, 5, 6]].combinations() == [[2, 4], [3, 4], [2, 5], [3, 5], [2, 6], [3, 6]]
assert [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].each { ++it } == [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
assert [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].collect { ++it } == [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

assert [&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3][&quot;b&quot;] == 2
assert &quot;a&quot; in [&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3]

[&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3].each {
    println(it.key + &quot; =&gt; &quot; + it.value)
}

def items = [4, 5]
def list = [1, 2, 3, *items, 6]
assert list == [1, 2, 3, 4, 5, 6]

def m1 = [c: 3, d: 4]
def map = [a: 1, b: 2, *:m1]
assert map == [a: 1, b: 2, c: 3, d: 4]
</code></pre>
<ul>
<li>相比 java，groovy 支持字面语法，定义 list 和 map 方便了很多</li>
<li>可以使用 def 定义变量，而无需显式的写明类型</li>
<li>可以用 <code>each</code> 实现循环遍历，实际上 each 的参数是一个闭包，闭包里面的 <code>it</code> 是个关键字，其实代表的是第一个参数</li>
<li>使用 <code>collect</code> 方法实现列表的转化</li>
</ul>
<h3 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h3><p>这个东西很有意思，简单理解就是一段代码，这段代码可以传入参数，也可以有上下文，这个东西也是一个对象，可以用来赋值，也可传递</p>
<pre><code class="groovy">def add = { a,b -&gt; a+b }
assert add(1, 2) == 3
assert add(&quot;a&quot;, &quot;b&quot;) == &quot;ab&quot;
</code></pre>
<p><code>{ a,b -&gt; a+b }</code> 这就是一个闭包，<code>a,b</code> 是传入的参数，如果不需要参数也可以省略，当只有一个参数的时候也可以省略，因为有个默认参数 <code>it</code>，<code>-&gt;</code> 后面是要执行的代码，如果没有显式地指定 return 语句，默认会以最后一个语句返回，这里返回值就是 <code>a+b</code>，因此这个闭包可以被用来当做 add 函数使用</p>
<pre><code class="groovy">def ncopies = {int n, String str -&gt; str*n}
def twice = ncopies.curry(2)    // curry 参数绑定
assert twice(&quot;bla&quot;) == ncopies(2, &quot;bla&quot;)
</code></pre>
<p>可以用 <code>curry</code> 绑定参数值</p>
<pre><code class="groovy">fib = { long n -&gt; n &lt; 2 ? n : fib(n-1)+fib(n-2) }.memoize()
assert fib(15) == 610
</code></pre>
<p>这还能自动帮你缓存递归的结果……感觉有点过分了……</p>
<pre><code class="groovy">def plus2  = { it + 2 }
def times3 = { it * 3 }
def times3plus2 = plus2 &lt;&lt; times3
assert times3plus2(3) == 11
assert times3plus2(4) == plus2(times3(4))
</code></pre>
<p>可以把多个闭包连起来组成新的闭包</p>
<pre><code class="groovy">class Thing1 {
    String name
}
class Thing2 {
    String name
}

def t1 = new Thing1(name: &#39;Norman&#39;)
def t2 = new Thing2(name: &#39;Teapot&#39;)
def upperCasedName = { delegate.name.toUpperCase() }
upperCasedName.delegate = t1
assert upperCasedName() == &#39;NORMAN&#39;
upperCasedName.delegate = t2
assert upperCasedName() == &#39;TEAPOT&#39;
</code></pre>
<p><strong>代理</strong>，我的理解是闭包运行的上下文，每个闭包都会有一个代理，默认是闭包本身（owner），这个代理可以设置成别的对象，然后就可以再闭包里面调用这个对象的方法了，<code>delegate</code> 也可以省略，<code>def upperCasedName = { name.toUpperCase() }</code> 也是可以的</p>
<p>仔细想想，就这个功能其实把 t1 当做参数传给 upperCaseName() 也是可以的，没必要整这么个复杂的概念，但是有意思的事情才刚刚开始，往下看你就知道了</p>
<h3 id="gradle-的-dependencies-原理"><a href="#gradle-的-dependencies-原理" class="headerlink" title="gradle 的 dependencies 原理"></a>gradle 的 dependencies 原理</h3><pre><code class="groovy">dependencies {
    testCompile group: &#39;junit&#39;, name: &#39;junit&#39;, version: &#39;4.11&#39;
    compile group: &#39;com.fasterxml.jackson.core&#39;, name: &#39;jackson-core&#39;, version: &#39;2.9.4&#39;
    compile group: &#39;com.fasterxml.jackson.core&#39;, name: &#39;jackson-databind&#39;, version: &#39;2.9.4&#39;
    compile group: &#39;com.fasterxml.jackson.core&#39;, name: &#39;jackson-annotations&#39;, version: &#39;2.9.4&#39;
}
</code></pre>
<p>在 <code>build.gradle</code> 里面有这么一段依赖管理的代码，那这段代码是怎么工作的呢，dependencies 看起来像是一个函数，而且参数是一个闭包，闭包里面有条语句，调用了几个函数，这些函数接受一个 Map 的参数，那这些函数在哪里呢，可以是全局的，也可以像下面这样，通过代理的方式传进去</p>
<pre><code class="groovy">class Dependency {
    void testCompile(Map map) {
        println(&quot;download dependency: &quot; + map)
    }

    void compile(Map map) {
        println(&quot;download dependency: &quot; + map)
    }
}

def dependencies(Closure cl) {
    def dependency = new Dependency()
    def code = cl.rehydrate(dependency, this, this)
    code()
}
</code></pre>
<p><code>rehydrate</code> 的功能是 <code>clone</code> 一个闭包，第一个参数就是代理，将代理设置成一个 <code>Dependency</code> 对象后，就用调用代理对象的方法了</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>官方文档：<a href="http://www.groovy-lang.org/documentation.html#gettingstarted" target="_blank" rel="noopener">http://www.groovy-lang.org/documentation.html#gettingstarted</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> groovy </tag>
            
            <tag> gradle </tag>
            
            <tag> closure </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[java json 库之 jackson]]></title>
      <url>/2018/03/18/java-json-%E5%BA%93%E4%B9%8B-jackson/</url>
      <content type="html"><![CDATA[<p>jackson 是一个 java json 库，提供了完备的 json 解析，序列化以及反序列化功能</p>
<h3 id="依赖配置"><a href="#依赖配置" class="headerlink" title="依赖配置"></a>依赖配置</h3><p>在 build.gradle 里面添加依赖配置</p>
<pre><code>compile group: &#39;com.fasterxml.jackson.core&#39;, name: &#39;jackson-core&#39;, version: &#39;2.9.4&#39;
compile group: &#39;com.fasterxml.jackson.core&#39;, name: &#39;jackson-databind&#39;, version: &#39;2.9.4&#39;
compile group: &#39;com.fasterxml.jackson.core&#39;, name: &#39;jackson-annotations&#39;, version: &#39;2.9.4&#39;
</code></pre><h3 id="json-解析"><a href="#json-解析" class="headerlink" title="json 解析"></a>json 解析</h3><pre><code class="golang">String jsonString = &quot;{\&quot;name\&quot;: \&quot;hatlonely\&quot; /* comment */, \&quot;birthday\&quot;: \&quot;2018-03-18 15:26:37\&quot;, \&quot;mails\&quot;: [\&quot;hatlonely@foxmail.com\&quot;, \&quot;hatlonely@gmail.com\&quot;]}&quot;;

JsonFactory jsonFactory = new JsonFactory();
jsonFactory.enable(Feature.ALLOW_COMMENTS);
ObjectMapper objectMapper = new ObjectMapper(jsonFactory);
JsonNode node = objectMapper.readTree(jsonString);

assertThat(node.path(&quot;name&quot;).asText(), equalTo(&quot;hatlonely&quot;));
assertThat(node.path(&quot;birthday&quot;).asText(), equalTo(&quot;2018-03-18 15:26:37&quot;));
assertThat(node.path(&quot;mails&quot;).size(), equalTo(2));
assertThat(node.path(&quot;mails&quot;).path(0).asText(), equalTo(&quot;hatlonely@foxmail.com&quot;));
assertThat(node.path(&quot;mails&quot;).path(1).asText(), equalTo(&quot;hatlonely@gmail.com&quot;));
</code></pre>
<p>调用 <code>ObjectMapper.readTree</code> 就能讲 json 字符串解析成一个 <code>JsonNode</code> 对象，然后通过 <code>path</code> 方法就可以获取 json 中各个字段的值了，这种方式可以用来读取 json 格式的配置文件，可以用一个 JsonFactory 打开 ALLOW_COMMENTS 特性，可以在 json 里面加入注释</p>
<h3 id="序列化与反序列化"><a href="#序列化与反序列化" class="headerlink" title="序列化与反序列化"></a>序列化与反序列化</h3><h4 id="首先定义一个对象"><a href="#首先定义一个对象" class="headerlink" title="首先定义一个对象"></a>首先定义一个对象</h4><pre><code class="golang">class Person {
    String name;

    @JsonFormat(pattern = &quot;yyyy-MM-dd hh:mm:ss&quot;)
    Date birthday;

    @JsonProperty(&quot;mails&quot;)
    List&lt;String&gt; emails;

    // 省略了 getter/setter
}
</code></pre>
<p>除了支持基本的数据类型，还支持 List 和 Map 类型，甚至还支持 Date 类型，Date 类型默认的格式是 ISO8601 格式，也可以通过 <code>@JsonFormat</code> 指定日期格式，通过 <code>@JsonProperty</code> 指定字段在 json 中的字段名</p>
<h4 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h4><pre><code class="golang">SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;);
dateFormat.setTimeZone(TimeZone.getTimeZone(&quot;GMT&quot;));

Person person = new Person();
person.setName(&quot;hatlonely&quot;);
person.setBirthday(dateFormat.parse(&quot;2018-03-18 15:26:37&quot;));
person.setEmails(Arrays.asList(&quot;hatlonely@foxmail.com&quot;, &quot;hatlonely@gmail.com&quot;));

ObjectMapper objectMapper = new ObjectMapper();
String jsonString = objectMapper.writeValueAsString(person);

assertThat(jsonString, equalTo(
        &quot;{\&quot;name\&quot;:\&quot;hatlonely\&quot;,\&quot;birthday\&quot;:\&quot;2018-03-18 03:26:37\&quot;,\&quot;mails\&quot;:[\&quot;hatlonely@foxmail.com\&quot;,\&quot;hatlonely@gmail.com\&quot;]}&quot;));
</code></pre>
<p>使用 <code>ObjectMapper.writeValueAsString</code> 方法就可以序列化成 string</p>
<h4 id="反序列化"><a href="#反序列化" class="headerlink" title="反序列化"></a>反序列化</h4><pre><code class="golang">String jsonString = &quot;{\&quot;name\&quot;: \&quot;hatlonely\&quot;, \&quot;birthday\&quot;: \&quot;2018-03-18 15:26:37\&quot;, \&quot;mails\&quot;: [\&quot;hatlonely@foxmail.com\&quot;, \&quot;hatlonely@gmail.com\&quot;]}&quot;;

ObjectMapper objectMapper = new ObjectMapper();
objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
Person person = objectMapper.readValue(jsonString, Person.class);

assertThat(person.getName(), equalTo(&quot;hatlonely&quot;));
SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;);
dateFormat.setTimeZone(TimeZone.getTimeZone(&quot;GMT&quot;));
assertThat(person.getBirthday(), equalTo(dateFormat.parse(&quot;2018-03-18 15:26:37&quot;)));
assertThat(person.getEmails(), equalTo(Arrays.asList(&quot;hatlonely@foxmail.com&quot;, &quot;hatlonely@gmail.com&quot;)));
</code></pre>
<p>使用 <code>ObjectMapper.readValue</code> 方法就能实现反序列化，可以通过 <code>configure</code> 方法设置碰到未知的属性不抛异常</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>Jackson JSON Tutorial：<a href="http://www.baeldung.com/jackson" target="_blank" rel="noopener">http://www.baeldung.com/jackson</a></li>
<li>Jackson maven 仓库：<a href="http://mvnrepository.com/search?q=jackson" target="_blank" rel="noopener">http://mvnrepository.com/search?q=jackson</a></li>
<li>Jackson 框架的高阶应用：<a href="https://www.ibm.com/developerworks/cn/java/jackson-advanced-application/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/java/jackson-advanced-application/index.html</a></li>
<li>测试代码链接：<a href="https://github.com/hatlonely/hellojava/blob/master/src/test/java/jackson/JacksonTest.java" target="_blank" rel="noopener">https://github.com/hatlonely/hellojava/blob/master/src/test/java/jackson/JacksonTest.java</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> json </tag>
            
            <tag> java </tag>
            
            <tag> jackson </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[java 多线程]]></title>
      <url>/2018/03/17/java-%E5%A4%9A%E7%BA%BF%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p>java 的多线程有好几种，可以继承 Thread，也可以实现 Runnable 接口，还可以实现 Callable 接口</p>
<h3 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h3><pre><code class="golang">class MyThread extends Thread {
    private String name;

    public MyThread(String name) {
        this.name = name;
    }

    @Override
    public void run() {
        for (int i = 0; i &lt; 5; i++) {
            try {
                Thread.sleep(100L);
            } catch (Exception e) {
                e.printStackTrace();
            }
            System.out.printf(&quot;%s is running %d\n&quot;, name, i);
        }
    }
}

{
    Thread t1 = new MyThread(&quot;t1&quot;);
    Thread t2 = new MyThread(&quot;t2&quot;);

    t1.start();
    t2.start();
    try {
        t1.join();
        t2.join();
    } catch (Exception e) {
        e.printStackTrace();
    }
}
</code></pre>
<p>继承 Thread，自己实现 <code>run</code> 方法，就可以定一个线程类，调用 <code>start</code> 就可以在一个新的线程里面调用 <code>run</code> 方法，如果需要等待线程结束，可以调用 <code>join</code> 方法</p>
<h3 id="Runnable"><a href="#Runnable" class="headerlink" title="Runnable"></a>Runnable</h3><pre><code class="golang">class MyRunnable implements Runnable {
    private String name;

    public MyRunnable(String name) {
        this.name = name;
    }

    @Override
    public void run() {
        for (int i = 0; i &lt; 5; i++) {
            try {
                Thread.sleep(100L);
            } catch (Exception e) {
                e.printStackTrace();
            }
            System.out.printf(&quot;%s is running %d\n&quot;, name, i);
        }
    }
}

{
    Thread r1 = new Thread(new MyRunnable(&quot;r1&quot;));
    Thread r2 = new Thread(new MyRunnable(&quot;r2&quot;));

    r1.start();
    r2.start();
    try {
        r1.join();
        r2.join();
    } catch (Exception e) {
        e.printStackTrace();
    }
}
</code></pre>
<p>和 Thread 差不多，只不过不直接继承 Thread，而是实现 Runnable 接口（Runable 只有一个 <code>run</code> 方法），使用上面用这个 Runnable 去构造一个 Thread，这种方式相对直接继承 Thread 的方式要更加灵活，因为 java 是单继承，如果继承了 Thread 就不能再继承别的类</p>
<p>事实上，建议永远不要直接继承 Thread 类，因为从语义上来讲，Thread 也应该也只是方法运行的方式，你的类应该是可以在这种方式下运行，而不是一种 Thread 对象，从这个角度讲，Runnable 提供了更好的语义，用一个 Thread 对象去运行一个 Runable</p>
<h3 id="Callable"><a href="#Callable" class="headerlink" title="Callable"></a>Callable</h3><pre><code class="golang">class MyCallable implements Callable&lt;Integer&gt; {
    private Random random;

    public MyCallable() {
        this.random = new Random();
    }

    @Override
    public Integer call() throws Exception {
        Thread.sleep(100L);
        return this.random.nextInt();
    }
}

{
    FutureTask&lt;Integer&gt; future1 = new FutureTask&lt;&gt;(new MyCallable());
    FutureTask&lt;Integer&gt; future2 = new FutureTask&lt;&gt;(new MyCallable());
    new Thread(future1).start();
    new Thread(future2).start();

    try {
        System.out.println(future1.get(50, TimeUnit.MILLISECONDS));
    } catch (TimeoutException e) {
        System.out.println(&quot;future1 timeout&quot;);
    } catch (Exception e) {
        e.printStackTrace();
    }

    try {
        System.out.println(future2.get());
    } catch (Exception e) {
        e.printStackTrace();
    }
}
</code></pre>
<p>Callable 接口也只有一个方法 <code>call</code>，和 Runnable 不同的是 Callable 允许有返回值，而这个返回值可以通过 <code>FutureTask.get</code> 获取，还可以设置任务运行的超时时间，超时后会抛出一个异常</p>
<h3 id="ThreadPool"><a href="#ThreadPool" class="headerlink" title="ThreadPool"></a>ThreadPool</h3><pre><code class="golang">class MyCallable implements Callable&lt;Integer&gt; {
    private Random random;

    public MyCallable() {
        this.random = new Random();
    }

    @Override
    public Integer call() throws Exception {
        Thread.sleep(100L);
        return this.random.nextInt();
    }
}

{
    ExecutorService es = Executors.newFixedThreadPool(5);
    Future&lt;Integer&gt; future1 = es.submit(new MyCallable());
    Future&lt;Integer&gt; future2 = es.submit(new MyCallable());

    try {
        System.out.println(future1.get(50, TimeUnit.MILLISECONDS));
    } catch (TimeoutException e) {
        System.out.println(&quot;future1 timeout&quot;);
    } catch (Exception e) {
        e.printStackTrace();
    }

    try {
        System.out.println(future2.get());
    } catch (Exception e) {
        e.printStackTrace();
    }

    es.shutdown();
}
</code></pre>
<p>java 里面线程的创建和销毁成本比较大，所以一般会需要放到线程池里面跑，java 的基础设施就是好，这些在标准库里面都有实现，使用上面也很简单，直接 new 出一个线程池就好了，然后就可以往里面 submit Callable 对象，线程池也有很多种，上面用到的 <code>newFixedThreadPool</code> 是固定线程数的线程池，下面用到的 <code>newCachedThreadPool</code> 在线程不够用的时候会创建新线程，同时也会不断复用之前创建的线程</p>
<pre><code>{
    ExecutorService es = Executors.newCachedThreadPool();
    CompletionService&lt;Integer&gt; cs = new ExecutorCompletionService&lt;&gt;(es);
    cs.submit(new MyCallable());
    cs.submit(new MyCallable());
    cs.submit(new MyCallable());
    cs.submit(new MyCallable());

    try {
        System.out.println(cs.take().get());
        System.out.println(cs.take().get());
        System.out.println(cs.take().get());
        System.out.println(cs.take().get());
    } catch (Exception e) {
        e.printStackTrace();
    }

    es.shutdown();
}
</code></pre><p>典型的生成者消费者模型里面，我们需要把生产的结果放到一个队列里面，而消费者从这个队列里面不断地去消费，<code>ExecutorCompletionService</code> 就相当于这个队列，MyCallable 的结果会写入到缓存里面，使用 <code>cs.take().get()</code> 从里面取出结果</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>线程的创建，销毁，切换在 java 里面都是耗性能的操作，如果有需求要大量地创建线程，尽量使用线程池去复用线程</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>测试代码链接：<a href="https://github.com/hatlonely/hellojava/blob/master/src/test/java/javase/ThreadTest.java" target="_blank" rel="noopener">https://github.com/hatlonely/hellojava/blob/master/src/test/java/javase/ThreadTest.java</a></li>
<li>“implements Runnable” vs. “extends Thread” ：<a href="https://stackoverflow.com/questions/541487/implements-runnable-vs-extends-thread" target="_blank" rel="noopener">https://stackoverflow.com/questions/541487/implements-runnable-vs-extends-thread</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> 多线程 </tag>
            
            <tag> java </tag>
            
            <tag> 并发 </tag>
            
            <tag> runnable </tag>
            
            <tag> thread </tag>
            
            <tag> callable </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang slice 和 string 重用]]></title>
      <url>/2018/03/17/golang-slice-%E5%92%8C-string-%E9%87%8D%E7%94%A8/</url>
      <content type="html"><![CDATA[<p>相比于 c/c++，golang 的一个很大的改进就是引入了 gc 机制，不再需要用户自己管理内存，大大减少了程序由于内存泄露而引入的 bug，但是同时 gc 也带来了额外的性能开销，有时甚至会因为使用不当，导致 gc 成为性能瓶颈，所以 golang 程序设计的时候，应特别注意对象的重用，以减少 gc 的压力。而 slice 和 string 是 golang 的基本类型，了解这些基本类型的内部机制，有助于我们更好地重用这些对象</p>
<h3 id="slice-和-string-内部结构"><a href="#slice-和-string-内部结构" class="headerlink" title="slice 和 string 内部结构"></a>slice 和 string 内部结构</h3><p>slice 和 string 的内部结构可以在 <code>$GOROOT/src/reflect/value.go</code> 里面找到</p>
<pre><code class="golang">type StringHeader struct {
    Data uintptr
    Len  int
}

type SliceHeader struct {
    Data uintptr
    Len  int
    Cap  int
}
</code></pre>
<p>可以看到一个 string 包含一个数据指针和一个长度，长度是不可变的</p>
<p>slice 包含一个数据指针、一个长度和一个容量，当容量不够时会重新申请新的内存，Data 指针将指向新的地址，原来的地址空间将被释放</p>
<p>从这些结构就可以看出，string 和 slice 的赋值，包括当做参数传递，和自定义的结构体一样，都仅仅是 Data 指针的浅拷贝</p>
<h3 id="slice-重用"><a href="#slice-重用" class="headerlink" title="slice 重用"></a>slice 重用</h3><h4 id="append-操作"><a href="#append-操作" class="headerlink" title="append 操作"></a>append 操作</h4><pre><code class="golang">si1 := []int{1, 2, 3, 4, 5, 6, 7, 8, 9}
si2 := si1
si2 = append(si2, 0)
Convey(&quot;重新分配内存&quot;, func() {
    header1 := (*reflect.SliceHeader)(unsafe.Pointer(&amp;si1))
    header2 := (*reflect.SliceHeader)(unsafe.Pointer(&amp;si2))
    fmt.Println(header1.Data)
    fmt.Println(header2.Data)
    So(header1.Data, ShouldNotEqual, header2.Data)
})
</code></pre>
<p>si1 和 si2 开始都指向同一个数组，当对 si2 执行 append 操作时，由于原来的 Cap 值不够了，需要重新申请新的空间，因此 Data 值发生了变化，在 <code>$GOROOT/src/reflect/value.go</code> 这个文件里面还有关于新的 cap 值的策略，在 <code>grow</code> 这个函数里面，当 cap 小于 1024 的时候，是成倍的增长，超过的时候，每次增长 25%，而这种内存增长不仅仅数据拷贝（从旧的地址拷贝到新的地址）需要消耗额外的性能，旧地址内存的释放对 gc 也会造成额外的负担，所以如果能够知道数据的长度的情况下，尽量使用 <code>make([]int, len, cap)</code> 预分配内存，不知道长度的情况下，可以考虑下面的内存重用的方法</p>
<h4 id="内存重用"><a href="#内存重用" class="headerlink" title="内存重用"></a>内存重用</h4><pre><code class="golang">si1 := []int{1, 2, 3, 4, 5, 6, 7, 8, 9}
si2 := si1[:7]
Convey(&quot;不重新分配内存&quot;, func() {
    header1 := (*reflect.SliceHeader)(unsafe.Pointer(&amp;si1))
    header2 := (*reflect.SliceHeader)(unsafe.Pointer(&amp;si2))
    fmt.Println(header1.Data)
    fmt.Println(header2.Data)
    So(header1.Data, ShouldEqual, header2.Data)
})

Convey(&quot;往切片里面 append 一个值&quot;, func() {
    si2 = append(si2, 10)
    Convey(&quot;改变了原 slice 的值&quot;, func() {
        header1 := (*reflect.SliceHeader)(unsafe.Pointer(&amp;si1))
        header2 := (*reflect.SliceHeader)(unsafe.Pointer(&amp;si2))
        fmt.Println(header1.Data)
        fmt.Println(header2.Data)
        So(header1.Data, ShouldEqual, header2.Data)
        So(si1[7], ShouldEqual, 10)
    })
})
</code></pre>
<p>si2 是 si1 的一个切片，从第一段代码可以看到切片并不重新分配内存，si2 和 si1 的 Data 指针指向同一片地址，而第二段代码可以看出，当我们往 si2 里面 append 一个新的值的时候，我们发现仍然没有内存分配，而且这个操作使得 si1 的值也发生了改变，因为两者本就是指向同一片 Data 区域，利用这个特性，我们只需要让 <code>si1 = si1[:0]</code> 就可以不断地清空 si1 的内容，实现内存的复用了</p>
<p><strong>PS</strong>: 你可以使用 <code>copy(si2, si1)</code> 实现深拷贝</p>
<h3 id="string"><a href="#string" class="headerlink" title="string"></a>string</h3><pre><code class="golang">Convey(&quot;字符串常量&quot;, func() {
    str1 := &quot;hello world&quot;
    str2 := &quot;hello world&quot;
    Convey(&quot;地址相同&quot;, func() {
        header1 := (*reflect.StringHeader)(unsafe.Pointer(&amp;str1))
        header2 := (*reflect.StringHeader)(unsafe.Pointer(&amp;str2))
        fmt.Println(header1.Data)
        fmt.Println(header2.Data)
        So(header1.Data, ShouldEqual, header2.Data)
    })
})
</code></pre>
<p>这个例子比较简单，字符串常量使用的是同一片地址区域</p>
<pre><code class="golang">Convey(&quot;相同字符串的不同子串&quot;, func() {
    str1 := &quot;hello world&quot;[:6]
    str2 := &quot;hello world&quot;[:5]
    Convey(&quot;地址相同&quot;, func() {
        header1 := (*reflect.StringHeader)(unsafe.Pointer(&amp;str1))
        header2 := (*reflect.StringHeader)(unsafe.Pointer(&amp;str2))
        fmt.Println(header1.Data, str1)
        fmt.Println(header2.Data, str2)
        So(str1, ShouldNotEqual, str2)
        So(header1.Data, ShouldEqual, header2.Data)
    })
})
</code></pre>
<p>相同字符串的不同子串，不会额外申请新的内存，但是要注意的是这里的相同字符串，指的是 <code>str1.Data == str2.Data &amp;&amp; str1.Len == str2.Len</code>，而不是 <code>str1 == str2</code>，下面这个例子可以说明 <code>str1 == str2</code> 但是其 Data 并不相同</p>
<pre><code class="golang">Convey(&quot;不同字符串的相同子串&quot;, func() {
    str1 := &quot;hello world&quot;[:5]
    str2 := &quot;hello golang&quot;[:5]
    Convey(&quot;地址不同&quot;, func() {
        header1 := (*reflect.StringHeader)(unsafe.Pointer(&amp;str1))
        header2 := (*reflect.StringHeader)(unsafe.Pointer(&amp;str2))
        fmt.Println(header1.Data, str1)
        fmt.Println(header2.Data, str2)
        So(str1, ShouldEqual, str2)
        So(header1.Data, ShouldNotEqual, header2.Data)
    })
})
</code></pre>
<p>实际上对于字符串，你只需要记住一点，字符串是不可变的，任何字符串的操作都不会申请额外的内存（对于仅内部数据指针而言），我曾自作聪明地设计了一个 cache 去存储字符串，以减少重复字符串所占用的空间，事实上，除非这个字符串本身就是由 <code>[]byte</code> 创建而来，否则，这个字符串本身就是另一个字符串的子串（比如通过 <code>strings.Split</code> 获得的字符串），本来就不会申请额外的空间，这么做简直就是多此一举</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>Go Slices: usage and internals：<a href="https://blog.golang.org/go-slices-usage-and-internals" target="_blank" rel="noopener">https://blog.golang.org/go-slices-usage-and-internals</a></li>
<li>测试代码链接：<a href="https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/reuse_test.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/reuse_test.go</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> slice </tag>
            
            <tag> string </tag>
            
            <tag> 重用 </tag>
            
            <tag> 性能优化 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 字节对齐]]></title>
      <url>/2018/03/17/golang-%E5%AD%97%E8%8A%82%E5%AF%B9%E9%BD%90/</url>
      <content type="html"><![CDATA[<p>最近在做一些性能优化的工作，其中有个结构体占用的空间比较大，而且在内存中的数量又特别多，就在想有没有优化的空间，想起了 c 语言里面的字节对齐，通过简单地调整一下字段的顺序，就能省出不少内存，这个思路在 golang 里面同样适用</p>
<h3 id="基本数据大小"><a href="#基本数据大小" class="headerlink" title="基本数据大小"></a>基本数据大小</h3><p>在这之前先来看下 golang 里面基本的类型所占数据的大小</p>
<pre><code class="golang">So(unsafe.Sizeof(true), ShouldEqual, 1)
So(unsafe.Sizeof(int8(0)), ShouldEqual, 1)
So(unsafe.Sizeof(int16(0)), ShouldEqual, 2)
So(unsafe.Sizeof(int32(0)), ShouldEqual, 4)
So(unsafe.Sizeof(int64(0)), ShouldEqual, 8)
So(unsafe.Sizeof(int(0)), ShouldEqual, 8)
So(unsafe.Sizeof(float32(0)), ShouldEqual, 4)
So(unsafe.Sizeof(float64(0)), ShouldEqual, 8)
So(unsafe.Sizeof(&quot;&quot;), ShouldEqual, 16)
So(unsafe.Sizeof(&quot;hello world&quot;), ShouldEqual, 16)
So(unsafe.Sizeof([]int{}), ShouldEqual, 24)
So(unsafe.Sizeof([]int{1, 2, 3}), ShouldEqual, 24)
So(unsafe.Sizeof([3]int{1, 2, 3}), ShouldEqual, 24)
So(unsafe.Sizeof(map[string]string{}), ShouldEqual, 8)
So(unsafe.Sizeof(map[string]string{&quot;1&quot;: &quot;one&quot;, &quot;2&quot;: &quot;two&quot;}), ShouldEqual, 8)
So(unsafe.Sizeof(struct{}{}), ShouldEqual, 0)
</code></pre>
<ul>
<li>bool 类型虽然只有一位，但也需要占用1个字节，因为计算机是以字节为单位</li>
<li>64为的机器，一个 int 占8个字节</li>
<li>string 类型占16个字节，内部包含一个指向数据的指针（8个字节）和一个 int 的长度（8个字节）</li>
<li>slice 类型占24个字节，内部包含一个指向数据的指针（8个字节）和一个 int 的长度（8个字节）和一个 int 的容量（8个字节）</li>
<li>map 类型占8个字节，是一个指向 map 结构的指针</li>
<li>可以用 struct{} 表示空类型，这个类型不占用任何空间，用这个作为 map 的 value，可以将 map 当做 set 来用</li>
</ul>
<h3 id="字节对齐"><a href="#字节对齐" class="headerlink" title="字节对齐"></a>字节对齐</h3><p>结构体中的各个字段在内存中并不是紧凑排列的，而是按照字节对齐的，比如 int 占8个字节，那么就只能写在地址为8的倍数的地址处，至于为什么要字节对齐，主要是为了效率考虑，而更深层的原理看了一下网上的说法，感觉不是很靠谱，就不瞎说了，感兴趣可以自己研究下</p>
<pre><code class="golang">// |x---|
So(unsafe.Sizeof(struct {
    i8 int8
}{}), ShouldEqual, 1)
</code></pre>
<p>简单封装一个 int8 的结构体，和 int8 一样，仅占1个字节，没有额外空间</p>
<pre><code class="golang">// |x---|xxxx|xx--|
So(unsafe.Sizeof(struct {
    i8  int8
    i32 int32
    i16 int16
}{}), ShouldEqual, 12)

// |x-xx|xxxx|
So(unsafe.Sizeof(struct {
    i8  int8
    i16 int16
    i32 int32
}{}), ShouldEqual, 8)
</code></pre>
<p>这两个结构体里面的内容完全一样，调整了一下字段顺序，节省了 33% 的空间</p>
<pre><code class="golang">// |x---|xxxx|xx--|----|xxxx|xxxx|
So(unsafe.Sizeof(struct {
    i8  int8
    i32 int32
    i16 int16
    i64 int64
}{}), ShouldEqual, 24)

// |x-xx|xxxx|xxxx|xxxx|
So(unsafe.Sizeof(struct {
    i8  int8
    i16 int16
    i32 int32
    i64 int64
}{}), ShouldEqual, 16)
</code></pre>
<p>这里需要注意的是 int64 只能出现在8的倍数的地址处，因此第一个结构体中，有连续的4个字节是空的</p>
<pre><code class="golang">type I8 int8
type I16 int16
type I32 int32

So(unsafe.Sizeof(struct {
    i8  I8
    i16 I16
    i32 I32
}{}), ShouldEqual, 8)
</code></pre>
<p>给类型重命名之后，类型的大小并没有发生改变</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>测试代码链接：<a href="https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/struct_test.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/struct_test.go</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 性能优化 </tag>
            
            <tag> 字节对齐 </tag>
            
            <tag> 结构体 </tag>
            
            <tag> 内存优化 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 并发编程之生产者消费者]]></title>
      <url>/2018/03/11/golang-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85/</url>
      <content type="html"><![CDATA[<p>golang 最吸引人的地方可能就是并发了，无论代码的编写上，还是性能上面，golang 都有绝对的优势</p>
<p>学习一个语言的并发特性，我喜欢实现一个生产者消费者模型，这个模型非常经典，适用于很多的并发场景，下面我通过这个模型，来简单介绍一下 golang 的并发编程</p>
<h3 id="go-并发语法"><a href="#go-并发语法" class="headerlink" title="go 并发语法"></a>go 并发语法</h3><h4 id="协程-go"><a href="#协程-go" class="headerlink" title="协程 go"></a>协程 <code>go</code></h4><p><strong>协程</strong>是 golang 并发的最小单元，类似于其他语言的线程，只不过线程的实现借助了操作系统的实现，每次线程的调度都是一次系统调用，需要从用户态切换到内核态，这是一项非常耗时的操作，因此一般的程序里面线程太多会导致大量的性能耗费在线程切换上。而在 golang 内部实现了这种调度，协程在这种调度下面的切换非常的轻量级，成百上千的协程跑在一个 golang 程序里面是很正常的事情</p>
<p>golang 为并发而生，启动一个协程的语法非常简单，使用 <code>go</code> 关键字即可</p>
<pre><code class="go">go func () {
    // do something
}()
</code></pre>
<h4 id="同步信号-sync-WaitGroup"><a href="#同步信号-sync-WaitGroup" class="headerlink" title="同步信号 sync.WaitGroup"></a>同步信号 <code>sync.WaitGroup</code></h4><p>多个协程之间可以通过 <code>sync.WaitGroup</code> 同步，这个类似于 Linux 里面的信号量</p>
<pre><code class="go">var wg sync.WaitGroup  // 声明一个信号量
wg.Add(1)   // 信号量加一
wg.Done()   // 信号量减一
wg.Wait()   // 信号量为正时阻塞，直到信号量为0时被唤醒
</code></pre>
<h4 id="通道-chan"><a href="#通道-chan" class="headerlink" title="通道 chan"></a>通道 <code>chan</code></h4><p>通道可以理解为一个消息队列，生产者往队列里面放，消费者从队列里面取。通道可以使用 <code>close</code> 关闭</p>
<pre><code class="go">ic := make(chan int, 10)  // 申明一个通道
ic &lt;- 10        // 往通道里面放
i := &lt;- ic      // 从通道里面取

close(ic)       // 关闭通道
</code></pre>
<h3 id="生产者消费者实现"><a href="#生产者消费者实现" class="headerlink" title="生产者消费者实现"></a>生产者消费者实现</h3><h4 id="定义产品类"><a href="#定义产品类" class="headerlink" title="定义产品类"></a>定义产品类</h4><p>这个产品类根据具体的业务需求定义</p>
<pre><code class="go">type Product struct {
    name  int
    value int
}
</code></pre>
<h4 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h4><p>如果 <code>stop</code> 标志不为 <code>false</code>，不断地往通道里面放 <code>product</code>，完成之后信号量完成</p>
<pre><code class="go">func producer(wg *sync.WaitGroup, products chan&lt;- Product, name int, stop *bool) {
    for !*stop {
        product := Product{name: name, value: rand.Int()}
        products &lt;- product
        fmt.Printf(&quot;producer %v produce a product: %#v\n&quot;, name, product)
        time.Sleep(time.Duration(200+rand.Intn(1000)) * time.Millisecond)
    }
    wg.Done()
}
</code></pre>
<h4 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h4><p>不断地从通道里面取 product，然后作对应的处理，直到通道被关闭，并且 products 里面为空， for 循环才会终止，而这正是我们期望的</p>
<pre><code class="go">func consumer(wg *sync.WaitGroup, products &lt;-chan Product, name int) {
    for product := range products {
        fmt.Printf(&quot;consumer %v consume a product: %#v\n&quot;, name, product)
        time.Sleep(time.Duration(200+rand.Intn(1000)) * time.Millisecond)
    }
    wg.Done()
}
</code></pre>
<h4 id="主线程"><a href="#主线程" class="headerlink" title="主线程"></a>主线程</h4><pre><code class="go">var wgp sync.WaitGroup
var wgc sync.WaitGroup
stop := false
products := make(chan Product, 10)

// 创建 5 个生产者和 5 个消费者
for i := 0; i &lt; 5; i++ {
    go producer(&amp;wgp, products, i, &amp;stop)
    go consumer(&amp;wgc, products, i)
    wgp.Add(1)
    wgc.Add(1)
}

time.Sleep(time.Duration(1) * time.Second)
stop = true     // 设置生产者终止信号
wgp.Wait()      // 等待生产者退出
close(products) // 关闭通道
wgc.Wait()      // 等待消费者退出
</code></pre>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 并发编程 </tag>
            
            <tag> 生产者消费者 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> sync.WaitGroup </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 设计模式之选项模式]]></title>
      <url>/2018/03/10/golang-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E9%80%89%E9%A1%B9%E6%A8%A1%E5%BC%8F/</url>
      <content type="html"><![CDATA[<p>有时候一个函数会有很多参数，为了方便函数的使用，我们会给希望给一些参数设定默认值，调用时只需要传与默认值不同的参数即可，类似于 python 里面的默认参数和字典参数，虽然 golang 里面既没有默认参数也没有字典参数，但是我们有选项模式</p>
<h3 id="可变长参数列表"><a href="#可变长参数列表" class="headerlink" title="可变长参数列表"></a>可变长参数列表</h3><p>在这之前，首先需要介绍一下可变长参数列表，顾名思义，就是参数的个数不固定，可以是一个也可以是多个，最典型的用法就是标准库里面的 <code>fmt.Printf</code>，语法比较简单，如下面例子实现任意多个参数的加法</p>
<pre><code class="go">func add(nums ...int) int {
    sum := 0
    for _, num := range nums {
        sum += num
    }
    return sum
}

So(add(1, 2), ShouldEqual, 3)
So(add(1, 2, 3), ShouldEqual, 6)
</code></pre>
<p>在类型前面加 <code>...</code> 来表示这个类型的变长参数列表，使用上把参数当成 <code>slice</code> 来用即可</p>
<h3 id="选项模式"><a href="#选项模式" class="headerlink" title="选项模式"></a>选项模式</h3><p>假设我们要实现这样一个函数，这个函数接受5个参数，三个 <code>string</code>（其中第一个参数是必填参数），两个 <code>int</code>，这里功能只是简单输出这个参数，于是我们可以简单用如下代码实现</p>
<pre><code class="go">func MyFunc1(requiredStr string, str1 string, str2 string, int1 int, int2 int) {
    fmt.Println(requiredStr, str1, str2, int1, int2)
}

// 调用方法
MyFunc1(&quot;requiredStr&quot;, &quot;defaultStr1&quot;, &quot;defaultStr2&quot;, 1, 2)
</code></pre>
<p>这种实现比较简单，但是同时传入参数较多，对调用方来说，使用的成本就会比较高，而且每个参数的具体含义这里并不清晰，很容易出错</p>
<p>那选项模式怎么实现这个需求呢？先来看下最终的效果</p>
<pre><code class="go">MyFunc2(&quot;requiredStr&quot;)
MyFunc2(&quot;requiredStr&quot;, WithOptionStr1(&quot;mystr1&quot;))
MyFunc2(&quot;requiredStr&quot;, WithOptionStr2AndInt2(&quot;mystr2&quot;, 22), WithOptionInt1(11))
</code></pre>
<p>如上面代码所示，你可以根据自己的需求选择你需要传入的参数，大大简化了函数调用的复杂度，并且每个参数都有了清晰明确的含义</p>
<p>那怎么实现上面的功能呢</p>
<h4 id="定义可选项和默认值"><a href="#定义可选项和默认值" class="headerlink" title="定义可选项和默认值"></a>定义可选项和默认值</h4><p>首先定义可选项和默认值，这里有4个可选项，第一个参数为必填项</p>
<pre><code class="go">type MyFuncOptions struct {
    optionStr1 string
    optionStr2 string
    optionInt1 int
    optionInt2 int
}

var defaultMyFuncOptions = MyFuncOptions{
    optionStr1: &quot;defaultStr1&quot;,
    optionStr2: &quot;defaultStr2&quot;,
    optionInt1: 1,
    optionInt2: 2,
}
</code></pre>
<h4 id="实现-With-方法"><a href="#实现-With-方法" class="headerlink" title="实现 With 方法"></a>实现 With 方法</h4><p>这些 With 方法看起来有些古怪，接受一个选项参数，返回一个选项方法，而选项方法以选项作为参数负责修改选项的值，如果没看明白没关系，可以先看函数功能如何实现</p>
<pre><code class="go">type MyFuncOption func(options *MyFuncOptions)

func WithOptionStr1(str1 string) MyFuncOption {
    return func(options *MyFuncOptions) {
        options.optionStr1 = str1
    }
}

func WithOptionInt1(int1 int) MyFuncOption {
    return func(options *MyFuncOptions) {
        options.optionInt1 = int1
    }
}

func WithOptionStr2AndInt2(str2 string, int2 int) MyFuncOption {
    return func(options *MyFuncOptions) {
        options.optionStr2 = str2
        options.optionInt2 = int2
    }
}
</code></pre>
<p>这里我们让 optionStr2 和 optionInt2 合并一起设置，实际应用场景中可以用这种方式将相关的参数放到一起设置</p>
<h4 id="实现函数功能"><a href="#实现函数功能" class="headerlink" title="实现函数功能"></a>实现函数功能</h4><pre><code class="go">func MyFunc2(requiredStr string, opts ...MyFuncOption) {
    options := defaultMyFuncOptions
    for _, o := range opts {
        o(&amp;options)
    }

    fmt.Println(requiredStr, options.optionStr1, options.optionStr2, options.optionInt1, options.optionInt2)
}
</code></pre>
<p>使用 With 方法返回的选项方法作为参数列表，用这些方法去设置选项</p>
<h3 id="选项模式的应用"><a href="#选项模式的应用" class="headerlink" title="选项模式的应用"></a>选项模式的应用</h3><p>从这里可以看到，为了实现选项的功能，我们增加了很多的代码，实现成本相对还是较高的，所以实践中需要根据自己的业务场景去权衡是否需要使用。个人总结满足下面条件可以考虑使用选项模式</p>
<ol>
<li>参数确实比较复杂，影响调用方使用</li>
<li>参数确实有比较清晰明确的默认值</li>
<li>为参数的后续拓展考虑</li>
</ol>
<p>在 golang 的很多开源项目里面也用到了选项模式，比如 grpc 中的 rpc 方法就是采用选项模式设计的，除了必填的 rpc 参数外，还可以一些选项参数，grpc_retry 就是通过这个机制实现的，可以实现自动重试功能</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>Go 函数式选项模式：<a href="https://studygolang.com/articles/12329" target="_blank" rel="noopener">https://studygolang.com/articles/12329</a></li>
<li>Functional Options Pattern in Go：<a href="https://halls-of-valhalla.org/beta/articles/functional-options-pattern-in-go,54/" target="_blank" rel="noopener">https://halls-of-valhalla.org/beta/articles/functional-options-pattern-in-go,54/</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 设计模式 </tag>
            
            <tag> 选项模式 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang aws-sdk-go 之 s3 服务]]></title>
      <url>/2018/03/04/golang-aws-sdk-go-%E4%B9%8B-s3-%E6%9C%8D%E5%8A%A1/</url>
      <content type="html"><![CDATA[<p>s3 是 aws 提供的分布式文件服务，价格比较优惠，经常被用来作为日志的持久化存储，大数据处理结果的输入输出等</p>
<p>s3 服务提供命令行工具，可以很方便地上传、下载、删除文件，普通 golang 程序如果需要访问 s3 上文件，一种简单方式可以先将 s3 上文件下载到本地，然后直接访问本地文件即可，但是这种方式需要一个额外的步骤，下载到本地，有额外的运维成本，需要额外的磁盘空间，使用上面不是很灵活，此外，微服务应该尽可能地降低对本地数据的依赖，这种设计也不符合微服务的设计思想</p>
<p>使用 aws-sdk-go 可以直接访问 s3 服务，实现文件的上传和读取</p>
<p>以下使用的代码：<a href="https://github.com/hatlonely/hellogolang/blob/master/internal/aws-sdk-go/s3_test.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/internal/aws-sdk-go/s3_test.go</a></p>
<h3 id="创建会话"><a href="#创建会话" class="headerlink" title="创建会话"></a>创建会话</h3><p>首先需要创建一个会话，后续的访问都可以通过这个会话进行，如果访问的服务需要授权，也可以在 config 里面指定授权文件</p>
<pre><code>sess := session.Must(session.NewSession(&amp;aws.Config{
    Region: aws.String(endpoints.ApSoutheast1RegionID),
}))
service := s3.New(sess)
</code></pre><p>这里必须指定 s3 桶所在的地区</p>
<h3 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h3><pre><code>fp, err := os.Open(&quot;s3_test.go&quot;)
So(err, ShouldBeNil)
defer fp.Close()

ctx, cancel := context.WithTimeout(context.Background(), time.Duration(30)*time.Second)
defer cancel()

_, err = service.PutObjectWithContext(ctx, &amp;s3.PutObjectInput{
    Bucket: aws.String(&quot;hatlonely&quot;),
    Key:    aws.String(&quot;test/s3_test.go&quot;),
    Body:   fp,
})
So(err, ShouldBeNil)
</code></pre><p>使用 <code>PutObjectWithContext</code> 实现文件的上传，这里只能实现文件的上传，不能实现文件的写入，所以只能先将文件写入到本地，然后再整个上传</p>
<p>可以通过 context 设置访问超时时间</p>
<h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><pre><code>ctx, cancel := context.WithTimeout(context.Background(), time.Duration(30)*time.Second)
defer cancel()

out, err := service.GetObjectWithContext(ctx, &amp;s3.GetObjectInput{
    Bucket: aws.String(&quot;hatlonely&quot;),
    Key: aws.String(&quot;test/s3_test.go&quot;),
})
So(err, ShouldBeNil)
defer out.Body.Close()
scanner := bufio.NewScanner(out.Body)
for scanner.Scan() {
    Println(scanner.Text())
}
</code></pre><p>使用 <code>GetObjectWithContext</code> 接口读取文件，文件的内容在 out.Body 中，可以使用 scanner 接口，不断地按行读取文件内容</p>
<p>最后要记得调用 <code>out.Body.Close()</code>，释放资源</p>
<h3 id="遍历目录"><a href="#遍历目录" class="headerlink" title="遍历目录"></a>遍历目录</h3><pre><code>var objkeys []string

ctx, cancel := context.WithTimeout(context.Background(), time.Duration(30)*time.Second)
defer cancel()

out, err := service.ListObjectsWithContext(ctx, &amp;s3.ListObjectsInput{
    Bucket: aws.String(&quot;hatlonely&quot;),
    Prefix: aws.String(&quot;test/&quot;),
})
So(err, ShouldBeNil)
for _, content := range out.Contents  {
    objkeys = append(objkeys, aws.StringValue(content.Key))
}
Println(objkeys)
</code></pre><p>大数据一般都是并发输出，每个节点都会输出一个文件，到一个指定的目录下面，所以有时候我们需要去获取一个目录下面到底有哪些文件，可以使用 <code>ListObjectsWithContext</code> 遍历一个目录下所有的文件，这个函数是递归的</p>
<pre><code>var objkeys []string

ctx, cancel := context.WithTimeout(context.Background(), time.Duration(30)*time.Second)
defer cancel()

err := service.ListObjectsPagesWithContext(ctx, &amp;s3.ListObjectsInput{
    Bucket: aws.String(&quot;hatlonely&quot;),
    Prefix: aws.String(&quot;test/&quot;),
}, func(output *s3.ListObjectsOutput, b bool) bool {
    for _, content := range output.Contents {
        objkeys = append(objkeys, aws.StringValue(content.Key))
    }
    return true
})
So(err, ShouldBeNil)
Println(objkeys)
</code></pre><p>也可以使用 <code>ListObjectsPagesWithContext</code> 传入一个回调函数，用于处理每个文件</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>aws-sdk-go：<a href="https://github.com/aws/aws-sdk-go" target="_blank" rel="noopener">https://github.com/aws/aws-sdk-go</a></li>
<li>aws-sdk-go api：<a href="https://docs.aws.amazon.com/sdk-for-go/api/" target="_blank" rel="noopener">https://docs.aws.amazon.com/sdk-for-go/api/</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> aws-sdk-go </tag>
            
            <tag> s3 </tag>
            
            <tag> aws </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[基于 aws 的 vpn 服务器搭建]]></title>
      <url>/2018/03/04/%E5%9F%BA%E4%BA%8E-aws-%E7%9A%84-vpn-%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA/</url>
      <content type="html"><![CDATA[<p>搭 vpn 的原因主要有两个：</p>
<ol>
<li>google，“内事不知问百度，外事不知问 google”，技术这件事情明显是外事，百度在技术搜索上面要不就是和问题不太相关，要不就是已经是过时的内容，确实体验比较差</li>
<li>一些 golang 库没有办法通过 <code>go get</code> 正常下载</li>
</ol>
<p>之前在淘宝上还可以买到这种 vpn 账号，现在也越来越难买了，还是自己搭一个比较省事</p>
<h3 id="墙外的服务器"><a href="#墙外的服务器" class="headerlink" title="墙外的服务器"></a>墙外的服务器</h3><p>要搭 vpn 首先需要有一台墙外的服务器，香港的或者国外的都可以，操作系统建议安装 <code>CentOS 7</code></p>
<p>这里我使用 aws 的服务，主要是可以免费一年，唯一需要的是绑定一个 visa 信用卡。然后创建一台 EC2 实例，选择 <code>Centos 7</code> 系统镜像，在 <code>AWS Marketplace</code> 中搜索 “centos” 关键字即可</p>
<h3 id="安装-vpn-服务"><a href="#安装-vpn-服务" class="headerlink" title="安装 vpn 服务"></a>安装 vpn 服务</h3><p>github 上有个大神写了个一键安装的脚本：<a href="https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md" target="_blank" rel="noopener">https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md</a>，直接执行下列命令即可完成安装: </p>
<pre><code>wget https://git.io/vpnsetup-centos -O vpnsetup.sh &amp;&amp; sudo sh vpnsetup.sh
</code></pre><p>安装成功后，会在屏幕上显示 vpn 凭证</p>
<pre><code>Server IP: xx.xx.xx.xx
IPsec PSK: xxxxxxxxxxx
Username: vpnuser
Password: xxxxxxxxxxxx
</code></pre><p>现在 vpn 服务还不能访问，需要将 vpn 服务端口对外网开放，vpn 服务使用到的端口有 500/4500/50/51/1701，通过设置安全组可以开放这些端口，也可以暴力一点，开发所有端口</p>
<h3 id="客户端访问"><a href="#客户端访问" class="headerlink" title="客户端访问"></a>客户端访问</h3><h4 id="Mac"><a href="#Mac" class="headerlink" title="Mac"></a>Mac</h4><ol>
<li><code>打开系统偏好设置</code> → <code>网络</code></li>
<li>点 <code>+</code> 添加网络，接口选 <code>vpn</code>，vpn 类型选 <code>IPSec 上的 L2TP</code>，服务名称随意</li>
<li>选中刚刚创建的网络，将上面生成的 vpn 凭证填入，服务器地址填 <code>Server Ip</code>，账户名称填 <code>Username</code>，点开鉴定设置，密码填 <code>Password</code>，共享的秘钥填 <code>IPsec PSK</code></li>
<li>点击 <code>连接</code> 即可</li>
</ol>
<h4 id="iOS"><a href="#iOS" class="headerlink" title="iOS"></a>iOS</h4><ol>
<li><code>设置</code> → <code>通用</code> → <code>vpn</code></li>
<li>添加 vpn 配置 → 类型选择 <code>L2TP</code> → 填入上述 vpn 凭证即可</li>
</ol>
<h3 id="添加用户"><a href="#添加用户" class="headerlink" title="添加用户"></a>添加用户</h3><p>直接编辑 <code>/etc/ppp/chap-secrets</code> 文件，新增用户即可，无需重启服务</p>
<pre><code>sudo vim /etc/ppp/chap-secrets
</code></pre><p>文件样例如下:</p>
<pre><code>&quot;user1&quot; l2tpd &quot;password1&quot; *
&quot;user2&quot; l2tpd &quot;password2&quot; *
&quot;user3&quot; l2tpd &quot;password3&quot; *
</code></pre><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>IPsec VPN 服务器一键安装脚本：<a href="https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md" target="_blank" rel="noopener">https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/README-zh.md</a></li>
<li>IPsec 服务端口: <a href="https://serverfault.com/questions/451381/which-ports-for-ipsec-lt2p" target="_blank" rel="noopener">https://serverfault.com/questions/451381/which-ports-for-ipsec-lt2p</a></li>
<li>配置 IPsec/L2TP VPN 客户端：<a href="https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/clients-zh.md" target="_blank" rel="noopener">https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/clients-zh.md</a></li>
<li>管理 VPN 用户：<a href="https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/manage-users-zh.md" target="_blank" rel="noopener">https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/manage-users-zh.md</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> aws </tag>
            
            <tag> vpn </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mac 必备工具之 brew]]></title>
      <url>/2018/02/21/mac-%E5%BF%85%E5%A4%87%E5%B7%A5%E5%85%B7%E4%B9%8B-brew/</url>
      <content type="html"><![CDATA[<p>brew 是 Mac 下的一个包管理工具，类似于 centos 下的 yum，可以很方便地进行安装/卸载/更新各种软件包，例如：nodejs, elasticsearch, kibana, mysql, mongodb 等等，可以用来快速搭建各种本地环境，程序员必备工具</p>
<h3 id="安装-brew"><a href="#安装-brew" class="headerlink" title="安装 brew"></a>安装 brew</h3><p>首先要通过如下命令安装 brew</p>
<pre><code>/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;
</code></pre><h3 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h3><h4 id="安装-卸载-更新"><a href="#安装-卸载-更新" class="headerlink" title="安装/卸载/更新"></a>安装/卸载/更新</h4><p>以 nodejs 为例，执行下面命令即可，安装目录在 <code>/usr/local/Cellar</code></p>
<pre><code>brew install nodejs
</code></pre><p>如果需要更新或卸载</p>
<pre><code>brew upgrade nodejs
brew remove nodejs
</code></pre><h4 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a>其他命令</h4><pre><code>brew list                   # 列出当前安装的软件
brew search nodejs          # 查询与 nodejs 相关的可用软件
brew info nodejs            # 查询 nodejs 的安装信息
</code></pre><p>如果需要指定版本，可以在 <code>brew search</code> 查看有没有需要的版本，在 <code>@</code> 后面指定版本号，例如 <code>brew install thrift@0.9</code></p>
<h3 id="brew-services"><a href="#brew-services" class="headerlink" title="brew services"></a>brew services</h3><p><code>brew services</code> 是一个非常强大的工具，可以用来管理各种服务的启停，有点像 linux 里面的 services，非常方便，以 elasticsearch 为例</p>
<pre><code>brew install elasticsearch          # 安装 elasticsearch
brew services start elasticsearch   # 启动 elasticsearch
brew services stop elasticsearch    # 停止 elasticsearch
brew services restart elasticsearch # 重启 elasticsearch
brew services list                  # 列出当前的状态
</code></pre><p>brew services 服务相关配置以及日志路径</p>
<ul>
<li>配置路径：<code>/usr/local/etc/</code></li>
<li>日志路径：<code>/usr/local/var/log</code></li>
</ul>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>brew 官网：<a href="https://brew.sh/" target="_blank" rel="noopener">https://brew.sh/</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> Mac </tag>
            
            <tag> brew </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[markdown 一个优雅的写作工具]]></title>
      <url>/2018/02/14/markdown-%E4%B8%80%E4%B8%AA%E4%BC%98%E9%9B%85%E7%9A%84%E5%86%99%E4%BD%9C%E5%B7%A5%E5%85%B7/</url>
      <content type="html"><![CDATA[<p>说到写作工具，不得不提的就是 word 了吧，现在有哪个公司能不用这个软件吗？作为最流行的写作软件，word 确实有很多优点，操作比较直观，所见即所得等等，但是大家也一定遇到过样式调整起来比较繁琐的问题，不同的内容可能需要频繁地调整字体、大小、行距等等，而且还很容易出现不一致，整体都显得很不协调，当然你是 word 的高级用户的话，可能知道有模板这个东西，帮你定义了统一的样式，但是首先你要成为一个高级用户，总之你需要花很多额外的时间在样式的调整上面，编辑体验很差；另一方面不同的用户都有自己的样式偏好，风格不统一也很影响阅读体验；此外，修订功能真的做得很难看……难看到不太想……</p>
<p>其实 word 的主要的问题根源来自于将内容和样式绑定在一起了，写作者需要同时编辑文章的内容和样式，虽然很灵活，但是实际上是一种很低效的方式，因为创作本身只与内容有关。相比之下 LaTeX 通过为内容定义一些标签，再统一对这些标签定义样式，编辑体验可能会更好一些，但是其复杂甚至有些古怪的语法，在使用上有比较高的门槛。事实上，word 也提供了内容和样式分离的方式，就是模板样式，但是当你的初级用户已经习惯了同时编辑内容和样式，就很难再改变他们了，如果你也在使用 word 我建议你多用一用模板相关的功能，可以提高你不少效率，当然我更建议你使用我下面要将的 markdown 啦，你看到的这篇文章，包括这个小站里面所有的文章也都是 markdown 编辑而成</p>
<p>markdown 其实就是一种标记语言，类似于 html，但是比 html 简单很多，简单到只需要三分钟就可以学会，也没有那么多冗余的标签，写作者只需要关注在内容上，但是写出来的东西只是纯文本文件，如果需要展示出来就需要一些专业的 markdown 软件了，比如 <a href="http://www.mweb.im/" target="_blank" rel="noopener">mweb</a>、<a href="http://25.io/mou/" target="_blank" rel="noopener">mou</a>、<a href="http://macdown.uranusjr.com/" target="_blank" rel="noopener">macdown</a> 之类的，可以通过导入 css 文件来定义样式，可以通过不同的 css 文件来定义不同的样式，非常灵活，如果你没有 css 文件，通常会有一个默认的显示，或者可以使用 github 上面的样式文件，当然你懂前端的话完全可以按自己的审美编写 css 文件啦。这里 markdown 将内容和样式完全分离，写作时完全不用关注样式，编辑体验大大提升；而另一方面，每个人都可以有自己喜好的样式，同样的内容在不同的用户面前能够按照他们习惯的方式展示出不同的风格，阅读体验也有较大提升；由于是纯文本文件，还可以配合 git 之类的版本管理工具，可以很清晰地看出不同版本的修改</p>
<p>当然还有一种情况，你只关注编辑，不需要展示，那你可能只需要一个像 sublime text 3 或者 vscode 之类的文本编辑器就可以了。大部分博客网站都是直接支持 markdown 的，写完整个文件内容帖进去即可，或者你用 hexo 之类的软件搭建的博客小站，更是直接基于 markdown 的</p>
<p>目前 markdown 已经成为了最流行的博客写作工具，也有越来越多的文档开始使用 markdown 来管理，快点开始使用 markdown 来提升你的工作效率吧</p>
<p>下面附上 markdown 的语法</p>
<pre><code>
# 一级标题
### 三级标题
##### 五级标题

正文正文正文正文正文正文正文正文正文

*强调*
**加粗**

1. 有序列表
2. 有序李彪

- 无序列表
- 无序列表

> 引用

[链接点这里](http://xxx.com)
![图片链接](/img/xxx.jpg)
&lt;http://xxx.com&gt;

| header1 | header2 | header3 |
|---------|---------|---------|
| column1 | column2 | column3 |
| column1 | column2 | column3 |

`代码`

```
代码块
```
</code></pre>
]]></content>
      
        
        <tags>
            
            <tag> markdown </tag>
            
            <tag> 写作 </tag>
            
            <tag> 工具 </tag>
            
            <tag> 博客 </tag>
            
            <tag> hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang restful 框架之 go-swagger]]></title>
      <url>/2018/02/08/golang-restful-%E6%A1%86%E6%9E%B6%E4%B9%8B-go-swagger/</url>
      <content type="html"><![CDATA[<p>restful 是这些年的高频词汇了，各大互联网公司也都纷纷推出了自己的 restful api，其实 restful 和 thrift，grpc 类似，就是一种协议，但是这种协议有点特殊的就是使用 http 接口，返回的对象一般是 json 格式，这样有个好处，就是可以供前端的 js 直接调用，使用非常方便，但 http 本身并不是一个高效的协议，后端的内部通信还是使用 grpc 或者 thrift 可以获得更高的性能</p>
<p>其实如果只是要用 http 返回 json 本身并不是一件很难的事情，不用任何框架，golang 本身也能很方便做到，但是当你有很多 api 的时候，这些 api 的维护和管理就会变得很复杂，你自己都无法记住这些 api 应该填什么参数，返回什么，当然你可以花很多时间去维护一份接口文档，这样不仅耗时而且很难保证文档的即时性，准确性以及一致性</p>
<p>swagger 有一整套规范来定义一个接口文件，类似于 thrift 和 proto 文件，定义了服务的请求内容和返回内容，同样也有工具可以生成各种不同语言的框架代码，在 golang 里面我们使用 go-swagger 这个工具，这个工具还提供了额外的功能，可以可视化显示这个接口，方便阅读</p>
<p>下面通过一个例子来简单介绍一下这个框架的使用，还是之前的点赞评论系统：<a href="https://github.com/hatlonely/microservices" target="_blank" rel="noopener">https://github.com/hatlonely/microservices</a></p>
<h3 id="go-swagger-使用方法"><a href="#go-swagger-使用方法" class="headerlink" title="go-swagger 使用方法"></a>go-swagger 使用方法</h3><h4 id="api-定义文件"><a href="#api-定义文件" class="headerlink" title="api 定义文件"></a>api 定义文件</h4><p>首先需要写一个 api 定义文件，这里我只展示其中一个接口 <code>countlike</code>，请求中带有某篇文章，返回点赞的次数</p>
<pre><code>paths:
  /countlike:
    get:
      tags:
        - like
      summary: 有多少赞
      description: &#39;&#39;
      operationId: countLike
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - name: title
          in: query
          description: 文章标题
          required: true
          type: string
      responses:
        &#39;200&#39;:
          description: 成功
          schema:
            $ref: &#39;#/definitions/CountLikeModel&#39;
        &#39;500&#39;:
          description: 内部错误
          schema:
            $ref: &#39;#/definitions/ErrorModel&#39;
definitions:
  CountLikeModel:
    type: object
    properties:
      count:
        type: integer
      title:
        type: string
        example: golang json 性能分析
  ErrorModel:
    type: object
    properties:
      message:
        type: string
        example: error message
      code:
        type: integer
        example: 400
</code></pre><p>这个是 yaml 语法，有点像去掉了括号的 json</p>
<p>这里完整地定义了请求方法、请求参数、正常返回接口、异常返回结果，有了这个文件只需要执行下面命令就能生成框架代码了</p>
<pre><code>swagger generate server -f api/comment_like/comment_like.yaml
</code></pre><p>还可以下面这个命令可视化查看这个接口文件</p>
<pre><code>swagger serve api/comment_like/comment_like.yaml
</code></pre><p>这个命令依赖 swagger 工具，可以通过下面命令获取</p>
<p>Mac</p>
<pre><code>brew tap go-swagger/go-swagger
brew install go-swagger
</code></pre><p>Linux</p>
<pre><code>go get -u github.com/go-swagger/go-swagger/cmd/swagger
export PATH=$GOPATH/bin:$PATH
</code></pre><p>执行完了之后，你发现多了几个文件夹，其中 <code>cmd</code> 目录里面包含 main 函数，是整个程序的入口，<code>restapi</code> 文件夹下面包含协议相关代码，其中 <code>configure_xxx.go</code> 是需要特别关注的，你需要在这个文件里面实现你具体的业务逻辑</p>
<p>现在你就其实已经可以运行程序了，<code>go run cmd/comment-like-server/main.go</code>，在浏览器里面访问一下你的 api，会返回一个错误信息，告诉你 api 还没有实现，下面就来实现一下吧</p>
<h4 id="业务逻辑实现"><a href="#业务逻辑实现" class="headerlink" title="业务逻辑实现"></a>业务逻辑实现</h4><pre><code>api.LikeCountLikeHandler = like.CountLikeHandlerFunc(func(params like.CountLikeParams) middleware.Responder {
    count, err := comment_like.CountLike(params.Title)
    if err != nil {
        return like.NewCountLikeInternalServerError().WithPayload(&amp;models.ErrorModel{
            Code: http.StatusInternalServerError,
            Message: err.Error(),
        })
    }
    return like.NewCountLikeOK().WithPayload(&amp;models.CountLikeModel{
        Count: count,
        Title: params.Title,
    })
})
</code></pre><p>你只需要在这些 handler 里面实现自己的业务逻辑即可，这里对协议的封装非常好，除了业务逻辑以及打包返回，没有多余的逻辑</p>
<p>再次运行，现在返回已经正常了</p>
<h4 id="统一处理"><a href="#统一处理" class="headerlink" title="统一处理"></a>统一处理</h4><p>如果你对请求有一些操作需要统一处理，比如输出统一的日志之类的，可以重写这个函数，也在 <code>configure_xxx.go</code> 这个文件中</p>
<pre><code>func setupGlobalMiddleware(handler http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        w.Header().Set(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;)
        handler.ServeHTTP(w, r)
    })
}
</code></pre><p>这里我统一设置了一下头部，解决跨域访问问题</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>go-swagger 官方文档：<a href="https://goswagger.io" target="_blank" rel="noopener">https://goswagger.io</a></li>
<li>go-swagger github：<a href="https://github.com/go-swagger/go-swagger" target="_blank" rel="noopener">https://github.com/go-swagger/go-swagger</a></li>
<li>OpenApi 2.0：<a href="https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md" target="_blank" rel="noopener">https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 微服务 </tag>
            
            <tag> swagger </tag>
            
            <tag> restful </tag>
            
            <tag> go-swagger </tag>
            
            <tag> 网络框架 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang orm 框架之 gorm]]></title>
      <url>/2018/02/08/golang-orm-%E6%A1%86%E6%9E%B6%E4%B9%8B-gorm/</url>
      <content type="html"><![CDATA[<p>最近在想给这个小站增加点赞和评论功能，第三方系统又有各种限制，就想自己弄个后端，实现类似的功能，对于个人来说，数据量不是很大，单机的 mysql 足够存下所有数据，mysql 作为底层存储是个不错的选择</p>
<p>之前在公司是直接用的 <code>github.com/go-sql-driver/mysql</code> 访问数据库都是直接用写 sql，取出结果然后自己拼成对象，使用上面不是很方便，可读性也不好。想起之前研究 php laravel 框架的时候，直接把数据库层屏蔽了，用户看到的只有对象，使用非常方便，java 里面这种操作方式基本上已经成了标准做法，就去 github 上找了一下 golang 里面有没有类似的东西，果然已经有非常成熟的框架了，<code>github.com/jinzhu/gorm</code> 已经有 7k+ 的 star 了</p>
<p>ORM（Object Relation Mapping），对象关系映射，实际上就是对数据库的操作进行封装，对上层开发人员屏蔽数据操作的细节，开发人员看到的就是一个个对象，大大简化了开发工作，提高了生产效率</p>
<p>好了，下面我以这个点赞评论系统为例，介绍一下 gorm 的简单用法，以下使用的完整代码：<a href="https://github.com/hatlonely/microservices/blob/master/internal/comment_like/comment_like.go" target="_blank" rel="noopener">https://github.com/hatlonely/microservices/blob/master/internal/comment_like/comment_like.go</a></p>
<h3 id="gorm-用法介绍"><a href="#gorm-用法介绍" class="headerlink" title="gorm 用法介绍"></a>gorm 用法介绍</h3><h4 id="库安装"><a href="#库安装" class="headerlink" title="库安装"></a>库安装</h4><pre><code>go get -u github.com/jinzhu/gorm
</code></pre><h4 id="数据库连接"><a href="#数据库连接" class="headerlink" title="数据库连接"></a>数据库连接</h4><pre><code class="golang">import (
    &quot;github.com/jinzhu/gorm&quot;
    _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;
）

var db *gorm.DB

func init() {
    var err error
    db, err = gorm.Open(&quot;mysql&quot;, &quot;&lt;user&gt;:&lt;password&gt;/&lt;database&gt;?charset=utf8&amp;parseTime=True&amp;loc=Local&quot;)
    if err != nil {
        panic(err)
    }
}
</code></pre>
<p>连接比较简单，直接调用 <code>gorm.Open</code> 传入数据库地址即可</p>
<p><code>github.com/jinzhu/gorm/dialects/mysql</code> 是 golang 的 mysql 驱动，实际上就是 <code>github.com/go-sql-driver/mysql</code> 作者这里为了好记，重新弄了个名字</p>
<p>这里我用的 mysql，实际上支持基本上所有主流的关系数据库，连接方式上略有不同</p>
<pre><code class="golang">db.DB().SetMaxIdleConns(10)
db.DB().SetMaxOpenConns(100)
</code></pre>
<p>还可以使用 <code>db.DB()</code> 对象设置连接池信息</p>
<h4 id="表定义"><a href="#表定义" class="headerlink" title="表定义"></a>表定义</h4><p>先来定义一个点赞表，这里面一条记录表示某个用户在某个时刻对某篇文章点了一个赞，用 ip + ua 来标识用户，title 标识文章标题</p>
<pre><code class="golang">type Like struct {
    ID        int    `gorm:&quot;primary_key&quot;`
    Ip        string `gorm:&quot;type:varchar(20);not null;index:ip_idx&quot;`
    Ua        string `gorm:&quot;type:varchar(256);not null;&quot;`
    Title     string `gorm:&quot;type:varchar(128);not null;index:title_idx&quot;`
    Hash      uint64 `gorm:&quot;unique_index:hash_idx;&quot;`
    CreatedAt time.Time
}
</code></pre>
<p>gorm 用 tag 的方式来标识 mysql 里面的约束</p>
<p>创建索引只需要直接指定列即可，这里创建了两个索引，<code>ip_idx</code> 和 <code>title_idx</code>；如果需要多列组合索引，直接让索引的名字相同即可；如果需要创建唯一索引，指定为 <code>unique_index</code> 即可</p>
<p>支持时间类型，直接使用 <code>time.Time</code> 即可</p>
<h4 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h4><pre><code class="golang">if !db.HasTable(&amp;Like{}) {
    if err := db.Set(&quot;gorm:table_options&quot;, &quot;ENGINE=InnoDB DEFAULT CHARSET=utf8&quot;).CreateTable(&amp;Like{}).Error; err != nil {
        panic(err)
    }
}
</code></pre>
<p>直接通过 <code>db.CreateTable</code> 就可以创建表了，非常方便，还可以通过 <code>db.Set</code> 设置一些额外的表属性</p>
<h4 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h4><pre><code class="golang">like := &amp;Like{
    Ip:        ip,
    Ua:        ua,
    Title:     title,
    Hash:      murmur3.Sum64([]byte(strings.Join([]string{ip, ua, title}, &quot;-&quot;))) &gt;&gt; 1,
    CreatedAt: time.Now(),
}

if err := db.Create(like).Error; err != nil {
    return err
}
</code></pre>
<p>先构造已给对象，直接调用 <code>db.Create()</code> 就可以插入一条记录了</p>
<h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><pre><code class="golang">if err := db.Where(&amp;Like{Hash: hash}).Delete(Like{}).Error; err != nil {
    return err
}
</code></pre>
<p>先用 <code>db.Where()</code> 构造查询条件，再调用 <code>db.Delete()</code> 就可以删除</p>
<h4 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h4><pre><code class="golang">var count int
err := db.Model(&amp;Like{}).Where(&amp;Like{Ip: ip, Ua: ua, Title: title}).Count(&amp;count).Error
if err != nil {
    return false, err
}
</code></pre>
<p>先用 <code>db.Model()</code> 选择一个表，再用 <code>db.Where()</code> 构造查询条件，后面可以使用 <code>db.Count()</code> 计算数量，如果要获取对象，可以使用 <code>db.Find(&amp;Likes)</code> 或者只需要查一条记录 <code>db.First(&amp;Like)</code></p>
<h4 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h4><pre><code class="golang">db.Model(&amp;user).Update(&quot;name&quot;, &quot;hello&quot;)
db.Model(&amp;user).Updates(User{Name: &quot;hello&quot;, Age: 18})
db.Model(&amp;user).Updates(User{Name: &quot;&quot;, Age: 0, Actived: false}) // nothing update
</code></pre>
<p>我这个系统里面没有更新需求，这几个例子来自于官网，第一个是更新单条记录；第二个是更新整条记录，注意只有非空字段才会更新；第三个例子是不会更新的，在系统设计的时候要尽量避免这些空值有特殊的含义，如果一定要更新，可以使用第一种方式，设置单个值</p>
<h4 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h4><p>其实你已经看到了，这里基本上所有的函数都是链式的，全部都返回 <code>db</code> 对象，任何时候调用 <code>db.Error</code> 就能获取到错误信息，非常方便</p>
<h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><pre><code class="golang">func CreateAnimals(db *gorm.DB) err {
    tx := db.Begin()
    if err := tx.Create(&amp;Animal{Name: &quot;Giraffe&quot;}).Error; err != nil {
        tx.Rollback()
        return err
    }
    if err := tx.Create(&amp;Animal{Name: &quot;Lion&quot;}).Error; err != nil {
        tx.Rollback()
        return err
    }
    tx.Commit()
    return nil
}
</code></pre>
<p>事务的处理也很简单，用 <code>db.Begin()</code> 声明开启事务，结束的时候调用 <code>tx.Commit()</code>，异常的时候调用 <code>tx.Rollback()</code></p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>还可以使用如下方式设置日志输出级别以及改变日志输出地方</p>
<pre><code>db.LogMode(true)
db.SetLogger(gorm.Logger{revel.TRACE})
db.SetLogger(log.New(os.Stdout, &quot;\r\n&quot;, 0))
</code></pre><p>也支持普通的 sql，但是建议尽量不要使用</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>gorm 官方文档: <a href="http://gorm.io/" target="_blank" rel="noopener">http://gorm.io/</a></li>
<li>gorm github: <a href="https://github.com/jinzhu/gorm" target="_blank" rel="noopener">https://github.com/jinzhu/gorm</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> golang </tag>
            
            <tag> orm </tag>
            
            <tag> gorm </tag>
            
            <tag> mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[几种实用的 pythonic 语法]]></title>
      <url>/2018/02/04/%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%94%A8%E7%9A%84-pythonic-%E8%AF%AD%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>python 是一门简单而优雅的语言，可能是过于简单了，不用花太多时间学习就能使用，其实 python 里面还有一些很好的特性，能大大简化你代码的逻辑，提高代码的可读性</p>
<p>关于 pythonic，你可以在终端打开 python，然后输入 <code>import this</code>，看看输出什么，这就是 Tim Peters 的 <a href="https://www.python.org/dev/peps/pep-0020/" target="_blank" rel="noopener">《The Zen of Python》</a>，这首充满诗意的诗篇里概况了 python 的设计哲学，而这些思想，其实在所有语言也基本上是通用的</p>
<blockquote>
<p>Beautiful is better than ugly.<br>Explicit is better than implicit.<br>Simple is better than complex.<br>Complex is better than complicated.<br>Flat is better than nested.<br>Sparse is better than dense.<br>Readability counts.<br>Special cases aren’t special enough to break the rules.<br>Although practicality beats purity.<br>Errors should never pass silently.<br>Unless explicitly silenced.<br>In the face of ambiguity, refuse the temptation to guess.<br>There should be one– and preferably only one –obvious way to do it.<br>Although that way may not be obvious at first unless you’re Dutch.<br>Now is better than never.<br>Although never is often better than *right* now.<br>If the implementation is hard to explain, it’s a bad idea.<br>If the implementation is easy to explain, it may be a good idea.<br>Namespaces are one honking great idea – let’s do more of those!</p>
</blockquote>
<h3 id="使用生成器-yield"><a href="#使用生成器-yield" class="headerlink" title="使用生成器 yield"></a>使用生成器 yield</h3><p>生成器是 python 里面一个非常有用的语法特性，却也是最容易被忽视的一个，可能是因为大部分能用生成器的地方也能用列表吧。</p>
<p>生成器可以简单理解成一个函数，每次执行到 yield 语句就返回一个值，通过不停地调用这个函数，就能获取到所有的值，这些值就能构成了一个等效的列表，但是与列表不同的是，这些值是不断计算得出，而列表是在一开始就计算好了，这就是 lazy evaluation 的思想。这个特性在数据量特别大的场景非常有用，比如大数据处理，一次无法加载所有的文件，使用生成器就能做到一行一行处理，而不用担心内存溢出</p>
<pre><code class="python">def fibonacci():
    num0 = 0
    num1 = 1
    for i in range(10):
        num2 = num0 + num1
        yield num2
        num0 = num1
        num1 = num2

for i in fibonacci():
    print(i)
</code></pre>
<h3 id="用-else-子句简化循环和异常"><a href="#用-else-子句简化循环和异常" class="headerlink" title="用 else 子句简化循环和异常"></a>用 else 子句简化循环和异常</h3><p><code>if / else</code> 大家都用过，但是在 python 里面，<code>else</code> 还可以用在循环和异常里面</p>
<pre><code class="python"># pythonic 写法
for cc in [&#39;UK&#39;, &#39;ID&#39;, &#39;JP&#39;, &#39;US&#39;]:
    if cc == &#39;CN&#39;:
        break
else:
    print(&#39;no CN&#39;)

# 一般写法
no_cn = True
for cc in [&#39;UK&#39;, &#39;ID&#39;, &#39;JP&#39;, &#39;US&#39;]:
    if cc == &#39;CN&#39;:
        no_cn = False
        break
if no_cn:
    print(&#39;no CN&#39;)
</code></pre>
<p><code>else</code> 放在循环里面的含义是，如果循环全部遍历完成，没有执行 <code>break</code>，则执行 <code>else</code> 子句</p>
<pre><code class="python"># pythonic 写法
try:
    db.execute(&#39;UPDATE table SET xx=xx WHERE yy=yy&#39;)
except DBError:
    db.rollback()
else:
    db.commit()

# 一般写法
has_error = False
try:
    db.execute(&#39;UPDATE table SET xx=xx WHERE yy=yy&#39;)
except DBError:
    db.rollback()
    has_error = True
if not has_error:
    db.commit()
</code></pre>
<p><code>else</code> 放到异常里面可以表示，如果没有异常发生需要执行的操作</p>
<h3 id="用-with-子句自动管理资源"><a href="#用-with-子句自动管理资源" class="headerlink" title="用 with 子句自动管理资源"></a>用 with 子句自动管理资源</h3><p>我们都知道，打开的文件需要在用完之后关闭，要不就会造成资源泄露，但是实际编程的时候经常会忘记关闭，特别是在一些逻辑复杂的场景中，更是如此，python 有一个优雅地解决方案，那就是 <code>with</code> 子句</p>
<pre><code class="python"># pythonic 写法
with open(&#39;pythonic.py&#39;) as fp:
    for line in fp:
        print(line[:-1])

# 一般写法
fp = open(&#39;pythonic.py&#39;)
for line in fp:
    print(line[:-1])
fp.close()
</code></pre>
<p>使用 <code>with as</code> 语句后，无需手动调用 <code>fp.close()</code>, 在作用域结束后，文件会被自动 close 掉，完整的执行过如下:</p>
<ol>
<li>调用 <code>open(&#39;pythonic.py&#39;)</code>，返回的一个对象 <code>obj</code>,</li>
<li>调用 <code>obj.__enter__()</code> 方法，返回的值赋给 <code>fp</code></li>
<li>执行 <code>with</code> 中的代码块</li>
<li>执行 <code>obj.__exit__()</code></li>
<li>如果这个过程发生异常，将异常传给 <code>obj.__exit__()</code>，如果 <code>obj.__exit__()</code> 返回 <code>False</code>, 异常将被继续抛出，如果返回 <code>True</code>，异常被挂起，程序继续运行</li>
</ol>
<h3 id="列表推导与生成器表达式"><a href="#列表推导与生成器表达式" class="headerlink" title="列表推导与生成器表达式"></a>列表推导与生成器表达式</h3><blockquote>
<p>列表推导<br><code>[expr for iter_var in iterable if cond_expr]</code></p>
<p>生成器表达式<br><code>(expr for iter_var in iterable if cond_expr)</code></p>
</blockquote>
<p>列表推导和生成器表达式提供了一种非常简洁高效的方式来创建列表或者迭代器</p>
<pre><code class="python"># pythonic 写法
squares = [x * x for x in range(10)]

# 一般写法
squares = []
for x in range(10):
    squares.append(x * x)
</code></pre>
<h3 id="用-items-遍历-map"><a href="#用-items-遍历-map" class="headerlink" title="用 items 遍历 map"></a>用 items 遍历 map</h3><p>python 里面 map 的遍历有很多种方式，在需要同事使用 key 和 value 的场合，建议使用 <code>items()</code> 函数</p>
<pre><code class="python">m = {&#39;one&#39;: 1, &#39;two&#39;: 2, &#39;three&#39;: 3}
for k, v in m.items():
    print(k, v)

for k, v in sorted(m.items()):
    print(k, v)
</code></pre>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>Google python 语言规范: <a href="http://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/python_language_rules/" target="_blank" rel="noopener">http://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/python_language_rules/</a></li>
<li>《编写高质量代码：改善 Python 程序的91个建议》</li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> python </tag>
            
            <tag> pythonic </tag>
            
            <tag> 语法糖 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 网络框架之 thrift]]></title>
      <url>/2018/02/04/golang-%E7%BD%91%E7%BB%9C%E6%A1%86%E6%9E%B6%E4%B9%8B-thrift/</url>
      <content type="html"><![CDATA[<p>thrift 最初是 facebook 开发使用的 rpc 通信框架，后来贡献给了 apache 基金会，出来得比较早，几乎支持所有的后端语言，使用非常广泛，是不可不知的一个网络框架</p>
<p>和 <a href="http://hatlonely.github.io/2018/02/03/golang-网络框架之-grpc/" target="_blank" rel="noopener">grpc</a> 一样，需要先定义通信协议，然后实现自己业务逻辑，下面还是通过一个简单示例（之前的echo程序）说明 thrift 的用法，下面示例使用的完整代码在下列地址：<br>实现文件：<a href="https://github.com/hatlonely/hellogolang/tree/master/cmd/thrift" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/tree/master/cmd/thrift</a><br>协议文件：<a href="https://github.com/hatlonely/hellogolang/tree/master/api/echo_thrift" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/tree/master/api/echo_thrift</a></p>
<h3 id="简单-echo-服务"><a href="#简单-echo-服务" class="headerlink" title="简单 echo 服务"></a>简单 echo 服务</h3><h4 id="获取-thrift"><a href="#获取-thrift" class="headerlink" title="获取 thrift"></a>获取 thrift</h4><pre><code>go get git.apache.org/thrift.git/lib/go
</code></pre><h4 id="定义协议文件"><a href="#定义协议文件" class="headerlink" title="定义协议文件"></a>定义协议文件</h4><pre><code>namespace go echo

struct EchoReq {
    1: string msg;
}

struct EchoRes {
    1: string msg;
}

service Echo {
    EchoRes echo(1: EchoReq req);
}
</code></pre><p>执行 <code>thrift -r --gen go echo.thrift</code> 命令会生成 <code>gen-go</code> 文件夹，这个过程其实是将上面的协议翻译成 golang 代码</p>
<p>这个命令依赖于 thrift 工具，可以通过下面命令获取</p>
<p>Mac</p>
<pre><code>brew install thrift
</code></pre><p>Linux</p>
<pre><code>wget http://www-us.apache.org/dist/thrift/0.11.0/thrift-0.11.0.tar.gz
tar -xzvf thrift-0.11.0.tar.gz
cd thrift-0.11.0
./configure
make -j8
[sudo] make install
</code></pre><h4 id="实现服务端"><a href="#实现服务端" class="headerlink" title="实现服务端"></a>实现服务端</h4><pre><code>type EchoServerImp struct {
}

func (e *EchoServerImp) Echo(ctx context.Context, req *echo.EchoReq) (*echo.EchoRes, error) {
    fmt.Printf(&quot;message from client: %v\n&quot;, req.GetMsg())

    res := &amp;echo.EchoRes{
        Msg: req.GetMsg(),
    }

    return res, nil
}

func main() {
    transport, err := thrift.NewTServerSocket(&quot;:3000&quot;)
    if err != nil {
        panic(err)
    }

    processor := echo.NewEchoProcessor(&amp;EchoServerImp{})
    server := thrift.NewTSimpleServer4(
        processor,
        transport,
        thrift.NewTBufferedTransportFactory(8192),
        thrift.NewTCompactProtocolFactory(),
    )
    if err := server.Serve(); err != nil {
        panic(err)
    }
}
</code></pre><p>这个过程和 grpc 类似，不同的地方在于，thrift 支持更多的服务器类型，支持不同的协议打包方式，方便用户选择，这里的 compact 协议是一种压缩的协议，使用比较多</p>
<h4 id="实现客户端"><a href="#实现客户端" class="headerlink" title="实现客户端"></a>实现客户端</h4><pre><code>func main() {
    var transport thrift.TTransport
    var err error
    transport, err = thrift.NewTSocket(&quot;localhost:3000&quot;)
    if err != nil {
        fmt.Errorf(&quot;NewTSocket failed. err: [%v]\n&quot;, err)
        return
    }

    transport, err = thrift.NewTBufferedTransportFactory(8192).GetTransport(transport)
    if err != nil {
        fmt.Errorf(&quot;NewTransport failed. err: [%v]\n&quot;, err)
        return
    }
    defer transport.Close()

    if err := transport.Open(); err != nil {
        fmt.Errorf(&quot;Transport.Open failed. err: [%v]\n&quot;, err)
        return
    }

    protocolFactory := thrift.NewTCompactProtocolFactory()
    iprot := protocolFactory.GetProtocol(transport)
    oprot := protocolFactory.GetProtocol(transport)
    client := echo.NewEchoClient(thrift.NewTStandardClient(iprot, oprot))

    var res *echo.EchoRes
    res, err = client.Echo(context.Background(), &amp;echo.EchoReq{
        Msg: strings.Join(os.Args[1:], &quot; &quot;),
    })
    if err != nil {
        fmt.Errorf(&quot;client echo failed. err: [%v]&quot;, err)
        return
    }

    fmt.Printf(&quot;message from server: %v&quot;, res.GetMsg())
}
</code></pre><p>这个 client 相对复杂一些，需要和 server 端设置一致的打包方式，如果不一致会出现通信失败，这一点需要特别注意一下</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>thrift go 官网: <a href="http://thrift.apache.org/tutorial/go" target="_blank" rel="noopener">http://thrift.apache.org/tutorial/go</a></li>
<li>thrift github: <a href="https://github.com/apache/thrift/" target="_blank" rel="noopener">https://github.com/apache/thrift/</a></li>
<li>thrift go tutorial: <a href="https://github.com/apache/thrift/tree/master/tutorial/go/src" target="_blank" rel="noopener">https://github.com/apache/thrift/tree/master/tutorial/go/src</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 微服务 </tag>
            
            <tag> 网络框架 </tag>
            
            <tag> thrift </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[我为什么写博客]]></title>
      <url>/2018/02/04/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E5%86%99%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<p>最近有点沉迷于这个博客了，除了工作，吃饭，睡觉，基本所有的时间都花在这里了，经常弄到夜里两点，和之前沉迷 dota 有得一拼😏</p>
<p>一直有一个博客梦，总是羡慕那些有个人网站的人，有那么一块地方，可以尽情地书写自己的感受，施展自己的才华，展现自己的个性。用过 csdn，试过 qq 空间，后来自己用 nodejs 自己打了一个，断断续续的，由于各种各样的原因最终都没有坚持下去</p>
<p>直到最近，那么多曾今的伙伴各奔东西，各种思绪在脑海里涌动。你知道，一个人的时候，总是会想很多事情。想得最多的就是，我将要做什么以及我做了什么。工作三年多了，好像懂了很多，但是真的当我想要去总结的时候，却发现好像什么都不懂，什么东西都好像知道一点，却又什么东西都说不清楚，总觉得比别人厉害一点，却又不知道厉害在哪里。开始怀疑自己，也不过庸人一个，还谈什么梦想，只不过空想</p>
<p>回想起来，自己其实也并不怎么努力，书买了一大堆，但是真正读完的没几本；一直想学英语，也只是说说而已；办过好几张健身卡，也只能坚持三天；花了那么多时间打游戏，水平也还是不咋地。这样下去，再过三年，又会怎样，我还是我，还是一样没有女朋友😔</p>
<p>我需要一些变化，开始看书，背单词，然后开始写博客</p>
<p>写博客可能会很耗时间，但实际上却是一件极大提升效率的事情。IT是个深不见底行业，你永远都在学习，却永远都学不完，而人是会遗忘的，很多时候，我们在重复解决着之前解决过的问题，浪费了很多时间。而写博客，不仅能避免这个问题，而且能帮你理清思路，对这个问题有更深的理解，如果写得好的话，分享出来还能帮更多人节省时间，反过来还能提升个人影响力。</p>
<p>之前就有使用过 hexo 这个博客模板，最近突然在 github 上看到 material 主题，早在 material design 出来的时候，就对这种设计感到惊叹，一直想做一个 material 风格的博客，由于设计天分有限，再加上没有经验，一直也没有实现，这个主题正好满足了我的需求。那天晚上我折腾到凌晨4点，第二天起来花了半天时间设计我的头像，只为了和这个主题风格更搭一些，又陆陆续续花了两天的时间，修改这个主题，包括手机的适配，一些小 bug 的修复，一些 ui 配色和一些小细节的调整等等，每一次小小的改进都让我开心不已。每篇博客还可以配一张图片作为背景图，找一张好看图片作为背景，为写博客增添了不少乐趣。</p>
<p>折腾了那么久，现在这个小站，算是基本满意吧，希望自己可以坚持写下去。</p>
]]></content>
      
        
        <tags>
            
            <tag> 博客 </tag>
            
            <tag> hexo </tag>
            
            <tag> 程序人生 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 网络框架之 grpc]]></title>
      <url>/2018/02/03/golang-%E7%BD%91%E7%BB%9C%E6%A1%86%E6%9E%B6%E4%B9%8B-grpc/</url>
      <content type="html"><![CDATA[<p>grpc 是 google 开源的一款网络框架，具有极好的性能，可能是目前性能最好的网络框架，支持流式 rpc，可以很方便地构建消息订阅发布系统，支持几乎所有主流的语言，使用上面也很简单，公司很多服务基于 grpc 框架构建，运行非常稳定</p>
<p>开始之前首先你要知道网络框架为你做了哪些事情：</p>
<blockquote>
<ol>
<li>网络协议序列化与反序列化</li>
<li>网络底层通信</li>
<li>并发管理</li>
</ol>
</blockquote>
<p>以及需要你做哪些事情：</p>
<blockquote>
<ol>
<li>定义通信的内容（通过协议文件）</li>
<li>实现通信的方法（实现协议接口）</li>
</ol>
</blockquote>
<p>以下面两个例子来分别说明两种 rpc 服务的简单用法</p>
<p>示例使用的完整代码在下列地址：<br>实现文件：<a href="https://github.com/hatlonely/hellogolang/tree/master/cmd/grpc" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/tree/master/cmd/grpc</a><br>协议文件：<a href="https://github.com/hatlonely/hellogolang/tree/master/api" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/tree/master/api</a></p>
<h3 id="简单-echo-服务"><a href="#简单-echo-服务" class="headerlink" title="简单 echo 服务"></a>简单 echo 服务</h3><p>要实现的这个服务很简单，功能和 echo 命令类似，用一个字符串请求服务器，返回相同的字符串</p>
<h4 id="获取-grpc"><a href="#获取-grpc" class="headerlink" title="获取 grpc"></a>获取 grpc</h4><pre><code>go get google.golang.org/grpc
go get google.golang.org/genproto/
</code></pre><p><code>go get</code> 上面两个库就可以了。可能被墙了，需要 vpn；如果没有 vpn，可以找一台能下载的服务器下载下来再传到本地；如果也没有服务器，可以点击<a href="/resource/google.golang.org.tar.gz">这里</a>下载，解压后放到 <code>vendor/</code> 目录下即可，不过可能不是最新版本</p>
<h4 id="定义协议文件"><a href="#定义协议文件" class="headerlink" title="定义协议文件"></a>定义协议文件</h4><p>首先要定义通信的协议，grpc 使用的是 proto3 序列化协议，这是一个高效的协议，关于这个协议的跟多内容可以参考下面链接：<a href="https://developers.google.com/protocol-buffers/docs/proto3" target="_blank" rel="noopener">https://developers.google.com/protocol-buffers/docs/proto3</a></p>
<pre><code>syntax = &quot;proto3&quot;;

package echo;

message EchoReq {
    string msg = 1;
}

message EchoRes {
    string msg = 1;
}

service Echo {
    rpc echo (EchoReq) returns (EchoRes);
}
</code></pre><p>执行如下命令会自动生成 <code>echo.pb.go</code> 文件，这个过程其实是把上面这个协议翻译成 golang：</p>
<pre><code>protoc --go_out=plugins=grpc:. echo.proto
</code></pre><p>实际项目中可以把这个命令放到一个 <a href="https://github.com/hatlonely/hellogolang/blob/master/api/echo_proto/Makefile" target="_blank" rel="noopener">Makefile</a> 文件中，执行 <code>make</code> 命令即可生成代码</p>
<p>上面命令依赖 <code>protoc</code> 工具，以及 golang 插件 <code>protoc-gen-go</code>，可以通过如下命令获取</p>
<p>Mac</p>
<pre><code>brew install grpc
go get -u github.com/golang/protobuf/{proto,protoc-gen-go}
</code></pre><p>Linux</p>
<pre><code>wget https://github.com/google/protobuf/releases/download/v3.2.0/protobuf-cpp-3.2.0.tar.gz
tar -xzvf protobuf-cpp-3.2.0.tar.gz
cd protobuf-3.2.0
./configure
make -j8
[sudo] make install
go get -u github.com/golang/protobuf/{proto,protoc-gen-go}
</code></pre><h4 id="实现协议接口"><a href="#实现协议接口" class="headerlink" title="实现协议接口"></a>实现协议接口</h4><pre><code>type EchoServerImp struct {

}

func (e *EchoServerImp) Echo(ctx context.Context, req *echo.EchoReq) (*echo.EchoRes, error) {
    fmt.Printf(&quot;message from client: %v\n&quot;, req.GetMsg())

    res := &amp;echo.EchoRes{
        Msg: req.GetMsg(),
    }

    return res, nil
}
</code></pre><p>首先要定义一个接口的实现类 <code>EchoServerImp</code>，接口的的定义可以在上面生成的文件 <code>echo.pb.go</code> 中找到，这个类里面也可以有一些和业务逻辑相关的成员变量，这里我们的需求比较简单，没有其他的成员</p>
<p>然后需要在接口函数里面实现我们具体的业务逻辑，这里仅仅把请求里面的内容读出来，再写回到响应里面</p>
<p>你还可以为这个类增加其他的函数，比如初始化之类的，根据你具体的业务需求就好</p>
<h4 id="实现服务端"><a href="#实现服务端" class="headerlink" title="实现服务端"></a>实现服务端</h4><pre><code>func main() {
    server := grpc.NewServer()
    echo.RegisterEchoServer(server, &amp;EchoServerImp{})

    address, err := net.Listen(&quot;tcp&quot;, &quot;:3000&quot;)
    if err != nil {
        panic(err)
    }

    if err := server.Serve(address); err != nil {
        panic(err)
    }
}
</code></pre><p>把我们刚刚实现的类实例注册到 grpc 里，再绑定到本地的一个端口上就可以了，现在可以启动服务了 <code>go run echo_server.go</code></p>
<h4 id="实现客户端"><a href="#实现客户端" class="headerlink" title="实现客户端"></a>实现客户端</h4><pre><code>func main() {
    conn, err := grpc.Dial(&quot;127.0.0.1:3000&quot;, grpc.WithInsecure())
    if err != nil {
        fmt.Errorf(&quot;dial failed. err: [%v]\n&quot;, err)
        return
    }

    client := echo.NewEchoClient(conn)
    res, err := client.Echo(context.Background(), &amp;echo.EchoReq{
        Msg: strings.Join(os.Args[1:], &quot; &quot;),
    })

    if err != nil {
        fmt.Errorf(&quot;client echo failed. err: [%v]&quot;, err)
        return
    }

    fmt.Printf(&quot;message from server: %v&quot;, res.GetMsg())
}
</code></pre><p>创建一个 client 之后，就可以像访问本地方法一样访问我们的服务了，<code>go run echo_client.go hellogrpc</code></p>
<h3 id="流式-rpc-服务"><a href="#流式-rpc-服务" class="headerlink" title="流式 rpc 服务"></a>流式 rpc 服务</h3><p>实现一个 counter 服务，客户端传过来一个数字，服务端从这个数字开始，不停地向下计数返回</p>
<h4 id="定义协议文件-1"><a href="#定义协议文件-1" class="headerlink" title="定义协议文件"></a>定义协议文件</h4><pre><code>syntax = &quot;proto3&quot;;

package counter;

message CountReq {
    int64 start = 1;
}

message CountRes {
    int64 num = 1;
}

service Counter {
    rpc count (CountReq) returns (stream CountRes);
}
</code></pre><p>定义一个流式的 rpc 只需要在返回的字段前加一个 stream 关键字就可以</p>
<h4 id="实现服务端-1"><a href="#实现服务端-1" class="headerlink" title="实现服务端"></a>实现服务端</h4><pre><code>type CounterServerImp struct {

}

func (c *CounterServerImp) Count(req *counter.CountReq, stream counter.Counter_CountServer) error {
    fmt.Printf(&quot;request from client. start: [%v]\n&quot;, req.GetStart())

    i := req.GetStart()
    for {
        i++
        stream.Send(&amp;counter.CountRes{
            Num: i,
        })
        time.Sleep(time.Duration(500) * time.Millisecond)
    }

    return nil
}

func main() {
    server := grpc.NewServer()
    counter.RegisterCounterServer(server, &amp;CounterServerImp{})

    address, err := net.Listen(&quot;tcp&quot;, &quot;:3000&quot;)
    if err != nil {
        panic(err)
    }

    if err := server.Serve(address); err != nil {
        panic(err)
    }
}
</code></pre><p>接口实现上需要写一个死循环，不停地调用 <code>Send</code> 函数返回结果即可</p>
<h4 id="实现客户端-1"><a href="#实现客户端-1" class="headerlink" title="实现客户端"></a>实现客户端</h4><pre><code>func main() {
    start, _ := strconv.ParseInt(os.Args[1], 10, 64)

    conn, err := grpc.Dial(&quot;127.0.0.1:3000&quot;, grpc.WithInsecure())
    if err != nil {
        fmt.Errorf(&quot;dial failed. err: [%v]\n&quot;, err)
        return
    }
    client := counter.NewCounterClient(conn)

    stream, err := client.Count(context.Background(), &amp;counter.CountReq{
        Start: start,
    })
    if err != nil {
        fmt.Errorf(&quot;count failed. err: [%v]\n&quot;, err)
        return
    }

    for {
        res, err := stream.Recv()
        if err != nil {
            fmt.Errorf(&quot;client count failed. err: [%v]&quot;, err)
            return
        }

        fmt.Printf(&quot;server count: %v\n&quot;, res.GetNum())
    }
}
</code></pre><p>客户端的 <code>Count</code> 接口返回的是一个 <code>stream</code>，不断地调用这个 <code>stream</code> 的 <code>Recv</code> 方法，可以不断地获取来自服务端的返回</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>grpc 官方文档中文版: <a href="http://doc.oschina.net/grpc?t=60133" target="_blank" rel="noopener">http://doc.oschina.net/grpc?t=60133</a></li>
<li>grpc 官方示例: <a href="https://github.com/grpc/grpc-go/tree/master/examples/route_guide" target="_blank" rel="noopener">https://github.com/grpc/grpc-go/tree/master/examples/route_guide</a></li>
<li>proto3 语法: <a href="https://developers.google.com/protocol-buffers/docs/proto3" target="_blank" rel="noopener">https://developers.google.com/protocol-buffers/docs/proto3</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> grpc </tag>
            
            <tag> 微服务 </tag>
            
            <tag> 网络框架 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 单元测试]]></title>
      <url>/2018/01/31/golang-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</url>
      <content type="html"><![CDATA[<p>单元测试是质量保证十分重要的一环，好的单元测试不仅能及时地发现问题，更能够方便地调试，提高生产效率，所以很多人认为写单元测试是需要额外的时间，会降低生产效率，是对单元测试最大的偏见和误解</p>
<p>go 语言原生支持了单元测试，使用上非常简单，测试代码只需要放到以 <code>_test.go</code> 结尾的文件中即可。golang的测试分为单元测试和性能测试，单元测试的测试用例以 <code>Test</code> 开头，性能测试以 <code>Benchmark</code> 开头</p>
<h3 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h3><p>实现排列组合函数对应的单元测试和性能测试</p>
<h4 id="实现排列组合函数"><a href="#实现排列组合函数" class="headerlink" title="实现排列组合函数"></a>实现排列组合函数</h4><pre><code>// combination.go

package hmath

func combination(m, n int) int {
    if n &gt; m-n {
        n = m - n
    }

    c := 1
    for i := 0; i &lt; n; i++ {
        c *= m - i
        c /= i + 1
    }

    return c
}
</code></pre><h4 id="实现单元测试和性能测试"><a href="#实现单元测试和性能测试" class="headerlink" title="实现单元测试和性能测试"></a>实现单元测试和性能测试</h4><pre><code>// combination_test.go

package hmath

import (
    &quot;math/rand&quot;
    &quot;testing&quot;
)

// 单元测试
// 测试全局函数，以TestFunction命名
// 测试类成员函数，以TestClass_Function命名
func TestCombination(t *testing.T) {
    // 这里定义一个临时的结构体来存储测试case的参数以及期望的返回值
    for _, unit := range []struct {
        m        int
        n        int
        expected int
    }{
        {1, 0, 1},
        {4, 1, 4},
        {4, 2, 6},
        {4, 3, 4},
        {4, 4, 1},
        {10, 1, 10},
        {10, 3, 120},
        {10, 7, 120},
    } {
        // 调用排列组合函数，与期望的结果比对，如果不一致输出错误
        if actually := combination(unit.m, unit.n); actually != unit.expected {
            t.Errorf(&quot;combination: [%v], actually: [%v]&quot;, unit, actually)
        }
    }
}

// 性能测试
func BenchmarkCombination(b *testing.B) {
    // b.N会根据函数的运行时间取一个合适的值
    for i := 0; i &lt; b.N; i++ {
        combination(i+1, rand.Intn(i+1))
    }
}

// 并发性能测试
func BenchmarkCombinationParallel(b *testing.B) {
    // 测试一个对象或者函数在多线程的场景下面是否安全
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            m := rand.Intn(100) + 1
            n := rand.Intn(m)
            combination(m, n)
        }
    })
}
</code></pre><h4 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h4><pre><code>go test combination_test.go combination.go           # 单元测试
go test --cover combination_test.go combination.go   # 单元测试覆盖率
go test -bench=. combination_test.go combination.go  # 性能测试 cpu
go test -bench=. -benchmem combination_test.go combination.go   # 性能测试 cpu + 内存
</code></pre><h4 id="setup-和-teardown"><a href="#setup-和-teardown" class="headerlink" title="setup 和 teardown"></a>setup 和 teardown</h4><p>setup 和 teardown 是在每个 case 执行前后都需要执行的操作，golang 没有直接的实现，可以通过下面这个方法实现全局的 setup 和 teardown，具体每个 case 的 setup 和 teardown 需要自己实现</p>
<pre><code>func TestMain(m *testing.M) {
    // setup code...
    os.Exit(m.Run())
    // teardown code...
}
</code></pre><h3 id="goconvey"><a href="#goconvey" class="headerlink" title="goconvey"></a>goconvey</h3><p>这个第三方工具会自动帮我们跑测试，并且以非常友好的可视化界面帮我们展示测试的结果，包括测试失败的原因，测试覆盖率等等，内部还提供了很多友好的断言，能提高测试代码的可读性</p>
<h4 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h4><pre><code>go get github.com/smartystreets/goconvey
</code></pre><p>然后用终端在测试代码的目录下运行 <code>goconvey</code> 命令即可</p>
<h4 id="测试例子"><a href="#测试例子" class="headerlink" title="测试例子"></a>测试例子</h4><pre><code>package package_name

import (
    &quot;testing&quot;
    . &quot;github.com/smartystreets/goconvey/convey&quot;
)

func TestIntegerStuff(t *testing.T) {
    Convey(&quot;Given some integer with a starting value&quot;, t, func() {
        x := 1

        Convey(&quot;When the integer is incremented&quot;, func() {
            x++

            Convey(&quot;The value should be greater by one&quot;, func() {
                So(x, ShouldEqual, 2)
            })
        })
    })
}
</code></pre><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>go testing: <a href="http://docs.studygolang.com/pkg/testing/" target="_blank" rel="noopener">http://docs.studygolang.com/pkg/testing/</a></li>
<li>goconvey: <a href="https://github.com/smartystreets/goconvey" target="_blank" rel="noopener">https://github.com/smartystreets/goconvey</a></li>
<li>goconvey 文档: <a href="https://github.com/smartystreets/goconvey/wiki/Documentation" target="_blank" rel="noopener">https://github.com/smartystreets/goconvey/wiki/Documentation</a></li>
<li>goconvey 标准断言: <a href="https://github.com/smartystreets/goconvey/wiki/Assertions" target="_blank" rel="noopener">https://github.com/smartystreets/goconvey/wiki/Assertions</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 单元测试 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang pprof 性能分析工具]]></title>
      <url>/2018/01/29/golang-pprof-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/</url>
      <content type="html"><![CDATA[<p>性能优化是个永恒的话题，而很多时候我们在作性能优化的时候，往往基于代码上面的直觉，把所有能想到的优化都优化了一遍，不错过任何小的优化点，结果整个代码的逻辑变得极其复杂，而性能上面并没有太大的提升。事实上，性能问题往往集中在某些小点，有时候很小的改动就能有巨大的提升，所以问题的关键是是怎么去找出这些优化点，幸运的是 golang 在设计的时候就考虑了这个问题，原生提供了性能分析的工具，可以很方便地帮我们找到性能瓶颈</p>
<h3 id="pprof-简介"><a href="#pprof-简介" class="headerlink" title="pprof 简介"></a>pprof 简介</h3><p>golang 的性能分析库在 <code>runtime/pprof</code> 里，主要提供下面几个接口</p>
<pre><code class="golang">// 堆栈分析
func WriteHeapProfile(w io.Writer) error
// cpu分析
func StartCPUProfile(w io.Writer) error
func StopCPUProfile()
</code></pre>
<p>使用上面比较简单，只需要将文件指针传给对应的函数即可，性能数据将写入到文件中，然后可以使用 golang 自带的 pprof 工具生成 svg，pdf 的可视化图，然后就可以很直观地从这些图里面看到主要的性能消耗了</p>
<h3 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h3><h4 id="首先需要一个程序"><a href="#首先需要一个程序" class="headerlink" title="首先需要一个程序"></a>首先需要一个程序</h4><p>首先需要在你的程序里面注入 pprof 代码，下面是一段示例代码，完整代码在：<a href="https://github.com/hatlonely/hellogolang/blob/master/cmd/pprof/pprof_runtime.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/cmd/pprof/pprof_runtime.go</a>，这里使用的 <code>PPCmd</code> 方法，是为了方便使用，做的一个简单封装，代码在：<a href="https://github.com/hatlonely/easygolang/blob/master/pprof/pprof.go" target="_blank" rel="noopener">https://github.com/hatlonely/easygolang/blob/master/pprof/pprof.go</a></p>
<pre><code class="golang">func main() {
    go doSomething1()
    go doSomething2()
    go doSomething3()

    if err := pprof.PPCmd(&quot;cpu 10s&quot;); err != nil {
        panic(err)
    }

    if err := pprof.PPCmd(&quot;mem&quot;); err != nil {
        panic(err)
    }
}
</code></pre>
<p>编译，运行上面代码会生成两个 pprof 文件，<code>cpu.pprof.yyyymmddhhmmss</code> 和 <code>mem.pprof.yyyymmddhhmmss</code>，编译运行的方法如下：</p>
<pre><code>cd $GOPATH/src
git clone git@github.com:hatlonely/hellogolang.git
cd hellogolang
glide install
go build cmd/pprof_runtime.go
./pprof_runtime
</code></pre><h4 id="pprof-文件分析"><a href="#pprof-文件分析" class="headerlink" title="pprof 文件分析"></a>pprof 文件分析</h4><p>pprof 文件是二进制的，不是给人读的，需要翻译一下，而 golang 原生就给我们提供了分析工具，直接执行下面命令即可，会生成一张很直观的 svg 图片，直接用 chrome 就可以打开，当然也可以生成别的格式（pdf，png 都可以），可以用 <code>go tool pprof -h</code> 命令查看支持的输出类型</p>
<pre><code>go tool pprof -svg ./pprof_runtime cpu.pprof.201801301415 &gt; cpu.svg
</code></pre><p>注意这个工具依赖于 graphviz 工具，Mac 上可用 <code>brew install graphviz</code>，centos <code>yum install graphviz</code> 即可</p>
<p><img src="/img/stats/pprof_runtime_cpu.png" alt="性能分析图"></p>
<h3 id="http-接口"><a href="#http-接口" class="headerlink" title="http 接口"></a>http 接口</h3><p><code>net/http/pprof</code> 里面对 <code>runtime/pprof</code> 作了一些封装，对外提供了 http 接口，可以直接通过浏览器访问，但是只是一些字符串的结果，没有作可视化，体验并不是很好，用 <code>go tool</code> 访问体验能好一点</p>
<pre><code>go tool pprof http://localhost:3000/debug/pprof/profile
go tool pprof http://localhost:3000/debug/pprof/heap
</code></pre><p>个人感觉这个接口比较鸡肋，首先最大的问题是展示上面并不直观，要是能直接在网页上面可视化地展示可能还真的挺方便的；还有就是需要额外的提供一个 http 的端口，而这个接口还依赖 <code>net/http</code>这就意味着如果你的应用使用的是其他第三方的 http 库，可能还需要解决兼容性的问题；实际上，我再使用这个接口的时候，在服务器压力较大的场景下，会出现访问超时，而这种压力较大情况下的性能可能才是真正的性能瓶颈。</p>
<p>建议在根据的需求，自己封装 <code>runtime/pprof</code> 的接口，当然是用场景比较简单也可以用我上面的封装，然后在服务里面自己提供一个专门的性能分析接口（可能是 gprc，thrift，或者其他的第三方 http 框架）</p>
<h3 id="火焰图"><a href="#火焰图" class="headerlink" title="火焰图"></a>火焰图</h3><p>除了上面生成的 svg 图，还可以生成火焰图，这是 uber 提供的一个工具，在显示上面可能更直观一些</p>
<p>安装命令如下：</p>
<pre><code>go get github.com/uber/go-torch
git clone git@github.com:brendangregg/FlameGraph.git
export PATH=$PATH:/path/to/FlameGraph
</code></pre><p>使用方法如下：</p>
<pre><code>go-torch --binaryname=./pprof_runtime --binaryinput=cpu.pprof.201801301415
</code></pre><p><img src="/img/stats/pprof_runtime_cpu_torch.svg" alt="性能分析图"></p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>Package pprof: <a href="https://golang.org/pkg/runtime/pprof/" target="_blank" rel="noopener">https://golang.org/pkg/runtime/pprof/</a></li>
<li>Profiling Go Programs: <a href="https://blog.golang.org/profiling-go-programs" target="_blank" rel="noopener">https://blog.golang.org/profiling-go-programs</a></li>
<li>Go torch: <a href="https://github.com/uber/go-torch" target="_blank" rel="noopener">https://github.com/uber/go-torch</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> 性能 </tag>
            
            <tag> golang </tag>
            
            <tag> pprof </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang json 性能分析]]></title>
      <url>/2018/01/28/golang-json-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/</url>
      <content type="html"><![CDATA[<p>Json 作为一种重要的数据格式，具有良好的可读性以及自描述性，广泛地应用在各种数据传输场景中。Go 语言里面原生支持了这种数据格式的序列化以及反序列化，内部使用反射机制实现，性能有点差，在高度依赖 json 解析的应用里，往往会成为性能瓶颈，好在已有很多第三方库帮我们解决了这个问题，但是这么多库，对于像我这种有选择困难症的人来说，到底要怎么选择呢，下面就给大家来一一分析一下</p>
<h3 id="ffjson"><a href="#ffjson" class="headerlink" title="ffjson"></a>ffjson</h3><pre><code>go get -u github.com/pquerna/ffjson
</code></pre><p>原生的库性能比较差的主要原因是使用了很多反射的机制，为了解决这个问题，ffjson 通过预编译生成代码，类型的判断在预编译阶段已经确定，避免了在运行时的反射</p>
<p>但也因此在编译前需要多一个步骤，需要先生成 ffjson 代码，生成代码只需要执行 <code>ffjson &lt;file.go&gt;</code> 就可以了，其中 <code>file.go</code> 是一个包含 json 结构体定义的 go 文件。注意这里 ffjson 是这个库提供的一个代码生成工具，直接执行上面的 <code>go get</code> 会把这个工具安装在 <code>$GOPATH/bin</code> 目录下，把 <code>$GOPATH/bin</code> 加到 <code>$PATH</code> 环境变量里面，可以全局访问</p>
<p>另外，如果有些结构，不想让 ffjson 生成代码，可以通过增加注释的方式</p>
<pre><code class="golang">// ffjson: skip
type Foo struct {
   Bar string
}

// ffjson: nodecoder
type Foo struct {
   Bar string
}
</code></pre>
<h3 id="easyjson"><a href="#easyjson" class="headerlink" title="easyjson"></a>easyjson</h3><pre><code>go get -u github.com/mailru/easyjson/...
</code></pre><p>easyjson 的思想和 ffjson 是一致的，都是增加一个预编译的过程，预先生成对应结构的序列化反序列化代码，除此之外，easyjson 还放弃了一些原生库里面支持的一些不必要的特性，比如：key 类型声明，key 大小写不敏感等等，以达到更高的性能</p>
<p>生成代码执行 <code>easyjson -all &lt;file.go&gt;</code> 即可，如果不指定 <code>-all</code> 参数，只会对带有 <code>//easyjson:json</code> 的结构生成代码</p>
<pre><code class="golang">//easyjson:json
type A struct {
    Bar string
}
</code></pre>
<h3 id="jsoniter"><a href="#jsoniter" class="headerlink" title="jsoniter"></a>jsoniter</h3><pre><code>go get -u github.com/json-iterator/go
</code></pre><p>这是一个很神奇的库，滴滴开发的，不像 easyjson 和 ffjson 都使用了预编译，而且 100% 兼容原生库，但是性能超级好，也不知道怎么实现的，如果有人知道的话，可以告诉我一下吗？</p>
<blockquote>
<p>2018-1-28日更新，来自官方（@taowen）的回复：<br>没啥神奇的。就是预先缓存了对应struct的decoder实例而已。然后unsafe.Pointer省掉了一些interface{}的开销。还有一些文本解析上的优化</p>
</blockquote>
<p>使用上面，你只要把所有的 </p>
<pre><code>import &quot;encoding/json&quot;
</code></pre><p>替换成</p>
<pre><code>import &quot;github.com/json-iterator/go&quot;

var json = jsoniter.ConfigCompatibleWithStandardLibrary
</code></pre><p>就可以了，其它都不需要动</p>
<h3 id="codec-json"><a href="#codec-json" class="headerlink" title="codec-json"></a>codec-json</h3><pre><code>go get -u github.com/ugorji/go/codec
</code></pre><p>这个库里面其实包含很多内容，json 只是其中的一个功能，比较老，使用起来比较麻烦，性能也不是很好</p>
<h3 id="jsonparser"><a href="#jsonparser" class="headerlink" title="jsonparser"></a>jsonparser</h3><pre><code>go get -u github.com/buger/jsonparser
</code></pre><p>严格来说，这个库不属于 json 序列化的库，只是提供了一些 json 解析的接口，使用的时候需要自己去设置结构里面的值，事实上，每次调用都需要重新解析 json 对象，性能并不是很好</p>
<p>就像名字暗示的那样，这个库只是一个解析库，并没有序列化的接口</p>
<h3 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h3><p>对上面这些 json 库，作了一些性能测试，测试代码在：<a href="https://github.com/hatlonely/hellogolang/blob/master/internal/json/json_benchmark_test.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/internal/json/json_benchmark_test.go</a>，下面是在我的 Macbook 上测试的结果（实际结果和库的版本以及机器环境有关，建议自己再测试一遍）：</p>
<pre><code>BenchmarkMarshalStdJson-4                    1000000          1097 ns/op
BenchmarkMarshalJsonIterator-4               2000000           781 ns/op
BenchmarkMarshalFfjson-4                     2000000           941 ns/op
BenchmarkMarshalEasyjson-4                   3000000           513 ns/op
BenchmarkMarshalCodecJson-4                  1000000          1074 ns/op
BenchmarkMarshalCodecJsonWithBufio-4         1000000          2161 ns/op
BenchmarkUnMarshalStdJson-4                   500000          2512 ns/op
BenchmarkUnMarshalJsonIterator-4             2000000           591 ns/op
BenchmarkUnMarshalFfjson-4                   1000000          1127 ns/op
BenchmarkUnMarshalEasyjson-4                 2000000           608 ns/op
BenchmarkUnMarshalCodecJson-4                  20000        122694 ns/op
BenchmarkUnMarshalCodecJsonWithBufio-4        500000          3417 ns/op
BenchmarkUnMarshalJsonparser-4               2000000           877 ns/op
</code></pre><p><img src="/img/stats/golang_json_performance.png" alt="golang_json_performance"></p>
<p>从上面的结果可以看出来：</p>
<ol>
<li>easyjson 无论是序列化还是反序列化都是最优的，序列化提升了1倍，反序列化提升了3倍</li>
<li>jsoniter 性能也很好，接近于easyjson，关键是没有预编译过程，100%兼容原生库</li>
<li>ffjson 的序列化提升并不明显，反序列化提升了1倍</li>
<li>codecjson 和原生库相比，差不太多，甚至更差</li>
<li>jsonparser 不太适合这样的场景，性能提升并不明显，而且没有反序列化</li>
</ol>
<p><strong>所以综合考虑，建议大家使用 jsoniter，如果追求极致的性能，考虑 easyjson</strong></p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>ffjson: <a href="https://github.com/pquerna/ffjson" target="_blank" rel="noopener">https://github.com/pquerna/ffjson</a></li>
<li>easyjson: <a href="https://github.com/mailru/easyjson" target="_blank" rel="noopener">https://github.com/mailru/easyjson</a></li>
<li>jsoniter: <a href="https://github.com/json-iterator/go" target="_blank" rel="noopener">https://github.com/json-iterator/go</a></li>
<li>jsonparser: <a href="https://github.com/buger/jsonparser" target="_blank" rel="noopener">https://github.com/buger/jsonparser</a></li>
<li>codecjson: <a href="http://ugorji.net/blog/go-codec-primer" target="_blank" rel="noopener">http://ugorji.net/blog/go-codec-primer</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> 性能 </tag>
            
            <tag> golang </tag>
            
            <tag> json </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 依赖管理]]></title>
      <url>/2018/01/27/golang-%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/</url>
      <content type="html"><![CDATA[<p>依赖管理是一个语言非常重要的特性，很大程度上决定着一个语言的流行程度，流行的语言大多都有非常成熟的依赖管理工具，java 的 maven 和 gradle，javascript 的 npm，python 的 pip，这些工具极大地降低了我们使用第三方库的成本，提高了生产效率，而 c++ 比较奇葩，并没有这样统一的依赖管理工具，大公司好一点，有专门的团队去做这样的工具解决依赖的问题，小公司就只能自己把源码拉下来，放到固定的目录，然后编译成二进制，运气不好的话，还要自己解决各种兼容性的问题，如果有版本更新，这个过程还得重复一遍，第三方库的使用和维护成本之高，让人简直就想放弃……</p>
<p>Golang 是自带依赖管理工具的，直接 <code>go get &lt;packages&gt;</code> 就可以把依赖拉下来，但是这种方式有个缺陷，没有版本控制，你每次拉下来的 <code>package</code> 都是 <code>master</code> 分支上的版本，这样是很危险的，源代码更新可能会有一些对外接口上面的调整，这些调整很有可能就导致你的程序编译通不过，而更致命的是，新的代码引入了一些新的 bug 或者接口语义上的变化会导致你的程序崩溃，所以早期的 gopher 开发了另一个依赖管理工具 <a href="https://github.com/tools/godep" target="_blank" rel="noopener"><code>godep</code></a>解决了版本管理的问题，最近，golang 官方也在开发一个新的依赖管理工具 <a href="https://github.com/golang/dep" target="_blank" rel="noopener"><code>dep</code></a>，但今天我给大家推荐的是 <a href="https://github.com/Masterminds/glide" target="_blank" rel="noopener"><code>glide</code></a> 这款工具，和其他工具相比呢，这款工具支持更多的特性，包括支持依赖的自动分析，指定版本范围，依赖清理等等，而且使用起来也比较简单。这里有一些工具的对比：<a href="https://github.com/Masterminds/glide/wiki/Go-Package-Manager-Comparison" target="_blank" rel="noopener">https://github.com/Masterminds/glide/wiki/Go-Package-Manager-Comparison</a></p>
<p>下面我给大家简单介绍一下 <code>glide</code> 在实际项目中的使用</p>
<h3 id="glide使用"><a href="#glide使用" class="headerlink" title="glide使用"></a>glide使用</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>Linux</p>
<pre><code>curl https://glide.sh/get | sh
</code></pre><p>Mac</p>
<pre><code>brew install glide
</code></pre><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><pre><code>glide init
</code></pre><p>这个命令会自动分析你代码里面的依赖，然后创建一个 <code>glide.yaml</code> 来描述你当前项目的依赖，生成的这个文件是可以手动编辑的，可以手动修改一些版本之类的信息</p>
<p>如果有些文件夹不希望被扫描，可以通过修改 <code>glide.yaml</code>，增加 <code>excludeDirs</code>，希望忽略某些引入的包可以使用 <code>ignore</code>，更多信息可以参考：<a href="https://glide.readthedocs.io/en/latest/glide.yaml/" target="_blank" rel="noopener">https://glide.readthedocs.io/en/latest/glide.yaml/</a></p>
<pre><code>ignore:
- api
excludeDirs:
- api
- cmd
</code></pre><p>提醒一下，这个操作必须在 <code>$GOPATH/src/</code> 的子目录下面，这个和 golang 本身的包管理机制有关，如果没有设置 <code>$GOPATH</code>，记得设置一下 <code>export GOPATH=&lt;directory&gt;</code></p>
<h4 id="依赖下载"><a href="#依赖下载" class="headerlink" title="依赖下载"></a>依赖下载</h4><pre><code>glide update
</code></pre><p>这个命令会下载 <code>glide.yaml</code> 里面的依赖库，并且同样会分析并下载依赖库依赖的其他第三方库，下载的依赖会放到与 <code>glide.yaml</code> 同级的 <code>vendor</code> 目录，同时还会生成一个 <code>glide.lock</code> 文件，这个文件里面描述了当前依赖的版本信息，不要手工编辑这个文件</p>
<p>如果你在中国，这个步骤里面可能会碰到有些 <code>gopkg</code> 的库拉不下来，也不知道为啥要把这个也禁了……如果你碰到这个问题，你可以手动把这些库下载到 <code>${GOROOT}/src/golang.org/x</code> 下面</p>
<pre><code>git clone https://github.com/golang/crypto.git
git clone https://github.com/golang/sys.git
git clone https://github.com/golang/sync.git
git clone https://github.com/golang/text.git
git clone https://github.com/golang/net.git
</code></pre><h4 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h4><pre><code>glide get --all-dependencies github.com/foo/bar
</code></pre><p>也可以指定版本</p>
<pre><code>glide get --all-dependencies github.com/foo/bar#^1.2.3
</code></pre><p>除了 <code>github</code> 上的依赖，也可以是其他的平台，比如 <code>gitee</code>，或者自己公司搭建的 gitlab，只要有权限就可以，还有一点需要注意，版本必须是三位数字的版本号，否则可能识别不了</p>
<h4 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h4><pre><code>glide install
</code></pre><p>这个命令是在一个已经使用 glide 管理依赖的项目里，需要在新环境下重新安装依赖使用的，这个命令会按照 <code>glide.lock</code> 的信息，把所有的依赖拉取到本地，和 <code>glide update</code> 不同的是，<code>glide update</code> 会来去最新的版本，并且会修改 <code>glide.lock</code>，而 <code>glide install</code> 只下载之前的依赖</p>
<h4 id="依赖镜像"><a href="#依赖镜像" class="headerlink" title="依赖镜像"></a>依赖镜像</h4><pre><code>glide mirror set [original] [replacement]
</code></pre><p>有些库如果访问不了可以通过这种方式设置镜像，golang.org 被禁的问题也可以用如下方法解决</p>
<pre><code>glide mirror set https://golang.org/x/crypto https://github.com/golang/crypto --vcs git
glide mirror set https://golang.org/x/net https://github.com/golang/net --vcs git
glide mirror set https://golang.org/x/text https://github.com/golang/text --vcs git
glide mirror set https://golang.org/x/sys https://github.com/golang/sys --vcs git
</code></pre><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li>glide github: <a href="https://github.com/Masterminds/glide" target="_blank" rel="noopener">https://github.com/Masterminds/glide</a></li>
<li>glide 官网: <a href="https://glide.sh/" target="_blank" rel="noopener">https://glide.sh/</a></li>
<li>glide 文档: <a href="https://glide.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://glide.readthedocs.io/en/latest/</a></li>
<li>go 依赖包管理工具对比: <a href="https://ieevee.com/tech/2017/07/10/go-import.html" target="_blank" rel="noopener">https://ieevee.com/tech/2017/07/10/go-import.html</a></li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 依赖管理 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[蓄水池算法]]></title>
      <url>/2018/01/26/%E8%93%84%E6%B0%B4%E6%B1%A0%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>最近有个需求，需要从不固定大小的数据集中取固定数量的数据作为样本，有个同学提到了蓄水池算法，于是了解了一下。</p>
<p>蓄水池算法，本身是为了解决海量数据的随机抽样问题，在算法领域应用还是挺广泛的，由于数据本身是有权重，又出现了加权蓄水池算法。</p>
<h3 id="蓄水池算法"><a href="#蓄水池算法" class="headerlink" title="蓄水池算法"></a>蓄水池算法</h3><p><strong>问题描述</strong>: 给定一个不固定长度的数据集合 <code>sequence</code>，从中等概率地抽取 <code>k</code> 个元素作为样本返回</p>
<p><strong>问题思路</strong>: 先把样本填满，然后不断往样本里面等概率替换元素</p>
<p><strong>算法实现</strong></p>
<pre><code class="python">def reservior_sampling(sequence, k):
    n = len(sequence)
    if k &gt; n:
        return sequence

    sample = list()
    for i in range(k):
        sample.append(sequence[i])

    for i in range(k, n):
        j = random.randint(0, i)
        if j &gt;= k:
            continue
        sample[j] = sequence[i]

    return sample
</code></pre>
<p>这里需要注意的是往样本里面替换元素的时候，第 <code>i</code> 个元素能被选中用来替换的概率是 <code>k / i + 1</code>，这样就能保证每个元素被选中的机会都是均等的</p>
<h3 id="加权蓄水池算法"><a href="#加权蓄水池算法" class="headerlink" title="加权蓄水池算法"></a>加权蓄水池算法</h3><p><strong>问题描述</strong>: 给定一个不固定长度的非常大的数据集合 <code>sequence</code>，集合中每个元素包含一个权重 <code>weight</code>，按照权重从集合中抽取 <code>k</code> 个元素返回</p>
<p><strong>问题思路</strong>: 和蓄水池算法的思路一样，先把样本填满，然后不断地按照权重替换元素</p>
<p><strong>算法实现</strong></p>
<pre><code class="python">def weighted_reservior_sampling_achao(sequence, k):
    n = len(sequence)
    if k &gt; n:
        return sequence

    wsum = 0
    sample = list()
    for i in range(k):
        sample.append(sequence[i])
        wsum += sequence[i][&#39;weight&#39;] / k

    for i in range(k, n):
        wsum += sequence[i][&#39;weight&#39;] / k
        p = sequence[i][&#39;weight&#39;] / wsum
        j = random.random()
        if j &lt;= p:
            sample[random.randint(0, k-1)] = sequence[i]

    return sample
</code></pre>
<p>这里第 <code>i</code> 个元素被选中用来替换的概率是 <code>sequence[i].weight * k / sum(sequence[0:i+1].weight)</code>，当所有权重都一致的时候，就和蓄水池算法是一致的了。</p>
<p>这里面有个小问题，就是一开始用来填充样本的数据，其实是等概率的，这样会导致，填充样本的数据权重失效，但是这个问题只在数据集合较小（准确地说 <code>k</code> 和 <code>len(sequence)</code> 比较接近）的情况下才会有比较明显的缺陷，在海量数据集的情况下，这种影响是微乎其微的。</p>
<p>完整代码: <a href="https://github.com/hatlonely/algorithm/blob/master/reservoir_sampling.py" target="_blank" rel="noopener">https://github.com/hatlonely/algorithm/blob/master/reservoir_sampling.py</a></p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p>Reservoir sampling: <a href="https://en.wikipedia.org/wiki/Reservoir_sampling" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Reservoir_sampling</a></p>
]]></content>
      
        
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 几种字符串的连接方式]]></title>
      <url>/2018/01/24/golang-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%87%A0%E7%A7%8D%E8%BF%9E%E6%8E%A5%E6%96%B9%E5%BC%8F/</url>
      <content type="html"><![CDATA[<p>最近在做性能优化，有个函数里面的耗时特别长，看里面的操作大多是一些字符串拼接的操作，而字符串拼接在 golang 里面其实有很多种实现。</p>
<h3 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h3><h4 id="1-直接使用运算符"><a href="#1-直接使用运算符" class="headerlink" title="1. 直接使用运算符"></a>1. 直接使用运算符</h4><pre><code class="golang">func BenchmarkAddStringWithOperator(b *testing.B) {
    hello := &quot;hello&quot;
    world := &quot;world&quot;
    for i := 0; i &lt; b.N; i++ {
        _ = hello + &quot;,&quot; + world
    }
}

func BenchmarkAddMoreStringWithOperator(b *testing.B) {
    hello := &quot;hello&quot;
    world := &quot;world&quot;
    for i := 0; i &lt; b.N; i++ {
        var str string
        for i := 0; i &lt; 100; i++ {
            str += hello + &quot;,&quot; + world
        }
    }
}
</code></pre>
<p>golang 里面的字符串都是不可变的，每次运算都会产生一个新的字符串，所以会产生很多临时的无用的字符串，不仅没有用，还会给 gc 带来额外的负担，所以性能比较差</p>
<h4 id="2-fmt-Sprintf"><a href="#2-fmt-Sprintf" class="headerlink" title="2. fmt.Sprintf()"></a>2. fmt.Sprintf()</h4><pre><code class="golang">func BenchmarkAddStringWithSprintf(b *testing.B) {
    hello := &quot;hello&quot;
    world := &quot;world&quot;
    for i := 0; i &lt; b.N; i++ {
        _ = fmt.Sprintf(&quot;%s,%s&quot;, hello, world)
    }
}
</code></pre>
<p>内部使用 <code>[]byte</code> 实现，不像直接运算符这种会产生很多临时的字符串，但是内部的逻辑比较复杂，有很多额外的判断，还用到了 <code>interface</code>，所以性能也不是很好</p>
<h4 id="3-strings-Join"><a href="#3-strings-Join" class="headerlink" title="3. strings.Join()"></a>3. strings.Join()</h4><pre><code class="golang">func BenchmarkAddStringWithJoin(b *testing.B) {
    hello := &quot;hello&quot;
    world := &quot;world&quot;
    for i := 0; i &lt; b.N; i++ {
        _ = strings.Join([]string{hello, world}, &quot;,&quot;)
    }
}
</code></pre>
<p>join会先根据字符串数组的内容，计算出一个拼接之后的长度，然后申请对应大小的内存，一个一个字符串填入，在已有一个数组的情况下，这种效率会很高，但是本来没有，去构造这个数据的代价也不小</p>
<h4 id="4-buffer-WriteString"><a href="#4-buffer-WriteString" class="headerlink" title="4. buffer.WriteString()"></a>4. buffer.WriteString()</h4><pre><code class="golang">func BenchmarkAddStringWithBuffer(b *testing.B) {
    hello := &quot;hello&quot;
    world := &quot;world&quot;
    for i := 0; i &lt; b.N; i++ {
        var buffer bytes.Buffer
        buffer.WriteString(hello)
        buffer.WriteString(&quot;,&quot;)
        buffer.WriteString(world)
        _ = buffer.String()
    }
}

func BenchmarkAddMoreStringWithBuffer(b *testing.B) {
    hello := &quot;hello&quot;
    world := &quot;world&quot;
    for i := 0; i &lt; b.N; i++ {
        var buffer bytes.Buffer
        for i := 0; i &lt; 100; i++ {
            buffer.WriteString(hello)
            buffer.WriteString(&quot;,&quot;)
            buffer.WriteString(world)
        }
        _ = buffer.String()
    }
}
</code></pre>
<p>这个比较理想，可以当成可变字符使用，对内存的增长也有优化，如果能预估字符串的长度，还可以用 <code>buffer.Grow()</code> 接口来设置 capacity</p>
<h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h3><pre><code>BenchmarkAddStringWithOperator-8                50000000                28.4 ns/op             0 B/op          0 allocs/op
BenchmarkAddStringWithSprintf-8                 10000000               234 ns/op              48 B/op          3 allocs/op
BenchmarkAddStringWithJoin-8                    30000000                56.2 ns/op            16 B/op          1 allocs/op
BenchmarkAddStringWithBuffer-8                  20000000                86.0 ns/op           112 B/op          1 allocs/op
BenchmarkAddMoreStringWithOperator-8              100000             14295 ns/op           58896 B/op        100 allocs/op
BenchmarkAddMoreStringWithBuffer-8                300000              4551 ns/op            5728 B/op          7 allocs/op
</code></pre><p>这个是在我的自己 Mac 上面跑的结果，go 版本 <code>go version go1.8 darwin/amd64</code>，这个结果仅供参考，还是要以实际生产环境的值为准，代码在：<a href="https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/string_test.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/string_test.go</a></p>
<h3 id="主要结论"><a href="#主要结论" class="headerlink" title="主要结论"></a>主要结论</h3><ol>
<li>在已有字符串数组的场合，使用 <code>strings.Join()</code> 能有比较好的性能</li>
<li>在一些性能要求较高的场合，尽量使用 <code>buffer.WriteString()</code> 以获得更好的性能</li>
<li>较少字符串连接的场景下性能最好，而且代码更简短清晰，可读性更好</li>
<li>如果需要拼接的不仅仅是字符串，还有数字之类的其他需求的话，可以考虑 <code>fmt.Sprintf</code></li>
</ol>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p>go语言字符串拼接性能分析: <a href="http://herman.asia/efficient-string-concatenation-in-go" target="_blank" rel="noopener">http://herman.asia/efficient-string-concatenation-in-go</a></p>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> string </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[第一次写JD]]></title>
      <url>/2018/01/22/%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%86%99JD/</url>
      <content type="html"><![CDATA[<p>有个同学（同事+同学+室友+基友）要离职了（离职的原因，因为爱情，让我们一起祝福他们吧），缺一个人，老大说，你要找个什么样的人，你自己来写JD吧。</p>
<p>JD（job description）翻译过来工作岗位描述，先来看下我写的JD吧。</p>
<blockquote>
<p><strong>职位诱惑</strong></p>
<blockquote>
<p>双倍于BAT的成长速度</p>
</blockquote>
<p><strong>职位职责</strong></p>
<blockquote>
<ol>
<li>后端工程架构的设计与实现</li>
</ol>
</blockquote>
<p><strong>职位要求</strong></p>
<blockquote>
<ol>
<li>敬畏技术，追求卓越</li>
<li>精通数据结构与算法</li>
<li>至少对一门语言有较深入的研究，至少对一项技术有自己的理解</li>
<li>良好的学习能力，良好的沟通表达能力</li>
<li>爱技术，爱折腾，有代码洁癖、博客、github者优先</li>
<li>不接受非本人制作的简历</li>
</ol>
</blockquote>
<p><strong>工作地点</strong></p>
<blockquote>
<p>北京-望京-金辉大厦</p>
</blockquote>
</blockquote>
<p>职位诱惑，我看到拉勾网上好多写的都是，什么半年调薪，季度奖金，公司福利好啊之类的，好像现在所有互联网公司都这样说，但是做得怎么样可能就差距很大了，这些东西都的可解释性很强，比如奖金，人家王者荣耀发几十个月的年终奖，你发一个月还得乘个系数；人家一年调了三次薪水，你一年调了一次，涨了5%；公司说免费的三餐，如果你想变瘦的话，确实还挺适合你的。所以这些东西真的有什么诱惑力吗？其实最实际的还是最后 offer 里面里面的实际薪资，你要直接告诉我，这个职位月薪 50K，那确实会有一些诱惑力。</p>
<p>那除了自己的利益，还有什么诱惑呢？我觉得还有两点，个人的成长以及公司的愿景。我自己就是一个很关注自身成长的人，毕业之后去百度，包括后来离开，来到mobvista，每次选择都把个人成长放到首要的位置，因为我知道，人生很短，而技术这条路很长，并没有那么多时间能让我去挥霍，而这个过程中，你遇到的人其实很关键，俗话说『听君一席话，胜读十年书』，有些东西，你要靠自己去摸索，真的会走很多弯路，甚至完全就走偏了，感谢我遇到的每个人，感谢你们带给我的成长。而公司愿景，可能听起来很虚，但是实际上对某些人来说，特别是不甘于平庸的人来说，是非常吸引人的，最近我时常在想一个词，『社会责任感』，近二三十年，互联网的飞速发展，彻底地改变了人们的生活，而我现在，深处在这样一个时代的潮流之中，像我这样一个人，到底能为这个社会创造怎样的价值？</p>
<p>所以我写下了双倍于BAT的成长速度，很虚，谁也不知道双倍是多快，甚至不知道有没有更快，但是我只是想让你知道，我在关注这件事情，我会尽我所能地去做到这件事情，这是我的责任，也是我对你的承诺。</p>
<p>职位职责，我看很多都会写现在具体做的事情，还会写一些什么问题排查啊，性能优化之类的事情，这些事情，我不写难道你不知道吗，而我写了，难道就只有这些吗？所以我把这些内容都省略了，只有一条，后端架构的设计与实现，你要知道，你来做的是后端，不是前端，也不是ios或者Android，另外你要做的事情，不仅仅包含系统的实现，同样包含系统的设计。</p>
<p>职位要求，我重点写了一下，主要为了节约一些时间，要知道，面试其实也是一件耗时且无趣的事情，非诚勿扰，谢谢！</p>
<p>第一点，『敬畏技术，追求卓越』，这个其实是公司技术部门，经历一些惨痛教训之后喊出来的口号，我很开心公司能有这样转变，特别是最近超哥（蔡超，前亚马逊中国研发中心首席架构师）的加入，能明显的感觉到技术文化的一些变化。</p>
<p>数据结构与算法，面试过很多七八年工作经验的人，很少人有能让我满意的（其实离满意差很远，简直难以相信），反而是一些年轻些的朋友，能做得比较好，很多人反驳我说，工作时间长了，这些东西经常不用，就忘了，也可以理解，要求不要太高，差不多行了，确实我也做过一些让步，放低一些要求。但是不得不说这是一种悲哀，数据结构与算法，可以说是整个计算机行业的基础，任何的程序都是构建在这样的基础之上，你告诉我说，随着工作经验的增长，这些基础你忘记了，那我会怀疑我们真的是在同一个行业吗？事实上，如果你不熟悉基础，那你的很多实现就会变得很麻烦，很难理解，耗时很长，而且问题很多。相比之下，国外的公司就很看重这个，好几轮的面试全都是算法，不把 <a href="https://leetcode.com/" target="_blank" rel="noopener"><code>leetcode</code></a> 刷个两三遍，都不好意思去找工作。与其说工作时间长了忘了，不如说是被惯坏了，因为国内这种浮躁的氛围，反正干这行，就肯定能找到工作，此处不留爷自有留爷处，何必花那些时间去折腾那些基础的东西，捞钱才最重要，过个一两年，干不下去了，再换个公司，还能涨比钱，整个行业的整体人才素质，就是这样被拉低了……所以，别和我说你再哪哪哪干过多少年，管过多少个人，在我这不好使，麻烦让我看到，现在此刻你有能力解决这个算法问题。</p>
<p>第三点，至少对一门语言有较深入的研究，至少对一项技术有自己的理解。这个其实挺难的，我看很多简历上都写着，有七八年的 c++ 使用经验，然后竟然不知道标准库里面的排序怎么用，不知道 <code>vector</code> 可以设置 <code>capcity</code>，你……让我情何以堪……，最近在用 golang，虽然用的时间不长，但自以为用得还挺6，但是超哥的加入，让我发现自己对 golang 其实一无所知，单元测试框架，pprof 性能分析，堆栈内存分配机制，锁的性能开销，gc 以及协程调度开销等等，让我开始反思自己到底学了些什么……这里我对语言和技术的定义都比较宽泛，没有特别指定何种语言，哪种技术，因为我觉得技术这东西的思想是相通的，你能掌握好一种，就能很快掌握别的，但是前提是你得掌握至少一种，我看重的是你的学习能力，看过某个牛人说过，『我不是啥都懂，我只是学得快』，如果你一种都不精通，很难让我相信你有很强的学习能力。</p>
<p>第四点，我又强调了一下学习能力，因为这个能力真的很重要，这个行业发展那么迅速，没有很强的学习能力，一定会成为团队的负担。另外沟通表达能力，这个被我之前被我忽视的能力，在最近的一年里，让我有非常深切的体会。这个能力包含两个方面，一个是如何快速准确理解别人给你的信息，还一个是如何准确地传达你想要表达的信息。毕竟这是一个高度社会化的行业，任何事情都是人与人合作的结果，中间任何一点理解上面的偏差都有可能造成非常严重的后果。</p>
<p>第五点，可以说是我个人的一个价值观吧，我从心里欣赏这样的人，希望与这样的人相处，和他们一起共事。最近认识了一些新朋友，都还是学生，已经能在 github 上写出 star 2k+的项目了，在看看自己，感觉很是惭愧……</p>
<p>第六点，特别注明了一下，不接受非本人制作的简历，现在这种找工作的 App 做得都很方便，你在上面随便填写东西，然后就会有猎头找到你，帮你找工作，然后还能自动帮你生成简历，我只想说这种简历实在是太low。简历其实可以看出很多东西，排版组织其实可以看出来你个人的一些性格，对项目的描述，也能看出来你的一些表达能力，当然还有很多细节啦，这种自动生成的东西完全没有太多的参考价值。如果你觉得这个东西很方便，能帮你节约时间的话，那我多少也能看出来，你是一个对自己不负责任，得过且过的人，对自己尚且如此，工作亦然。所以，对自己好一点，做个精致的简历吧！</p>
<p>最后祝大家都能找到自己理想的工作，如果找不到，可以来投奔我😏</p>
]]></content>
      
        
        <tags>
            
            <tag> 程序人生 </tag>
            
            <tag> 招聘 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[与vim的一段往事]]></title>
      <url>/2018/01/21/%E4%B8%8Evim%E7%9A%84%E4%B8%80%E6%AE%B5%E5%BE%80%E4%BA%8B/</url>
      <content type="html"><![CDATA[<p>这就要从大学里面学c语言说起了，那个时候我们还在用古老的 visual c++ 6.0（满满的回忆有木有……），不过我唯一的印象只剩下了，嗯，这个东西真的很丑很难用，不过还好，不久就有了 visual studio 2010，好看是好看了，但是好像卡得不行，也不知道是 windows 的锅呢，还是 vs 的锅呢，还是我电脑配置太低，anyway，这些都不太重要，反正那个时候对 IDE 没有什么好感，再加上英语也不太好，那些软件又都是英文，就更不想用了……</p>
<p>后来呢，进了一个实验室，发现大家都在一个黑白的终端下面写代码，所有的操作都通过键盘完成，完全不用鼠标，当时我都惊呆了，这和电视里面演的黑客不是一模一样么，瞬间觉得那些 IDE 简直 low 爆了，真正厉害的黑客是不用 IDE 的（当时天真的想法……）。Vim —— Text editor of the Gods，正是我想要的。</p>
<p>于是开始读vim的书，查相关的资料，记各种快捷键，装各种插件，折腾我的 vimrc。为了用上更纯粹的 vim，我装了双系统；为我的 chrome 装了 vim 插件；在 win 系统下用 vim 整了一套开发环境。远离鼠标！拒绝 IDE！很快我就在 vim 的使用上面小有成就。</p>
<p>然而一直有一个问题我没有解决，但是我相信和其他问题一样，很快就能找到答案。这个问题就是，我想做到像 IDE 那样的智能代码提示，以及函数的调用以及声明的跳转。我查了好多资料，尝试了很多方案，最后好不容易是有提示了，但是提示的内容只是这个文件中出现的其他标识符，也有点用，但是和我想要的还差很远；然后又继续尝试，功夫不负有心人，终于找到了标准库的代码提示，然而只能提示标准库，我自己写的类并没有用；然后我又继续尝试，然后时间一天天过去，并没有什么进展，渐渐地也就没有太大的兴趣了，现在这么用也挺好，真正的黑客是不依赖 IDE 的提示的。而函数跳转的那个问题也类似，一直也没有找到一个完美的解决方案。</p>
<p>后来开始学 java 了，作为 vim 的脑残粉，肯定是要用 vim 来写 java 的，没有代码提示，没有函数跳转，没有编译调试环境，无形之中给自己增加了好多难度，但是老师可不会等我把这些都整明白了再教，没办法，最终还是很不情愿地随了大流，用了 eclipse。</p>
<p>后来终于毕业了，看到公司里大家都在用 vim，我就放心了，这里这么多大牛，困扰我好几年的问题应该能很快就解决了吧。然而……，我发现，我竟然是这里面用 vim 用得最熟练……，也不知道是该高兴呢，还是该忧伤……</p>
<p>省吃俭用的工资终于够买 Mac，第一件事情，就是配置好 vim。然后果断放弃 windows，开始折腾新的 Mac。发现 Mac 上自带的 xcode 做得还挺好看的，关键是还能写 c++，然后就试了试，感觉还挺爽，关键是有错误直接就能看出来，不像之前用 vim 那样写了一大堆，尝试编译一下，跳出几十个错误；智能提示也很友好，好多之前没用过的函数被提示出来才知道，原来还有这么方便的函数，之前我都用别的方式自己实现了一下……；按住 <code>cmd</code> 键就能很方便地跳转到函数实现的地方，再也不用从一堆文件里面去猜，这个函数可能是在哪里实现的了。尝到甜头之后，开始尝试把公司的项目往 xcode 上面迁，结果开发效率有了极大的提升，而更关键的是写代码变成了一件愉快的事情。</p>
<p>现在，基本我所有的代码都用不同的 IDE（xcode, goland, ideal, pycharm, sublime text 3, webstorm）开发完成。而曾经那么迷恋的 vim，有时候在服务器上写一些临时的脚本，也还是会用一用的。</p>
<p>讲真的，鼠标和 IDE 都是非常伟大的发明，把人从繁复重复无聊的工作中解放出来，让人的精力集中在更具创造力的地方，极大提高了生产效率，推动了整个行业的快速发展。而 vim 作为上一个时代的效率的代表，也曾经那么光彩照人，也是时候功成身退了。</p>
<p>科技在进步，时代在向前，虽然我也是一个怀旧的人，但也不想被潮流甩开太远。</p>
]]></content>
      
        
        <tags>
            
            <tag> vim </tag>
            
            <tag> ide </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[谈谈注释]]></title>
      <url>/2018/01/19/%E8%B0%88%E8%B0%88%E6%B3%A8%E9%87%8A/</url>
      <content type="html"><![CDATA[<p>大家肯定都有写过注释，注释这个东西不同于代码，与程序逻辑的正确性没有直接的关系，所以每个人可能都有自己的风格，每个人对哪里应该写注释，注释应该写成什么样子可能都有自己的理解。</p>
<p>我个人对注释的理解经历了四个阶段。</p>
<p>第一个阶段，完全不写注释，这个阶段还处在代码逻辑的实现上面，花大量的时间去调试，修改代码，根本就无暇顾及到注释这个事情。过了一段时间后，发现之前写的又臭又长的代码完全看不明白了，才意识到注释的重要性，于是开始慢慢进入了第二个阶段。</p>
<p>第二个阶段，哪哪都是注释，每个文件，每个类，每个函数，设置每个分支，每个变量，都有一个注释来说明，就怕漏掉某个小细节然后就看不懂了。后来又发现了一个叫做文档注释的东西（doxygen），这个东西不要太酷，可以根据你的写的注释直接生成文档，于是到处都是文档注释，每个文件里面都有一段简介，而简介里面最重要的内容可能就是 <code>@author: hatlonely</code>，生怕别人不知道这些这么low的代码是你写出来的🤦‍♀️，每个函数参数，函数参数的返回值等等，也都有详尽的注释，注释的长度已经远远超过了代码的长度。看起来好像妈妈再也不用担心我看不懂之前写的代码了，然而，一段时间当我重新读到add这个函数的注释的时候，我发现这些信息对我来说好像并没有用，这段代码已经足够的清晰简单，甚至比注释更容易读懂，那这个注释在这里存在的意义又是什么呢，仅仅是为了生成文档注释吗？而更大的问题可能是，如果我要新增一个函数，<code>add3(int a, int b, int c)</code> 我不得不按照之前的文档注释格式写一大堆的注释……注释的维护也是一个大问题，每次逻辑的变更，都需要去改对应的注释，如果忘记修改，注释和代码逻辑的不一致会让人更加困惑。于是注释的维护变成了一件非常无聊的事情，大大地降低了编程体验，而另一方面冗长繁复的注释也降低了代码的阅读体验。</p>
<pre><code class="c++">// @file: 谈谈注释.md
// @date: 2018-01-19 14:00
// @author: hatlonely
// @brief: 一些对注释的理解

// @brief: 求两个数的和 
// @param a 加数
// @param b 被加数
// @return 和
int add(int a, int b) {
    return a + b;
}
</code></pre>
<p>第三个阶段，代码即注释。突然有一天，看到一个观点，代码是一种艺术，本身就是美，就像是诗歌，你见过一首诗歌里面插入了很多注释吗？注释不是对代码的翻译，而绝大多数时候，你在考虑用一个注释解释一个变量的时候，往往可以通过一个好的变量名来避免这个注释，同样，当你要注释某段逻辑的时候，也往往可以通过优化这段逻辑结构，使用一些可读性更强的变量来描述某些过程。于是我去掉了所有的注释，开始编写可读性更强的代码，开始纠结每一个普通的小变量的命名，开始站在普通人的角度去思考代码的逻辑，让代码更贴近自然语言，把让没有任何计算机基础的人都能读懂我的代码作为目标。于是现在代码看起来清爽了不少，代码本该如此简单。但是我满意了吗？并没有。</p>
<p>第四个阶段，必要的注释。毕竟代码不是诗歌，如果没有当时的文化背景以及别人的解读，大部分是诗歌普通人应该也是读不懂的吧。代码逻辑是由特定的场景决定，同一份代码在不同的场景下面也可能是完全不同的含义，所以为什么会是这样一个逻辑，是这个场景下特定的背景所决定的，而代码本身并不能包含这些背景信息。比如下面这段代码，关于ios过滤的这段逻辑，是因为目前的业务上暂时还没有这个需求决定的，这里的注释给了我们一些额外的信息，对我们理解这段逻辑有很大的帮助，如果没有这段注释，一个月后，你可能也忘记了为什么要有ios这样一个特殊的逻辑，不敢动也不知道，久而久之这些代码就成了谜一样的存在。嗯，看起来很优雅，现在我满意了！</p>
<pre><code class="golang">func checkDeviceType(info DeviceInfo, deviceTypeSet map[int32]struct{}) bool {
    // ios的设备类型不想android那么多，暂时还没有定向需求
    if info.platform != &quot;ios&quot; {
        return true
    }

    if _, ok := deviceTypeSet[info.deviceType]; ok {
        return true
    }
    return false
}
</code></pre>
<p>下一个阶段是什么呢？是时候提高一下自己的表述能力了🤣🤣。</p>
]]></content>
      
        
        <tags>
            
            <tag> 注释 </tag>
            
            <tag> 编码风格 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang slice 性能分析]]></title>
      <url>/2018/01/18/golang-slice-%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/</url>
      <content type="html"><![CDATA[<p>golang 在 gc 这块的做得比较弱，频繁地申请和释放内存会消耗很多的资源。另外 slice 使用数组实现，有一个容量和长度的问题，当 slice 的容量用完再继续添加元素时需要扩容，而这个扩容会把申请新的空间，把老的内容复制到新的空间，这是一个非常耗时的操作。有两种方式可以减少这个问题带来的性能开销：</p>
<ol>
<li>在 slice 初始化的时候设置 capacity（但更多的时候我们可能并不知道 capacity 的大小）</li>
<li>复用 slice</li>
</ol>
<p>下面就针对这两个优化设计了如下的benchmark，代码在: <a href="https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/slice_test.go" target="_blank" rel="noopener">https://github.com/hatlonely/hellogolang/blob/master/internal/buildin/slice_test.go</a></p>
<pre><code>BenchmarkAppendWithoutCapacity-8                     100      21442390 ns/op
BenchmarkAppendWithCapLessLen10th-8                  100      18579700 ns/op
BenchmarkAppendWithCapLessLen3th-8                   100      13867060 ns/op
BenchmarkAppendWithCapEqualLen-8                     200       6287940 ns/op
BenchmarkAppendWithCapGreaterLen10th-8               100      18692880 ns/op
BenchmarkAppendWithoutCapacityReuse-8                300       5014320 ns/op
BenchmarkAppendWithCapEqualLenReuse-8                300       4821420 ns/op
BenchmarkAppendWithCapGreaterLen10thReuse-8          300       4903230 ns/op
</code></pre><h3 id="主要结论"><a href="#主要结论" class="headerlink" title="主要结论"></a>主要结论</h3><ol>
<li>在已知 capacity 的情况下，直接设置 capacity 减少内存的重新分配，有效提高性能</li>
<li>capacity &lt; length，capacity 越接近 length，性能越好</li>
<li>capacity &gt; length，如果太大，反而会造成性能下降，这里当 capacity &gt; 10 * length时，与不设置 capacity 的性能差不太多</li>
<li>多次使用复用同一块内存能有效提高性能</li>
</ol>
<h3 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h3><pre><code class="go">func BenchmarkAppendWithoutCapacity(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        var arr []int
        for i := 0; i &lt; N; i++ {
            arr = append(arr, i)
        }
    }
}

func BenchmarkAppendWithCapLessLen10th(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        arr := make([]int, 0, N/10)
        for i := 0; i &lt; N; i++ {
            arr = append(arr, i)
        }
    }
}

func BenchmarkAppendWithCapLessLen3th(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        arr := make([]int, 0, N/3)
        for i := 0; i &lt; N; i++ {
            arr = append(arr, i)
        }
    }
}

func BenchmarkAppendWithCapEqualLen(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        arr := make([]int, 0, N)
        for i := 0; i &lt; N; i++ {
            arr = append(arr, i)
        }
    }
}

func BenchmarkAppendWithCapGreaterLen10th(b *testing.B) {
    for i := 0; i &lt; b.N; i++ {
        arr := make([]int, 0, N*10)
        for i := 0; i &lt; N; i++ {
            arr = append(arr, i)
        }
    }
}

func BenchmarkAppendWithoutCapacityReuse(b *testing.B) {
    var arr []int
    for i := 0; i &lt; b.N; i++ {
        arr = arr[:0]
        for i := 0; i &lt; N; i++ {
            arr = append(arr, i)
        }
    }
}

func BenchmarkAppendWithCapEqualLenReuse(b *testing.B) {
    arr := make([]int, N)
    for i := 0; i &lt; b.N; i++ {
        arr = arr[:0]
        for i := 0; i &lt; N; i++ {
            arr = append(arr, i)
        }
    }
}

func BenchmarkAppendWithCapGreaterLen10thReuse(b *testing.B) {
    arr := make([]int, N*10)
    for i := 0; i &lt; b.N; i++ {
        arr = arr[:0]
        for i := 0; i &lt; N; i++ {
            arr = append(arr, i)
        }
    }
}
</code></pre>
]]></content>
      
        
        <tags>
            
            <tag> 性能 </tag>
            
            <tag> golang </tag>
            
            <tag> slice </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[golang 开发目录结构]]></title>
      <url>/2018/01/16/golang-%E5%BC%80%E5%8F%91%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/</url>
      <content type="html"><![CDATA[<p>在实际的项目中发现大家的目录结构都比较凌乱，基本每个人都有每个人的风格，一个项目在不断地变大，一些新的文件或目录又不断地被添加进来，从这里面去找到自己需要的信息的成本越来越高，一个统一的通用的目录结构非常有必要。</p>
<p>以下内容来自于github上的这个项目（<a href="https://github.com/golang-standards/project-layout" target="_blank" rel="noopener">https://github.com/golang-standards/project-layout</a>）</p>
<h3 id="cmd"><a href="#cmd" class="headerlink" title="/cmd"></a><code>/cmd</code></h3><p>main函数文件（比如 <code>/cmd/myapp.go</code>）目录，这个目录下面，每个文件在编译之后都会生成一个可执行的文件。</p>
<p>不要把很多的代码放到这个目录下面，这里面的代码尽可能简单。</p>
<h3 id="internal"><a href="#internal" class="headerlink" title="/internal"></a><code>/internal</code></h3><p>应用程序的封装的代码，某个应用私有的代码放到 <code>/internal/myapp/</code> 目录下，多个应用通用的公共的代码，放到 <code>/internal/common</code> 之类的目录。</p>
<h3 id="pkg"><a href="#pkg" class="headerlink" title="/pkg"></a><code>/pkg</code></h3><p>一些通用的可以被其他项目所使用的代码，放到这个目录下面</p>
<h3 id="vendor"><a href="#vendor" class="headerlink" title="/vendor"></a><code>/vendor</code></h3><p>项目依赖的其他第三方库，使用 <a href="https://github.com/Masterminds/glide" target="_blank" rel="noopener"><code>glide</code></a> 工具来管理依赖</p>
<h3 id="api"><a href="#api" class="headerlink" title="/api"></a><code>/api</code></h3><p>协议文件，<code>Swagger/thrift/protobuf</code> 等</p>
<h3 id="web"><a href="#web" class="headerlink" title="/web"></a><code>/web</code></h3><p>web服务所需要的静态文件</p>
<h3 id="configs"><a href="#configs" class="headerlink" title="/configs"></a><code>/configs</code></h3><p>配置文件</p>
<h3 id="init"><a href="#init" class="headerlink" title="/init"></a><code>/init</code></h3><p>服务启停脚本</p>
<h3 id="scripts"><a href="#scripts" class="headerlink" title="/scripts"></a><code>/scripts</code></h3><p>其他一些脚本，编译、安装、测试、分析等等</p>
<h3 id="build"><a href="#build" class="headerlink" title="/build"></a><code>/build</code></h3><p>持续集成目录</p>
<p>云 (AMI), 容器 (Docker), 操作系统 (deb, rpm, pkg)等的包配置和脚本放到 <code>/build/package/</code> 目录</p>
<h3 id="deployments"><a href="#deployments" class="headerlink" title="/deployments"></a><code>/deployments</code></h3><p>部署相关的配置文件和模板</p>
<h3 id="test"><a href="#test" class="headerlink" title="/test"></a><code>/test</code></h3><p>其他测试目录，功能测试，性能测试等</p>
<h3 id="docs"><a href="#docs" class="headerlink" title="/docs"></a><code>/docs</code></h3><p>设计文档</p>
<h3 id="tools"><a href="#tools" class="headerlink" title="/tools"></a><code>/tools</code></h3><p>常用的工具和脚本，可以引用 <code>/internal</code> 或者 <code>/pkg</code> 里面的库</p>
<h3 id="examples"><a href="#examples" class="headerlink" title="/examples"></a><code>/examples</code></h3><p>应用程序或者公共库使用的一些例子</p>
<h3 id="assets"><a href="#assets" class="headerlink" title="/assets"></a><code>/assets</code></h3><p>其他一些依赖的静态资源</p>
]]></content>
      
        
        <tags>
            
            <tag> golang </tag>
            
            <tag> 开发 </tag>
            
            <tag> 目录结构 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[《microservice & serverless》by 蔡超的一点感想]]></title>
      <url>/2018/01/12/%E3%80%8Amicroservice-&amp;-serverless%E3%80%8Bby-%E8%94%A1%E8%B6%85%E7%9A%84%E4%B8%80%E7%82%B9%E6%84%9F%E6%83%B3/</url>
      <content type="html"><![CDATA[<p>超哥是来自Amazon的顶级的架构师，经历了Amazon整个向微服务架构迁移的过程，以及向serverless的演化过程，有着极其丰富的经验，年过40，一直站在技术的最前沿，始终保持对技术的执着追求和热情，是名副其实的技术大牛，能与之一起工作，荣幸之至！今天超哥给我们分享的主题《microservice &amp; serverless》，是超哥实际工作经验的一些分享，也为公司架构的演化提供了新的思路和指导。</p>
<p>microservice（微服务）这个可能是这些年最火的一种架构设计了，频繁地出现在各种技术大会上，各大互联网巨头纷纷向这种架构演化，很多小的互联网公司也往这些概念上去靠，大有一种不做微服务就要落伍的趋势。事实上，很多对于微服务的理解比较粗浅，盲目的微服务化甚至会带来更多的负面影响。</p>
<p>目前Amazon内部运行着超过2w过微服务，但是这些微服务并不是凭空产生的，在这之前，运行的服务都是超大的单体服务，但是随着业务的发展，这种服务在整个研发的pipeline（设计→研发→编译→测试→发布→部署→运维）中都出现了一些问题。设计阶段，老的单体服务会给我们带来一些技术限制，比如有些技术只有python语言的实现，但是我们的服务使用java开发，这样我们不得不拿出一个更复杂的设计去解决类似的问题；研发阶段，随着开发人数越来越多，代码冲突的问题越来越多，我们不得不花更多的时间去做这种无趣又没有什么意义的事情；编译阶段，越来越多的依赖很容易造成版本冲突，不同的版本也会引发兼容性的问题，而这种问题如果在运行时才暴露出来可能会造成严重业务影响；部署阶段，很多的特性打包在一起发布，特性越多，出问题的概率也就越大；而最致命的是运维阶段没有回滚方案，一次上线中可能包含很多的特性，而其中任何一条特性的bug就需要回滚，然后可能有些特性需要变更数据格式，新特性能向前兼容老的数据格式，但是回滚后却无法处理新的数据格式，因此无法回滚……就是在这样的背景下，Amazon开始朝微服务的架构演化。</p>
<p>微服务摆脱了单体服务技术的束缚，可以自由地根据业务的特点，选择最适合的技术去实现自己的服务；将一个大的开发流程拆成了很多个小的独立的开发流程，彼此之间不在相互依赖，大大缩短了项目周期；代码冲突的问题也得到了很好的改善；每次发布的特性很少，每天都能发布，而且能做到快速回滚。真正做到，持续集成，持续交付，敏捷开发。</p>
<p>微服务架构同时也带来了一些新的问题。相比与单体服务，微服务的架构数据的传输依赖于rpc的调用，这个调用会带来一些额外的网络耗时，这种耗时往往需要业务上面去考虑是否能容忍，这种rpc的调用收到网络环境的影响，失败是很正常事情，因此需要失败重试机制，于是代码里面到处都充斥着失败重试的冗余代码，影响代码的可读性，更糟糕的是会有雪崩效应，当某个底层服务出现问题时，比如响应时间过长，或者无法访问，这种影响会层层传递到上层，最终导致整个业务系统挂掉；在测试上面也会变得更加困难，之前都在一个实例里面，现在一个服务依赖很多其他的微服务，测试的时候都需要去mock，日志也会分布在不同的服务下面，问题排查比较困难；此外，数据分布在不同的微服务上，在数据一致性上也会有些问题。所以在进行微服务设计的时候也要特别注意这些额外的负面影响，封装重试逻辑，引入熔断和限流机制，统一的日志收集方式。</p>
<p>serverless（无服务器）架构可能是为了让devOps从繁复的运维工作中解放出来的全新架构，最大的特点是整个系统基于AWS提供的各种服务，能够做到自动的拓展以及按流量计费，不再需要人力去维护，大大提高了效率，同时按真实流量的计费对成本也有可能会有优化。而Fass架构，把业务需求封装在一个函数内部，开发人员只需要关注自己的业务逻辑，然后通过网页提交就能完成上线。我在想，当这些技术真正成熟和普及的时候，可能每个普通人，随便花点时间学点python，也能做出一个的服务，而那个时候，我的价值又是什么！？</p>
]]></content>
      
        
        <tags>
            
            <tag> 微服务 </tag>
            
            <tag> 无服务架构 </tag>
            
            <tag> serverless </tag>
            
            <tag> microservice </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
